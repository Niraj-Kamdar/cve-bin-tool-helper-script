/lib64/ld-linux-x86-64.so.2
|fUa
libcurl.so.4
inflate
inflateInit2_
inflateEnd
_ITM_deregisterTMCloneTable
__gmon_start__
_ITM_registerTMCloneTable
curl_version_info
curl_getdate
curl_mime_free
curl_strequal
curl_version
curl_msnprintf
curl_easy_cleanup
curl_easy_escape
curl_mime_filedata
curl_mvfprintf
curl_mime_data
curl_easy_strerror
curl_strnequal
curl_mime_data_cb
curl_mime_init
curl_mime_headers
curl_mprintf
curl_slist_free_all
curl_mfprintf
curl_url
curl_global_cleanup
curl_mime_type
curl_mime_subparts
curl_mime_filename
curl_mime_addpart
curl_url_get
curl_url_cleanup
curl_mvaprintf
curl_mime_name
curl_url_set
curl_easy_init
curl_maprintf
curl_easy_reset
curl_easy_setopt
curl_easy_perform
curl_free
curl_slist_append
curl_easy_pause
curl_global_init
curl_getenv
curl_easy_getinfo
curl_mime_encoder
libmetalink.so.3
metalink_parse_update
metalink_parser_context_new
metalink_get_version
metalink_parser_context_delete
metalink_parse_final
metalink_delete
libssl.so.1.1
libcrypto.so.1.1
SHA1_Init
SHA256_Init
SHA1_Update
MD5_Final
MD5_Init
SHA256_Final
SHA256_Update
SHA1_Final
MD5_Update
libz.so.1
libpthread.so.0
lseek
__errno_location
libc.so.6
getc
fflush
strcpy
__printf_chk
setlocale
fopen
ftruncate
strrchr
pipe
__isoc99_sscanf
getpwuid
ftell
signal
strncpy
__stack_chk_fail
mkdir
realloc
stdin
memchr
strpbrk
strdup
strtod
strtok
strtol
isatty
fgets
calloc
strlen
strstr
strcspn
tcsetattr
fseek
memcmp
poll
__fprintf_chk
stdout
fputc
fputs
memcpy
fclose
strtoul
malloc
__ctype_b_loc
stderr
ioctl
__memset_chk
__fxstat
fileno
utimes
fwrite
fread
gettimeofday
rename
geteuid
clock_gettime
localtime
strchr
tcgetattr
__cxa_finalize
fcntl
fsetxattr
__xstat
memmove
strcmp
__libc_start_main
ferror
_edata
__bss_start
_end
GLIBC_2.2.5
OPENSSL_1_1_0
GLIBC_2.4
GLIBC_2.3
GLIBC_2.7
GLIBC_2.17
GLIBC_2.14
GLIBC_2.3.4
D$x1
\$pH
D$`H
D$PH
T$xdH3
[]A\A]
D$PD
|$(H
|$`H
u+UH
AWAVA
D$H1
t8H9
L$HdH3
X[]A\A]A^A_
|$(H
|$0H
](XZH
T$0H
tJL;|$
H+L$
T$0L
H+l$
L9|$
D$01
T$0H
T$0H
T$0H
AWAVAUATUH
dH3<%(
([]A\A]A^A_
filenameH
t	I9
L94$t
filename
AWAVAUI
4$dH
[]A\A]A^A_
l$@L
HcC<E
-=O=
C<H9,$t
AUATI
[]A\A]A^
AVE1
[]A\A]A^A_
AUATUSH
t9f.
[]A\A]
AWAVAUATUSH
[]A\A]A^A_
T$0H
L$8L
D$@L
)D$P
)L$`
)T$p
[]A\
ATUSH
u[[]A\A]A^
[]A\A]A^
[]A\A]A^
\$XH
D$(1
D$(dH3
"tOA
t'A8
"t@D
}'H)
[]A\A]
T$ D
D$8%
AVAUATU
|$XH
D$hH
L$pH
D$x@
t$SdH
D$xH
D$hH
D$8H
D$Hf
D$0H
|$0H
|$ H
D$ 1
L$@H
D$pH
L$(H
D$hH
L$`H
D$xH
L$ H
[]A\A]A^A_
D$(H
l$SD8t$Su
|$ L
D$ E1
L$XH
L$8H
T$HH
D$@H
H+L$H
H+T$8H
\$@H
l$SD8
\$(H9D$(r
L$XH
T$0H
D$`H
\$`H9D$`r 
L$TH
T$0H
\$0H;D$0w!
T$(H
D$XH
T$`H
D$XH
D$XH
L$XH
D$pH
D$XH
D$XH
D$pH
AVAUI
D$x1
D$HH
@u	E
D$PE1
t$PH
t$`H
t$XH
t$hH
D$ H
L$xdH3
[]A\A]A^A_
D$pH
L$PE1
T$HPL
AYAZ
t$XH
D$pH
L$P1
T$HPH
D$pPL
L$pL
D$XL
|$(E1
d$pH
D$PH
D$HH
D$`H
D$hH
l$8I
t$PH
t$`H
t$XH
t$hH
T$HH
T$HATAWL
L$(L
D$ H
D$(L
D$41
|$(H
l$8M97t
L$PH
T$H1
D$HH
D$pE1
D$pPL
t$PH
T$P1
l$8H
D$HH
|$(H
l$8M97t
|$(I
M97t
|$(I
M97t
|$(I
M97t
|$(I
M97t
|$(H
l$8I
|$(I
M97t
AVAUI
 []A\A]A^
AWAVAUATI
[]A\A]A^A_
<:t[<\u
<:tvA
\<\tr
AWAVAUATUH
t$8H
L$(L
D$0dH
t$ I
\$'H
l$8L
|$(H
L$8H
<WwKH
[]A\A]A^A_
t$ A
D$'A
D$'E	
D$'E
D$ E	
T$8H
D$xH
|$xL
D$8H
L$xH
t$pH
L$8H
L$@H
D$HA
D$xH
D$(E	
t$(H
|$(H
D$'H
t$hH
|$'H
D$pH
|$(H
L$x1
D$'E	
D$'E	
D$'E	
|$(H
L$xH
D$xE	
D$(H
D$(H
L$(H
D$(E	
D$(H
D$(H
L$(H
|$(H
D$(E	
D$'E	
D$'E	
D$'E	
KH@E	
KH E	
D$'E	
D$'E	
D$'E	
D$'E	
CHE	
CHE	
D$'E	
D$'E	
|$(H
L$xH
D$xE	
D$'E	
D$'E	
L$(H
D$'E	
D$'E	
t$xH
|$pD
|$pD
D$@H
t$xH
|$pH
D$pH
T$xH
|$pH
D$@H
T$XH
D$HH
t$PH
T$XH
L$@H
|$8I
D$HH
D$xH
D$8H
|$xH
|$(H
|$(H
|$(H
D$(E	
D$pH
|$(H
|$8H
D$HH
D$pH
L$8H
D$HH
D$HH
T$@H
D$pH
t$xH
|$(H
D$8H
|$(H
|$(H
D$PH
l$HH
D$@E
t$xH
|$pH
D$pH
|$(H
|$(H
|$pL
|$pH
D$'E	
D$'E	
|$(H
t$xH
D$(H
D$(H
L$(H
D$'D
D$'E	
D$'E	
D$'E	
D$(H
D$'E	
|$(H
D$'E	
|$(H
|$(H
D$'E	
T$xH
t$pH
L$xAi
D$'E	
D$'E	
|$81
AXAY
D$'E	
D$'E	
~!E	
|$(H
D$'E	
D$'E	
L$'E	
D$'E	
D$'E	
D$'E	
D$'E	
D$'E	
D$'E	
D$'E	
D$'E	
D$'E	
D$'E	
D$'E	
AWAVAUATUSH
D$(1
D$'I
tPIc
\$(dH3
8[]A\A]A^A_
D9L$
5cz"
[]A\A]
[]A\A]
[]A\
ATUS
[]A\
D$(1
L$(dH3
ATUSH
D$(1
D$ H
D$(dH3
D$(dH3
0[]A\
D$(dH3
[]A\
D$x1
D$@H
D$HH
D$xdH3
[]A\
+t$ 
AWAVAUATUSH
[]A\A]A^A_
AWAVAUATUSH
L$h1
T$P1
|$hH
t$pH
t$HH
\$8L
T$^H
D$ H
tpE1
d$0M
T$^I
t$ L
|$(H
\$8H
K "H
\$8H
\$pH
dH34%(
[]A\A]A^A_
D$pH
T$PH
T$PH
T$PH
[]A\
[]A\
tmSH
tE< t
AUATI
[]A\A]
AVAUI
ATUL
L9$$
H+l$
([]A\A]A^A_
([]A\A]A^A_
T$0H
L$8L
D$@L
)D$P
)L$`
)T$p
D$ H
T$0H
L$8L
D$@L
)D$P
)L$`
)T$p
D$ H
T$0H
L$8L
D$@L
)D$P
)L$`
)T$p
AUATUSH
D$GH
D$ H
D$ H
D$0H
D$`H
D$ H
D$ H
D$PtOH
t$PH
D$PH
D$HH
D$ H
)C H
D$XE
l$(M
D$@H
L$8H
t3Mc
)C H
\$ H
D$FH
|$(A
D$GA
[]A\A]A^A_
t$0L
D$FA
D$GA
D$0H
D$ H
T$(H
L$HH9
L$H1
D$ H
D$ H
\$ H
D$(H
L$HM
L$(M
L$8M
L$0M
L$@H
L$xM
t$8H
D$hH
D$xD
l$\L
T$hL
D$pI
t$8u
t$8u
l$\L
t$81
T$h1
t$8A
T$h1
l$\L
L$8I
D$0I
L$8H
$t-H
D$0I
L$8H
L$8A
L$8A
L$8H
L$8H
L$8I
D$0I
t$8D
l$\A
D$0H
L$hH
L$XH
D$8L
T$8A
L$ A
[]A\
[]A\
[]A\
[]A\
tGSH
AVAUI
]A\A]A^
ATUH
t*I9
AWAVAUATUSH
[]A\A]A^A_
<$;t
AUATI
,$H9
[]A\A]
AWAVAUATI
[]A\A]A^A_
ATUSH
[]A\A]A^A_
[]A\A]A^A_
t"SH
AUATUSH
<$"t]f
([]A\A]
AWAVAUATI
<=t&<+
[]A\A]A^A_
tmH	E
ATUSH
,$H9
[]A\
[]A\
[]A\
[]A\A]
[]A\A]
AWAVAUATUSH
t$(dH
D$ H
[]A\A]A^A_
D$ H
L$(L
D$ H
D$ H
L$(1
T$?E1
t$ I
t$(I
D$ H
t:<n
<tt,<vA
<#v5H
l$@I
AVAUATI
[]A\A]A^
A\A]A^
AVAUI
[]A\A]A^
AWAVAUI
ATE1
([]A\A]A^A_
P<\t
t$H;k
[]A\A]
[]A\A]
D$X1
|$XdH3<%(
`[]A\A]A^
D$X1
\$XdH3
`[]A\A]A^
[]A\
[]A\
AUATE
D$ H
D$(A
\$0L
L9,$
[]A\A]A^A_
D$(H
D$(L
l$0H
AVAUI
ATE1
x;Hc
]A\A]A^
AWAVAUI
ATUSH
|$0H
T$(H
L$8dH
tS<{tO<[
<\t4
]t:A
L$VH
T$UL
D$WH
D$XH
D$XI9
t'<	t
L$XH
L$@A
D$(H
[]A\A]A^A_
Hct$
|$8H
T$ Hc
D$(H
t$ H
D$0L
D$W<:
t$VL
t$ Hc
\$`H
L$XM9
t$V@8
|$ 1
D$HL
L$XM
L$@L
AWAVI
AUATUSH
[]A\A]A^A_
t1HcU
[]A\A]A^A_
p H;p
@:p	~
AWAVAUATUSH
t$(H
L$H1
L$(E1
L$0H
D$(N
<3M9
tX<#u
|$(H
L$(L
L$HdH3
X[]A\A]A^A_
\$ L
D$ H
D$(1
|$(dH3<%(
AWAVAUATUSH
D$81
D$8dH3
H[]A\A]A^A_
D$(H
T$ H
D$0H
D$0H
D$0H
T$(H
T$(H
|$ H
AWE1
AVAUI
ATU1
D$81
D$(H
D$0H
t$(M
L$8dH3
H[]A\A]A^A_
T$(1
T$(E1
T$0A
L;4$t
[]A\A]A^
[]A\A]A^A_
=> Send SSL data
=> Send header
<= Recv header
<= Recv data
<= Recv SSL data
=> Send data
%02d:%02d:%02d.%06ld 
Failed to create/open output
%s%s 
[%zu bytes data]
%s== Info: %s
%s%s, %zu bytes (0x%zx)
%04zx: 
%02x 
Content-disposition:
filename=
[1m%.*s
[0m:
%%-%ds %%5.1f%%%%
COLUMNS
Y@Remote filename has no length!
Failed to create the file %s: %s
Binary output can mess up your terminal. Use "--output -" to tell curl to output it to your terminal anyway, or consider "--output <FILE>" to save to a file.
Refusing to overwrite %s: %s
Error creating directory %s.
You don't have permission to create %s.
The directory name %s is too long.
%s resides on a read-only file system.
No space left on the file system that will contain the directory %s.
Cannot create directory %s because you exceeded your quota.
hnd = curl_easy_init();
ret = curl_easy_perform(hnd);
curl_easy_cleanup(hnd);
hnd = NULL;
  return (int)ret;
  %s
   them yourself.
#include <curl/curl.h>
  CURLcode ret;
  CURL *hnd;
/* Here is a list of options the curl code used that cannot get generated
 * All curl_easy_setopt() options are documented at:
/********* Sample code generated by the curl command line tool **********
Failed to open %s to write libcurl code!
/**** End of sample code ****/
   as source easily. You may select to either not use them or implement
 * https://curl.haxx.se/libcurl/c/curl_easy_setopt.html
 ************************************************************************/
int main(int argc, char *argv[])
Failed to get filetime: %s
Failed to set filetime %ld on outfile: %s
type=
%127[^/ ]/%127[^;, 
Cannot read from %s: %s
skip unknown form field: %s
headers=
encoder=
curl_mime_init failed!
out of memory
curl_mime_addpart failed!
curl_mime_subparts failed!
curl_mime_headers failed!
curl_mime_type failed!
no multipart to terminate!
setting file %s  failed!
curl_mime_filename failed!
curl_mime_encoder failed!
setting file %s failed!
curl_mime_data failed!
curl_mime_name failed!
Illegally formatted content-type field!
Out of memory for field headers!
Header file %s read error: %s
File %s line %d: header too long (truncated)
Out of memory for field header!
Field file name not allowed here: %s
Field encoder not allowed here: %s
garbage at end of field specification: %s
Illegally formatted input field!
invalid number specified for %s
unsupported %s unit. Use G, M, K or B!
The file name argument '%s' looks like a flag.
--trace overrides an earlier trace/verbose option
--trace-ascii overrides an earlier trace/verbose option
--metalink option cannot be used because the version of the linked libmetalink library is too old. Required: %d.%d.%d, found %d.%d.%d
--test-event is ignored unless a debug build!
Couldn't read data from file "%s", this makes an empty POST.
--include and --remote-header-name cannot be combined.
error trying read config from the '%s' file
A specified range MUST include at least one dash (-). Appending one for you!
Invalid character is found in given range. A specified range MUST have only digits in 'start'-'stop'. The server's response to this request is uncertain.
-v, --verbose overrides an earlier trace/verbose option
Illegal date format for -z, --time-cond (and not a file name). Disabling time condition. See curl_getdate(3) for valid date syntax.
pkcs11:
<stdin>
Failed to open %s!
max-filesize
%d - %d
bad range input
%.*s=%s
;auto
unsupported range point
%ld-
Failed to read %s
list
--url
option %s: %s
dns-ipv4-addr
dns-ipv6-addr
random-file
egd-file
oauth2-bearer
connect-timeout
dns-interface
disallow-username-in-url
dns-servers
trace
trace-ascii
limit-rate
max-redirs
krb4
ftp-ssl
socks5
retry
retry-delay
retry-max-time
ftp-account
ftp-method
local-port
socks4
socks4a
ftp-alternative-to-user
ftp-ssl-reqd
ftp-ssl-ccc-mode
libcurl
socks5-hostname
keepalive-time
noproxy
proxy1.0
tftp-blksize
mail-from
mail-rcpt
proto
proto-redir
resolve
delegation
mail-auth
test-event
socks5-gssapi-service
proxy-service-name
proto-default
expect100-timeout
connect-to
abstract-unix-socket
tls-max
suppress-connect-headers
happy-eyeballs-timeout-ms
proxy-tls13-ciphers
user-agent
cookie
cookie-jar
continue-at
data-raw
data-ascii
data-binary
data-urlencode
dump-header
referer
engine
hostpubmd5
login-options
proxy-pinnedpubkey
proxy-tlsuser
proxy-tlspassword
proxy-tlsauthtype
proxy-cert
proxy-cert-type
proxy-key
proxy-key-type
proxy-pass
proxy-ciphers
proxy-crlfile
proxy-cacert
proxy-capath
form
form-string
proxy-header
config
netrc-file
ftp-port
telnet-option
upload-file
proxy-user
write-out
preproxy
speed-limit
speed-time
time-cond
/dev/tty
    --anyauth
 %-19s %s
2018-09-05
Release-Date: %s
Protocols: 
Features: 
Metalink 
Build-time engines:
  <none>
AsynchDNS
Debug
TrackMemory
IPv6
Largefile
SSPI
GSS-API
Kerberos
SPNEGO
libz
brotli
CharConv
TLS-SRP
HTTP2
UnixSockets
HTTPS-proxy
MultiSSL
-a, --append
    --basic
Use HTTP Basic Authentication
    --cacert <file>
    --capath <dir>
    --cert-status
    --cert-type <type>
SSL ciphers to use
    --compressed
Request compressed response
    --compressed-ssh
Enable SSH compression
-K, --config <file>
Read config from a file
Connect to host
-C, --continue-at <offset>
Resumed transfer offset
-b, --cookie <data>
Send cookies from string/file
-c, --cookie-jar <filename>
    --create-dirs
    --crlf
Convert LF to CRLF in upload
    --crlfile <file>
-d, --data <data>
HTTP POST data
    --data-ascii <data>
HTTP POST ASCII data
    --data-binary <data>
HTTP POST binary data
    --data-raw <data>
HTTP POST data, '@' allowed
    --data-urlencode <data>
HTTP POST data url encoded
    --delegation <LEVEL>
GSS-API delegation permission
    --digest
-q, --disable
Disable .curlrc
    --disable-eprt
Inhibit using EPRT or LPRT
    --disable-epsv
Inhibit using EPSV
Disallow username in url
    --dns-ipv4-addr <address>
    --dns-ipv6-addr <address>
    --dns-servers <addresses>
DNS server addrs to use
-D, --dump-header <filename>
    --egd-file <file>
    --engine <name>
Crypto engine to use
-f, --fail
    --fail-early
    --false-start
Enable TLS False Start
-F, --form <name=content>
Specify multipart MIME data
    --ftp-account <data>
Account data string
String to replace USER [name]
    --ftp-create-dirs
    --ftp-method <method>
Control CWD usage
    --ftp-pasv
Use PASV/EPSV instead of PORT
-P, --ftp-port <address>
Use PORT instead of PASV
    --ftp-pret
Send PRET before PASV
    --ftp-skip-pasv-ip
Skip the IP address for PASV
    --ftp-ssl-ccc
Send CCC after authenticating
Set CCC mode
    --ftp-ssl-control
-G, --get
-g, --globoff
    --haproxy-protocol
-I, --head
Show document info only
-H, --header <header/@file>
-h, --help
This help text
    --hostpubmd5 <md5>
-0, --http1.0
Use HTTP 1.0
    --http1.1
Use HTTP 1.1
    --http2
Use HTTP 2
    --http2-prior-knowledge
    --ignore-content-length
-i, --include
-k, --insecure
    --interface <name>
-4, --ipv4
-6, --ipv6
-j, --junk-session-cookies
    --key <key>
Private key file name
    --key-type <type>
    --krb <level>
    --libcurl <file>
    --limit-rate <speed>
Limit transfer speed to RATE
-l, --list-only
List only mode
    --local-port <num/range>
-L, --location
Follow redirects
    --location-trusted
    --login-options <options>
Server login options
    --mail-auth <address>
    --mail-from <address>
Mail from this address
    --mail-rcpt <address>
Mail to this address
-M, --manual
Display the full manual
    --max-filesize <bytes>
Maximum file size to download
    --max-redirs <num>
-m, --max-time <seconds>
    --metalink
    --negotiate
-n, --netrc
    --netrc-file <filename>
Specify FILE for netrc
    --netrc-optional
Use either .netrc or URL
-:, --next
    --no-alpn
-N, --no-buffer
    --no-keepalive
    --no-npn
Disable the NPN TLS extension
    --no-sessionid
    --noproxy <no-proxy-list>
    --ntlm
Use HTTP NTLM authentication
    --ntlm-wb
    --oauth2-bearer <token>
OAuth 2 Bearer Token
-o, --output <file>
    --pass <phrase>
    --path-as-is
    --pinnedpubkey <hashes>
    --post301
    --post302
    --post303
Use this proxy first
-#, --progress-bar
    --proto <protocols>
Enable/disable PROTOCOLS
    --proto-redir <protocols>
Use this proxy
    --proxy-anyauth
    --proxy-basic
    --proxy-cacert <file>
    --proxy-capath <dir>
    --proxy-cert-type <type>
    --proxy-ciphers <list>
SSL ciphers to use for proxy
    --proxy-crlfile <file>
Set a CRL list for proxy
    --proxy-digest
    --proxy-insecure
    --proxy-key <key>
Private key for HTTPS proxy
    --proxy-key-type <type>
    --proxy-negotiate
    --proxy-ntlm
    --proxy-pass <phrase>
SPNEGO proxy service name
    --proxy-ssl-allow-beast
TLS 1.3 proxy cipher suites
TLS password for HTTPS proxy
    --proxy-tlsuser <name>
TLS username for HTTPS proxy
    --proxy-tlsv1
Use TLSv1 for HTTPS proxy
Proxy user and password
    --proxy1.0 <host[:port]>
-p, --proxytunnel
    --pubkey <key>
SSH Public key file name
-Q, --quote
    --random-file <file>
-r, --range <range>
    --raw
-e, --referer <URL>
Referrer URL
-J, --remote-header-name
-O, --remote-name
    --remote-name-all
-R, --remote-time
-X, --request <command>
    --request-target
    --retry <num>
    --retry-connrefused
    --retry-delay <seconds>
Wait time between retries
Retry only within this period
    --sasl-ir
    --service-name <name>
SPNEGO service name
-S, --show-error
-s, --silent
Silent mode
    --socks4 <host[:port]>
    --socks4a <host[:port]>
    --socks5 <host[:port]>
    --socks5-basic
    --socks5-gssapi
    --socks5-gssapi-nec
-Y, --speed-limit <speed>
-y, --speed-time <seconds>
    --ssl
Try SSL/TLS
    --ssl-allow-beast
    --ssl-no-revoke
    --ssl-reqd
Require SSL/TLS
-2, --sslv2
Use SSLv2
-3, --sslv3
Use SSLv3
    --stderr
Where to redirect stderr
    --styled-output
    --tcp-fastopen
Use TCP Fast Open
    --tcp-nodelay
Use the TCP_NODELAY option
-t, --telnet-option <opt=val>
Set telnet option
    --tftp-blksize <value>
Set TFTP BLKSIZE option
    --tftp-no-options
Do not send any TFTP options
-z, --time-cond <time>
    --tls-max <VERSION>
Use TLSv1.0 or greater
TLS 1.3 cipher suites to use
    --tlsauthtype <type>
TLS authentication type
    --tlspassword
TLS password
    --tlsuser <name>
TLS user name
-1, --tlsv1
    --tlsv1.0
Use TLSv1.0
    --tlsv1.1
Use TLSv1.1
    --tlsv1.2
Use TLSv1.2
    --tlsv1.3
Use TLSv1.3
    --tr-encoding
    --trace <file>
Write a debug trace to FILE
    --trace-ascii <file>
    --trace-time
    --unix-socket <path>
-T, --upload-file <file>
    --url <url>
URL to work with
-B, --use-ascii
Use ASCII/text transfer
-u, --user <user:password>
Server user and password
-A, --user-agent <name>
-v, --verbose
-V, --version
Show version number and quit
-w, --write-out <format>
    --xattr
Connect via abstract Unix domain socket
    --abstract-unix-socket <path>
Usage: curl [options...] <url>
curl 7.61.1 (x86_64-redhat-linux-gnu) %s
Pick any authentication method
Append to target file when uploading
CA certificate to verify peer against
CA directory to verify peer against
-E, --cert <certificate[:password]>
Client certificate file and password
Verify the status of the server certificate
Certificate file type (DER/PEM/ENG)
    --ciphers <list of ciphers>
    --connect-timeout <seconds>
Maximum time allowed for connection
    --connect-to <HOST1:PORT1:HOST2:PORT2>
Write cookies to <filename> after operation
Create necessary local directory hierarchy
Get a CRL list in PEM format from the given file
Use HTTP Digest Authentication
    --disallow-username-in-url
    --dns-interface <interface>
Interface to use for DNS requests
IPv4 address to use for DNS requests
IPv6 address to use for DNS requests
Write the received headers to <filename>
EGD socket path for random data
    --expect100-timeout <seconds>
How long to wait for 100-continue
Fail silently (no output at all) on HTTP errors
Fail on first transfer error, do not continue
    --form-string <name=string>
    --ftp-alternative-to-user <command>
Create the remote dirs if not present
    --ftp-ssl-ccc-mode <active/passive>
Require SSL/TLS for FTP login, clear for transfer
Put the post data in the URL and use GET
Disable URL sequences and ranges using {} and []
    --happy-eyeballs-timeout-ms <milliseconds>
How long to wait in milliseconds for IPv6 before trying IPv4
Send HAProxy PROXY protocol v1 header
Pass custom header(s) to server
Acceptable MD5 hash of the host public key
Use HTTP 2 without HTTP/1.1 Upgrade
Ignore the size of the remote resource
Include protocol response headers in the output
Allow insecure server connections when using SSL
Use network INTERFACE (or address)
Resolve names to IPv4 addresses
Resolve names to IPv6 addresses
Ignore session cookies read from file
    --keepalive-time <seconds>
Interval time for keepalive probes
Private key file type (DER/PEM/ENG)
Enable Kerberos with security <level>
Dump libcurl equivalent code of this command line
Force use of RANGE for local port numbers
Like --location, and send auth to other hosts
Originator address of the original email
Maximum number of redirects allowed
Maximum time allowed for the transfer
Process given URLs as metalink XML file
Use HTTP Negotiate (SPNEGO) authentication
Must read .netrc for user name and password
Make next URL use its separate set of options
Disable the ALPN TLS extension
Disable buffering of the output stream
Disable TCP keepalive on the connection
Disable SSL session-ID reusing
List of hosts which do not use proxy
Use HTTP NTLM authentication with winbind
Write to file instead of stdout
Pass phrase for the private key
Do not squash .. sequences in URL path
FILE/HASHES Public key to verify peer against
Do not switch to GET after following a 301
Do not switch to GET after following a 302
Do not switch to GET after following a 303
    --preproxy [protocol://]host[:port]
Display transfer progress as a bar
    --proto-default <protocol>
Use PROTOCOL for any URL missing a scheme
Enable/disable PROTOCOLS on redirect
-x, --proxy [protocol://]host[:port]
Pick any proxy authentication method
Use Basic authentication on the proxy
CA certificate to verify peer against for proxy
CA directory to verify peer against for proxy
    --proxy-cert <cert[:passwd]>
Set client certificate for proxy
Client certificate type for HTTPS proxy
Use Digest authentication on the proxy
    --proxy-header <header/@file>
Pass custom header(s) to proxy
Do HTTPS proxy connections without verifying the proxy
Private key file type for proxy
Use HTTP Negotiate (SPNEGO) authentication on the proxy
Use NTLM authentication on the proxy
Pass phrase for the private key for HTTPS proxy
    --proxy-pinnedpubkey <hashes>
FILE/HASHES public key to verify proxy with
    --proxy-service-name <name>
Allow security flaw for interop for HTTPS proxy
    --proxy-tls13-ciphers <ciphersuite list>
    --proxy-tlsauthtype <type>
TLS authentication type for HTTPS proxy
    --proxy-tlspassword <string>
-U, --proxy-user <user:password>
Use HTTP/1.0 proxy on given port
Operate through an HTTP proxy tunnel (using CONNECT)
Send command(s) to server before transfer
File for reading random data from
Retrieve only the bytes within RANGE
Do HTTP "raw"; no transfer decoding
Use the header-provided filename
Write output to a file named as the remote file
Use the remote file name for all URLs
Set the remote file's time on the local output
Specify request command to use
Specify the target for this request
    --resolve <host:port:address[,address]...>
Resolve the host+port to this address
Retry request if transient problems occur
Retry on connection refused (use with --retry)
    --retry-max-time <seconds>
Enable initial response in SASL authentication
Show error even when -s is used
SOCKS4 proxy on given host + port
SOCKS4a proxy on given host + port
SOCKS5 proxy on given host + port
Enable username/password auth for SOCKS5 proxies
Enable GSS-API auth for SOCKS5 proxies
Compatibility with NEC SOCKS5 server
    --socks5-gssapi-service <name>
SOCKS5 proxy service name for GSS-API
    --socks5-hostname <host[:port]>
SOCKS5 proxy, pass host name to proxy
Stop transfers slower than this
Trigger 'speed-limit' abort after this time
Allow security flaw to improve interop
Disable cert revocation checks (WinSSL)
Enable styled output for HTTP headers
    --suppress-connect-headers
Suppress proxy CONNECT response headers
Transfer based on a time condition
    --tls13-ciphers <list of TLS 1.3 ciphersuites>
Request compressed transfer encoding
Like --trace, but without hex output
Add time stamps to trace/verbose output
Connect through this Unix domain socket
Transfer local FILE to destination
Send User-Agent <name> to server
Make the operation more talkative
Use output FORMAT after completion
Store metadata in extended file attributes
unknown error
is ambiguous
requires parameter
is badly used here
out of memory
too large number
is unknown
GET (-G, --get)
HEAD (-I, --head)
POST (-d, --data)
HEAD
had unsupported trailing garbage
expected a proper numerical parameter
expected a positive numerical parameter
the installed libcurl version doesn't support this
a specified protocol is unsupported by libcurl
the given option can't be reversed with a --no- prefix
multipart formpost (-F, --form)
You can only select one HTTP request method! You asked for both %s and %s.
Unnecessary use of -X or --request, %s is already inferred.
Setting custom HTTP method to HEAD with -X/--request may not work the way you want. Consider using -I/--head instead.
CURL_HOME
1.2.11
JZQe
oDd&
61^T
NL_MYN
9>92
+M|VV
ra&<
Q6-o{
YeVvt
MS"&
9*~:
J~:C+
0kjm
uCA4*>
wwv~
ZB#F7
75c8
|4JG
/LzS
sPe`
0axmv
s3o'
j.gm
A&E:3'
afam
3C<7
e	Hr
0y{tqt
$7+]
v[H6
Ugh8
%g[xowg
IW4#1
9^0}
n~v:
^,2(
e<cCO
&NHt
AU91
=='	M
\g/j
AARP
EM;L#
q2]O
/tqOV
jQe|G
 Q|1
7U>_6:
"@-J
Ig5;
0Rt>
@1jJ6
/"Fd
d_b{[I
VaXt
+3Dn
Ns##
"{Ok@
wk9%
6's6
fID>E
$rui
NO]I
lQd66x
?~[3g
'[	C
fnc#b
sFr)E
.fT|p
!7t.v
c:HN
;.]f
h|w"
i9NE`qMO
|LI#FnD
k+@y
#at%
p}ac
<M?K
T4gC
%DfL
uzw7
^DfK
UUzbp
XRfw>
8E8y
!s!R
|sj^
: w([Md
]gD:
34=.f
kj+tQv
yJf{NH*mt5
Axa}
qOII
B"x$
$yc 
>rhX
D)zr
=;?%
0_@.
<&n	
!RG4N
&^Cd
\ZIvRd6D
44-Li}
U4j~
84A^
"\+U
"3<B
OG\{z+
z<RK&
eyyYgM
IAb`/
ZbBH-E
< =mS
ypq0V#
4"\n
}=f2'
!@dv/
Dx@0F
5|Y4
u9eU;
]On|
kIEF
\[1F?
dld_
mVp6&)
iftoq
8L?2
AnS7
C`$0
*HPp
/WXt&92
no$Dk[
1;Ar
-3L,
K6czo
F_Ff#%
Qy?Q
^"[E>
aUX"
W$]|%
gSd;4;
a!B?i
b_(Wn5"
|C$^
$o*W
3G 9
W&JF2
se3|Y
N_}j
!7y| "
52jW
QoZJ
_\%[
t7vT>FJ
u#+$=i
N"xc
8bXx
/(l?
mm00
%$,R
:!6]
FBr8
zuQ1
PQ55
mv@O
X6BH
Yx[2
FzqF
,0k;
pLmE
)u%r
u2vX
_A4`
'O"t
,KX"
k&AN
mTdvC[
BT,x_EAh
0mJ4
y8<	
{ lzz
41:(
W&0)=D+
4Yk\XhD
RS/`
A[d6yV
uw\|N:#
/'Y:
*Rb^
0F$r
>eW8
HUT$
8`VeBu
\6aFPH
Jf0G
_a7^
WQ45
bL"*L
*VnL
yCCSYf
dTc yM
\9uQ
@_LT
 *</
5wW/
LyM^
8%)Z
N3[hy
nyU",4
kfVSVn
Hka6
fd*A]
{h=5M
+z\u
d00l
NH5~
W<jU
,3"I
=aV;a
'{MDK{?T
6n/n
XZMlRi(
BCBq
lXC,
pD ^
gO>7
|	xe3
fl9>Fk
Fr@8
_#Mm
]&CH
}6)YI
Ib.UT0R
lKsZ
ke	Aj
5~!c\
3#J[
L}>F
T:yw
HEnn
f5S5?e
!eQhB
A~{t
3>YK
2Gt]
@]`[
:y93
zUVf
T6G\
6Co#
ZiCx*
)kHa
3nD.{
&k$yL#
D4&IL
g*)f
'Ysw
>"BI
v\#1
{Vl)_
vNz1
Jd`$
'xJb,
;#r2Z
mA2Bd[Y
%.f	
7+\4
3ZW[
lVE;K
YG?rW
x1k`
VS+5
rAtfF
1'~~U
V5J$+k
d-p,
HxRp"
g^u	
h	9j
]"Va
{=_.
(U}g
{.nm
uNp~
I>	 _D
>p|Z
dh%pd
x/oq
ZDs=
IYM" 
U5J^N
%9=G\
eUYwk
Iz i
wYO"
:;={
P,b7
kA\c
B1$C
-Eg%
tDWg
p8;{
:mRu
`BPu
jie,
r /Kl
FXXj+
NsO~
]kwkYz
[k+7m;a
-lR9
.gm3jq
K`YE
:^sH
'ED*
T%wy\d4
zkIA
Yd)q
~gws"
,&Fr8%
#Ztu
-Gb	"
 on^/)
IlDW
BZs4
0 ip
F)h9
r0j+
2|(=
IpBt.
`WYV
dqum|E3
wIv'.D
XpX(~
8u))
Qx	m
q] e
FiBM.
)'dF
ox\v
VMlA
0!}S
zwQs
5"^S
ek9S
\d 9"
;[v7
nP<$
u|<Ln
QJC*5
0c4r
<;.>
-5IB
tq/9A
!Q~:
#;ZG8
6nK~Yl<
R^;7
*[5F
g,Uy
#.%E	
n+NU
jAYi
Nu,X
r'[|
K<1!
,gP3
VXV]5/L;
IZ&A
Lw<z
*[R4
mp4V
s&C&
OOwhO
o!{/u
#x`,
z\Qm.)V
Ke,_>
uhw 
@We\4
[=d4g
#ueqv
n/8*
All}
cz|_(
u+I+o
Augi
0b6"0btD#
|o +
5e><
@FrY
";T|
,ydR
OGb/
_FNw^
oXiR
!6"q
EWkind
hS7=
J  a
97+y
&[u;L
 9'A
8&r-@
-MQ^
7t8b
FfXE
$!-Ni
srL7Uw
V)U_^pRc
e4>G
Ifave
$pSQ
>lYVy
o\~I
HD	*
[4J8T
eS.:6
X.4'X[
yc9uuS
0s1s% 
__Us
s*tD
zVN(
+{p-
<3,W
^?-|
&AQpo
f;@|
mz_G
I|Ivz
s]zu9B
pe\Ij
4#_]
aV%g
wGJl
6O;k
6X^-<:
s5D8=
9//j9
=n=-r
5]m6
a1M+
j?6BG
]lIr
C6z}
d2;;?={s
u/9<=
K/y{
x~tq>H6}
:\G(8
:ZY7
2FL7
GW	 	
K:#b
h$QrDiQ
FK>g*
YUvM
|KqH
7yid
fuz!
	5/8
fgwf
>Nbo
s{f	
O:XY+
WbL"pBxb[
n]75E
yE1Xz
pu]\
zA?k
+|P'
~	701
7.gsx^pMj
IfCW
is6q
W:Y)
b(t:
"o'S3
*e{lak
y7btII
N.@V
I6Z\i
;}}tr
jq^e-
MNA 
v[aw
=Fm.
rV'jc
!qL:
U,}T
{n/|
qEgv
=PD#
}O5U
R|C\08lA9
et8lKj
Q<<E
s\1I?
"2M7
D;$M
e[%A,
#,~o
5wB=*
"`_SV
$5Aw
_/fiQ
wH!0
_K&k
EF>WTD@1
?/|r
85#ZF
N 6m
K^-}
a`vu-
sA/2
AW ms
R\x9
<R2 
/:UM5
5,c\
hRx=
VAr$
tQAW]
K6^n
~-N'
#	@l3
nS|d
pf Vk;=
(cYaf
tyst
w`}_
E*or
#sc{
\d_h
~@fX
E|5I8Q
&#Hl
B-?0
[,^$
C>O:4y|F
v_E5
c-Cz
).f'
J6gL
cnv~V
[if@
_,a~
d)7mb
	[18
1H||
Cw x:
tjdo
=dJR
)d'Za
H`$'/.
Y^\ 4
nr5(
9jkt
vg ]
%,YV
9Y5<
)DbNF
3)/OY9kv
Yo^?
]`XH?
vB}+
$JcL
pYiy
D& ~
\p|H
\F}Uc$n
TSkVX^1
CLhki
eep0;
 DTOf
F]!.
En	O
7BL5
%rA*
4TDF
h	J9a
0$	q
z]=s
WYAJ
lYWi
dxqz
,pvz~
R*JC
`]:Y7
^:>9r;
\k|P
>sM]R
9T@3@
s1vP
-ibR
sU	4
	Jc3
QW	p
3	^U
yAf	
'TeT
mpxb%
rt@.
'7<&
|3$t,L
}7b"H
AY]m
ybdn
kEq>
hghF
/?dvc
&OwG
\u=.
	eT|.
M	rD+e
]!y^r
*!0=FO
0:M*
.jK9f
$?h5 
9@Bs
FJLHeB
ncUi
D1S6
kI& xI
Qh&0'w^
-5Ks
zV<3
^iU9
C@]=
/^,c
}ztY
M"]r78
\1B:
EFJ*
2e9H
l`|,I
RL:7
'?/C
q|eS
l.5_T
EN]4
!"ze9
uWBm}~m
Em&/
 =q~Z
EF~m
j9I9>
e+A^,
Bsy%
E7W7q
5_1?Q
&[8X
".pF
8vt/v
e_q{
Gz0[
xm)S>
6h	6z
:,	5
,\<,
:mh+,
`zNn
!/^<
yjBK
6,2d
iax$Ac
M,Pk1v
6zvst
[=+r
zKbd
T$uU
NhU(`
FomT
&.fm
0y{t
!jH@z
W)#=D
97#P
}~CdN
cF u
6bg9
0Q]{O
ySVc
RoesEy
v uf
>K8;
e-aQ
	o-a
:--Y	Q
Fg(o%
(xo3
CLO`
(;.gR
'd g
h.>I3NS
B{	{j
$-!z
S/n2
@'Jg
\2b5\
%:]S*
-ffX
H2xt
`|AI
4Ic`g
$ c\Z
I"N9
vAVX
vIYGa
L[I.
M~o#
 [/(
v`Rk
J*356
#nYZ
#}7H
,>n{
MDR@X
wL$H[
"-.S
qtG2
_sN?
3MG\
	JW_
8~{D
	'n(H
e>|_
eo^Q
]W2l-D
7PB!/"
j9L[
-F=2
d}}p
>3B8`\
3iL-
9BNp
=o~92
&OtF
FSQF
C-OP*L34
T/Ch
`//.Zu
>h--
H[nP
`_tQ
waDH
<#c*
lDjYw
f,rAh
mkY*
PBPe
Y	XQ
l#)8
5URE
|Sbn
B;O@
l7hCpv
5KAiQ9
F;z. 
NnwE
8Ii>?
c;+H
!]THP
lp5P
:1[9
n,:8
e	++En_
t`.Q
%~2[?
|t/V
bUi&
Z|>wO
GcjW
f7d1
dict
ftps
gopher
http
https
imap
imaps
ldap
ldaps
pop3
pop3s
rtmp
rtsp
sftp
smbs
smtp
smtps
telnet
tftp
error initializing curl easy handle
error retrieving curl library information
error initializing curl library
error initializing curl
Metalink: validating (%s) [%s] FAILED (%s)
failed to initialize hash algorithm
Metalink: validating (%s) [%s] OK
Metalink: validating (%s) [%s] FAILED (digest mismatch)
Metalink: validating (%s) FAILED (digest missing)
Metalink: parsing (%s) WARNING (missing or invalid file name)
Metalink: parsing (%s) WARNING (missing or invalid resource)
Metalink: parsing (%s) WARNING (digest missing)
Metalink: validating (%s)...
Metalink: parsing FAILED
application/metalink+xml
sha-256
sha256
sha-1
sha1
Note: 
Warning: 
curl: 
curl: try 'curl --help' or 'curl --manual' for more information
<stdout>
no URL specified!
CURL_CA_BUNDLE
SSL_CERT_DIR
SSL_CERT_FILE
Failed to open %s
--capath
bad output glob!
Can't open '%s'!
fcntl failed on fd=%d: %s
[%lu/%lu]: %s --> %s
--_curl_--
%s%s
CURLOPT_TCP_NODELAY
CURLOPT_WRITEDATA
CURLOPT_TCP_FASTOPEN
CURLOPT_INTERLEAVEDATA
CURLOPT_WRITEFUNCTION
CURLOPT_READDATA
CURLOPT_READFUNCTION
CURLOPT_SEEKDATA
CURLOPT_SEEKFUNCTION
CURLOPT_BUFFERSIZE
CURLOPT_URL
CURLOPT_INFILESIZE_LARGE
CURLOPT_NOPROGRESS
CURLOPT_NOBODY
CURLOPT_PROXY
CURLOPT_XOAUTH2_BEARER
CURLOPT_PROXYUSERPWD
CURLOPT_PROXYTYPE
CURLOPT_HTTPPROXYTUNNEL
CURLOPT_PRE_PROXY
CURLOPT_PROXYAUTH
CURLOPT_NOPROXY
CURLOPT_FAILONERROR
CURLOPT_REQUEST_TARGET
CURLOPT_UPLOAD
CURLOPT_DIRLISTONLY
CURLOPT_APPEND
CURLOPT_NETRC
CURLOPT_TRANSFERTEXT
CURLOPT_NETRC_FILE
CURLOPT_USERPWD
CURLOPT_LOGIN_OPTIONS
CURLOPT_RANGE
CURLOPT_ERRORBUFFER
CURLOPT_TIMEOUT_MS
CURLOPT_POSTFIELDS
CURLOPT_POSTFIELDSIZE_LARGE
CURLOPT_MIMEPOST
CURLOPT_HTTPHEADER
CURLOPT_HTTPAUTH
CURLOPT_REFERER
CURLOPT_USERAGENT
CURLOPT_FTPPORT
CURLOPT_FOLLOWLOCATION
CURLOPT_UNRESTRICTED_AUTH
CURLOPT_AUTOREFERER
CURLOPT_MAXREDIRS
CURLOPT_PROXYHEADER
CURLOPT_HEADEROPT
CURLOPT_HTTP_VERSION
CURLOPT_POSTREDIR
CURLOPT_ACCEPT_ENCODING
CURLOPT_TRANSFER_ENCODING
CURLOPT_LOW_SPEED_LIMIT
CURLOPT_LOW_SPEED_TIME
CURLOPT_MAX_SEND_SPEED_LARGE
CURLOPT_MAX_RECV_SPEED_LARGE
CURLOPT_RESUME_FROM_LARGE
CURLOPT_KEYPASSWD
CURLOPT_PROXY_KEYPASSWD
CURLOPT_SSH_PRIVATE_KEYFILE
CURLOPT_SSH_PUBLIC_KEYFILE
CURLOPT_SSH_COMPRESSION
CURLOPT_CAINFO
CURLOPT_PROXY_CAINFO
CURLOPT_CAPATH
CURLOPT_PROXY_CAPATH
CURLOPT_CRLFILE
CURLOPT_PROXY_CRLFILE
CURLOPT_PINNEDPUBLICKEY
CURLOPT_SSLCERT
CURLOPT_PROXY_SSLCERT
CURLOPT_SSLCERTTYPE
CURLOPT_PROXY_SSLCERTTYPE
CURLOPT_SSLKEY
CURLOPT_PROXY_SSLKEY
CURLOPT_SSLKEYTYPE
CURLOPT_PROXY_SSLKEYTYPE
CURLOPT_SSL_VERIFYPEER
CURLOPT_SSL_VERIFYHOST
CURLOPT_PROXY_SSL_VERIFYPEER
CURLOPT_PROXY_SSL_VERIFYHOST
CURLOPT_SSL_VERIFYSTATUS
CURLOPT_SSLVERSION
CURLOPT_SSL_FALSESTART
CURLOPT_PROXY_SSLVERSION
CURLOPT_PATH_AS_IS
%s/%sssh/known_hosts
CURLOPT_SSH_KNOWNHOSTS
CURLOPT_CRLF
CURLOPT_FILETIME
CURLOPT_QUOTE
CURLOPT_POSTQUOTE
CURLOPT_PREQUOTE
CURLOPT_COOKIE
CURLOPT_COOKIEFILE
CURLOPT_COOKIESESSION
CURLOPT_COOKIEJAR
CURLOPT_TIMECONDITION
CURLOPT_TIMEVALUE_LARGE
CURLOPT_CUSTOMREQUEST
CURLOPT_STDERR
CURLOPT_INTERFACE
CURLOPT_KRBLEVEL
CURLOPT_XFERINFOFUNCTION
CURLOPT_XFERINFODATA
CURLOPT_DNS_SERVERS
CURLOPT_DNS_INTERFACE
CURLOPT_DNS_LOCAL_IP4
CURLOPT_TELNETOPTIONS
CURLOPT_DNS_LOCAL_IP6
CURLOPT_RANDOM_FILE
CURLOPT_EGDSOCKET
CURLOPT_CONNECTTIMEOUT_MS
CURLOPT_SSL_CIPHER_LIST
CURLOPT_PROXY_SSL_CIPHER_LIST
CURLOPT_TLS13_CIPHERS
CURLOPT_PROXY_TLS13_CIPHERS
CURLOPT_FTP_USE_EPSV
CURLOPT_FTP_USE_EPRT
CURLOPT_DEBUGFUNCTION
CURLOPT_DEBUGDATA
CURLOPT_VERBOSE
CURLOPT_SSLENGINE
CURLOPT_MAXFILESIZE_LARGE
CURLOPT_IPRESOLVE
CURLOPT_USE_SSL
CURLOPT_FTP_SSL_CCC
CURLOPT_SOCKS5_GSSAPI_NEC
CURLOPT_SOCKS5_AUTH
CURLOPT_PROXY_SERVICE_NAME
CURLOPT_FTP_ACCOUNT
CURLOPT_SERVICE_NAME
CURLOPT_IGNORE_CONTENT_LENGTH
CURLOPT_FTP_SKIP_PASV_IP
CURLOPT_FTP_FILEMETHOD
CURLOPT_LOCALPORT
CURLOPT_LOCALPORTRANGE
CURLOPT_SSL_SESSIONID_CACHE
CURLOPT_HTTP_CONTENT_DECODING
CURLOPT_TCP_KEEPALIVE
CURLOPT_TCP_KEEPIDLE
CURLOPT_TCP_KEEPINTVL
CURLOPT_TFTP_BLKSIZE
CURLOPT_MAIL_FROM
CURLOPT_MAIL_RCPT
CURLOPT_FTP_USE_PRET
CURLOPT_PROTOCOLS
CURLOPT_REDIR_PROTOCOLS
CURLOPT_HEADERFUNCTION
CURLOPT_HEADERDATA
CURLOPT_RESOLVE
CURLOPT_CONNECT_TO
CURLOPT_TLSAUTH_USERNAME
CURLOPT_TLSAUTH_PASSWORD
CURLOPT_TLSAUTH_TYPE
CURLOPT_PROXY_TLSAUTH_TYPE
CURLOPT_GSSAPI_DELEGATION
CURLOPT_SSL_OPTIONS
CURLOPT_PROXY_SSL_OPTIONS
CURLOPT_MAIL_AUTH
CURLOPT_SASL_IR
CURLOPT_SSL_ENABLE_NPN
CURLOPT_SSL_ENABLE_ALPN
CURLOPT_ABSTRACT_UNIX_SOCKET
CURLOPT_UNIX_SOCKET_PATH
CURLOPT_DEFAULT_PROTOCOL
CURLOPT_EXPECT_100_TIMEOUT_MS
CURLOPT_TFTP_NO_OPTIONS
CURLOPT_HAPROXYPROTOCOL
curl: Saved to filename '%s'
Throwing away %ld bytes
failed to truncate, exiting
curl: (%d) %s
(%d) Failed writing body
Metalink: parsing (%s) OK
%s%c%s
%s/?%s
connection refused
HTTP error
FTP error
SSL_CERT_DIR environment variable
Remote file name has no length!
Using --anyauth or --proxy-anyauth with upload from stdin involves a big risk of it not working. Use a temporary file or a fixed auth type instead!
CURLOPT_SUPPRESS_CONNECT_HEADERS
CURLOPT_SSH_HOST_PUBLIC_KEY_MD5
ignoring %s, not supported by libcurl
ignoring --proxy-capath, not supported by libcurl
CURLOPT_FTP_CREATE_MISSING_DIRS
CURLOPT_FTP_ALTERNATIVE_TO_USER
CURLOPT_HTTP_TRANSFER_DECODING
CURLOPT_PROXY_TLSAUTH_USERNAME
CURLOPT_PROXY_TLSAUTH_PASSWORD
CURLOPT_HAPPY_EYEBALLS_TIMEOUT_MS
CURLOPT_DISALLOW_USERNAME_IN_URL
Metalink: parsing (%s) metalink/XML...
Metalink: fetching (%s) from (%s)...
Transient problem: %s Will retry in %ld seconds. %ld retries left.
failed seeking to end of file, exiting
Metalink: fetching (%s) from (%s) FAILED (HTTP status code %ld)
Metalink: fetching (%s) from (%s) FAILED (%s)
Metalink: fetching (%s) from (%s) OK
More details here: https://curl.haxx.se/docs/sslcerts.html
curl failed to verify the legitimacy of the server and therefore could not
establish a secure connection to it. To learn more about this situation and
how to fix it, please visit the web page mentioned above.
Error setting extended attributes: %s
Metalink: parsing (%s) FAILED
@http://
https://
%s/%s
Enter %s password for user '%s':
Enter %s password for user '%s' on URL #%lu:
unrecognized ftp file method '%s', using default
unrecognized ftp CCC method '%s', using default
unrecognized delegation method '%s', using none
unrecognized protocol '%s'
singlecwd
nocwd
multicwd
passive
active
none
policy
always
curl/7.61.1
%s%s%s
%s:%d: warning: '%s' %s
%s:%d: warning: '%s' uses unquoted white space in the line that may cause side-effects!
\%03o
struct curl_slist *slist%d;
slist%d = NULL;
curl_slist_free_all(slist%d);
curl_mime *mime%d;
mime%d = NULL;
mime%d = curl_mime_init(hnd);
curl_mime_free(mime%d);
curl_mimepart *part%d;
curl_mime_name(part%d, "%s");
curl_mime_type(part%d, "%s");
curl_easy_setopt(hnd, %s, 
%s%ldL);
%s(long)%s%s
%s%luUL);
functionpointer
objectpointer
%ldL
(curl_off_t)%ld
%s set to a %s
CURLPROTO_ALL
CURLPROTO_DICT
CURLPROTO_FILE
CURLPROTO_FTP
CURLPROTO_FTPS
CURLPROTO_GOPHER
CURLPROTO_HTTP
CURLPROTO_HTTPS
CURLPROTO_IMAP
CURLPROTO_IMAPS
CURLPROTO_LDAP
CURLPROTO_LDAPS
CURLPROTO_POP3
CURLPROTO_POP3S
CURLPROTO_RTSP
CURLPROTO_SCP
CURLPROTO_SFTP
CURLPROTO_SMB
CURLPROTO_SMBS
CURLPROTO_SMTP
CURLPROTO_SMTPS
CURLPROTO_TELNET
CURLPROTO_TFTP
CURL_NETRC_IGNORED
CURL_NETRC_OPTIONAL
CURL_NETRC_REQUIRED
CURLSSLOPT_ALLOW_BEAST
CURLSSLOPT_NO_REVOKE
CURLUSESSL_NONE
CURLUSESSL_TRY
CURLUSESSL_CONTROL
CURLUSESSL_ALL
CURLFTPSSL_CCC_NONE
CURLFTPSSL_CCC_PASSIVE
CURLFTPSSL_CCC_ACTIVE
CURL_TIMECOND_IFMODSINCE
CURL_TIMECOND_IFUNMODSINCE
CURL_TIMECOND_LASTMOD
CURL_TIMECOND_NONE
CURL_SSLVERSION_DEFAULT
CURL_SSLVERSION_TLSv1
CURL_SSLVERSION_SSLv2
CURL_SSLVERSION_SSLv3
CURL_SSLVERSION_TLSv1_0
CURL_SSLVERSION_TLSv1_1
CURL_SSLVERSION_TLSv1_2
CURL_SSLVERSION_TLSv1_3
CURL_HTTP_VERSION_NONE
CURL_HTTP_VERSION_1_0
CURL_HTTP_VERSION_1_1
CURL_HTTP_VERSION_2_0
CURL_HTTP_VERSION_2TLS
CURLAUTH_ANY
CURLAUTH_ANYSAFE
CURLAUTH_BASIC
CURLAUTH_DIGEST
CURLAUTH_GSSNEGOTIATE
CURLAUTH_NTLM
CURLAUTH_DIGEST_IE
CURLAUTH_NTLM_WB
CURLAUTH_ONLY
CURLAUTH_NONE
CURLPROXY_SOCKS4
CURLPROXY_SOCKS5
CURLPROXY_SOCKS4A
CURLPROXY_SOCKS5_HOSTNAME
CURLPROXY_HTTP
CURLPROXY_HTTP_1_0
CURLPROXY_HTTPS
slist%d = curl_slist_append(slist%d, "%s");
part%d = curl_mime_addpart(mime%d);
curl_mime_filedata(part%d, "%s");
curl_mime_filename(part%d, NULL);
curl_mime_data_cb(part%d, -1, (curl_read_callback) fread, \
                  (curl_seek_callback) fseek, NULL, stdin);
curl_mime_data(part%d, "%s", %ld);
curl_mime_data(part%d, "%s", CURL_ZERO_TERMINATED);
curl_mime_subparts(part%d, mime%d);
curl_mime_encoder(part%d, "%s");
curl_mime_filename(part%d, "%s");
curl_mime_headers(part%d, slist%d, %d);
curl_easy_setopt(hnd, %s, (long)%s);
curl_easy_setopt(hnd, %s, %ldL);
curl_easy_setopt(hnd, %s, mime%d);
curl_easy_setopt(hnd, %s, slist%d);
curl_easy_setopt(hnd, %s, "%s");
curl_easy_setopt(hnd, %s, %s);
unmatched close brace/bracket
unmatched brace
nested brace
empty string within braces
range overflow
unexpected close bracket
%c-%c%c
bad range
bad range specification
too many globs
%s in column %zu
curl: (%d) [globbing] %s
%0*lu
internal error: invalid pattern type (%d)
url_effective
%03ld
%.6f
%.0f
%.3f
http_code
response_code
http_connect
time_total
time_namelookup
time_connect
time_appconnect
time_pretransfer
time_starttransfer
size_header
size_request
size_download
size_upload
speed_download
speed_upload
content_type
num_connects
time_redirect
num_redirects
ftp_entry_path
redirect_url
proxy_ssl_verify_result
filename_effective
remote_ip
remote_port
local_ip
local_port
http_version
scheme
curl: unknown --write-out variable: '%s'
user.xdg.origin.url
user.mime_type
         (((((                  
AAAAAA
BBBBBB
:*3$"
3h864
3h864
3p864
gcc 8.2.1 20180905
GA*GOW
GA+stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
GA*FORTIFY
GA+GLIBCXX_ASSERTIONS
3h864
3h864
GA!stack_realign
GA!stack_clash
GA*cf_protection
GA*GOW
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.3.1 20190507
GA*GOW
GA!stack_clash
GA*cf_protection
GA+GLIBCXX_ASSERTIONS
GA*FORTIFY
GA!stack_realign
3h864
3h864
3p864
gcc 8.2.1 20180905
GA*GOW
GA+stack_clash
GA*cf_protection
GA*FORTIFY
GA+GLIBCXX_ASSERTIONS
GA!stack_realign
3h864
3h864
curl-7.61.1-11.el8.x86_64.debug
7zXZ
{19e
;g>q
oEK"y
`9.1
V0u&
LmR|Qr\
`yI*
iBcY
nolc@
\*"R
akd	3
CZAd
4{#x
d2gu-
kgBL0
yJ4p|
3~R@q
<YqF
&O	l
`:#	7&
z_(-
M)QM
ea,,
Pk0y
sZ/W
7/xk8
-js5^
dx!"
`8h q
u8pD
2f8Z
+Qa2
?26m
@-\r
V~m_
hN_S49
>2oT
K%h	
I WeO
u<!f-
{2q?iH
.shstrtab
.interp
.note.gnu.property
.note.ABI-tag
.note.gnu.build-id
.gnu.hash
.dynsym
.dynstr
.gnu.version
.gnu.version_r
.rela.dyn
.rela.plt
.init
.plt.sec
.text
.fini
.rodata
.eh_frame_hdr
.eh_frame
.init_array
.fini_array
.data.rel.ro
.dynamic
.got
.data
.bss
.gnu.build.attributes
.gnu_debuglink
.gnu_debugdata
../../../../usr/bin/curl
                                  _   _ ____  _
                              ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
BUGS
 1. Bugs
  1.1 There are still bugs
  1.2 Where to report
  1.3 Security bugs
  1.4 What to report
  1.5 libcurl problems
  1.6 Who will fix the problems
  1.7 How to get a stack trace
  1.8 Bugs in libcurl bindings
  1.9 Bugs in old versions
 2. Bug fixing procedure
 2.1 What happens on first filing
 2.2 First response
 2.3 Not reproducible
 2.4 Unresponsive
 2.5 Lack of time/interest
 2.6 KNOWN_BUGS
 2.7 TODO
 2.8 Closing off stalled bugs
==============================================================================
1.1 There are still bugs
  Curl and libcurl keep being developed. Adding features and changing code
  means that bugs will sneak in, no matter how hard we try not to.
  Of course there are lots of bugs left. And lots of misfeatures.
  To help us make curl the stable and solid product we want it to be, we need
  bug reports and bug fixes.
1.2 Where to report
  If you can't fix a bug yourself and submit a fix for it, try to report an as
  detailed report as possible to a curl mailing list to allow one of us to
  have a go at a solution. You can optionally also post your bug/problem at
  curl's bug tracking system over at
        https://github.com/curl/curl/issues
  Please read the rest of this document below first before doing that!
  If you feel you need to ask around first, find a suitable mailing list and
  post there. The lists are available on https://curl.haxx.se/mail/
1.3 Security bugs
  If you find a bug or problem in curl or libcurl that you think has a
  security impact, for example a bug that can put users in danger or make them
  vulnerable if the bug becomes public knowledge, then please report that bug
  using our security development process.
  Security related bugs or bugs that are suspected to have a security impact,
  should be reported by email to curl-security@haxx.se so that they first can
  be dealt with away from the public to minimize the harm and impact it will
  have on existing users out there who might be using the vulnerable versions.
  The curl project's process for handling security related issues is
  documented here:
        https://curl.haxx.se/dev/secprocess.html
1.4 What to report
  When reporting a bug, you should include all information that will help us
  understand what's wrong, what you expected to happen and how to repeat the
  bad behavior. You therefore need to tell us:
   - your operating system's name and version number
   - what version of curl you're using (curl -V is fine)
   - versions of the used libraries that libcurl is built to use
   - what URL you were working with (if possible), at least which protocol
  and anything and everything else you think matters. Tell us what you
  expected to happen, tell use what did happen, tell us how you could make it
  work another way. Dig around, try out, test. Then include all the tiny bits
  and pieces in your report. You will benefit from this yourself, as it will
  enable us to help you quicker and more accurately.
  Since curl deals with networks, it often helps us if you include a protocol
  debug dump with your bug report. The output you get by using the -v or
  --trace options.
  If curl crashed, causing a core dump (in unix), there is hardly any use to
  send that huge file to anyone of us. Unless we have an exact same system
  setup as you, we can't do much with it. Instead we ask you to get a stack
  trace and send that (much smaller) output to us instead!
  The address and how to subscribe to the mailing lists are detailed in the
  MANUAL file.
1.5 libcurl problems
  When you've written your own application with libcurl to perform transfers,
  it is even more important to be specific and detailed when reporting bugs.
  Tell us the libcurl version and your operating system. Tell us the name and
  version of all relevant sub-components like for example the SSL library
  you're using and what name resolving your libcurl uses. If you use SFTP or
  SCP, the libssh2 version is relevant etc.
  Showing us a real source code example repeating your problem is the best way
  to get our attention and it will greatly increase our chances to understand
  your problem and to work on a fix (if we agree it truly is a problem).
  Lots of problems that appear to be libcurl problems are actually just abuses
  of the libcurl API or other malfunctions in your applications. It is advised
  that you run your problematic program using a memory debug tool like
  valgrind or similar before you post memory-related or "crashing" problems to
  us.
1.6 Who will fix the problems
  If the problems or bugs you describe are considered to be bugs, we want to
  have the problems fixed.
  There are no developers in the curl project that are paid to work on bugs.
  All developers that take on reported bugs do this on a voluntary basis. We
  do it out of an ambition to keep curl and libcurl excellent products and out
  of pride.
  But please do not assume that you can just lump over something to us and it
  will then magically be fixed after some given time. Most often we need
  feedback and help to understand what you've experienced and how to repeat a
  problem. Then we may only be able to assist YOU to debug the problem and to
  track down the proper fix.
  We get reports from many people every month and each report can take a
  considerable amount of time to really go to the bottom with.
1.7 How to get a stack trace
  First, you must make sure that you compile all sources with -g and that you
  don't 'strip' the final executable. Try to avoid optimizing the code as
  well, remove -O, -O2 etc from the compiler options.
  Run the program until it cores.
  Run your debugger on the core file, like '<debugger> curl core'. <debugger>
  should be replaced with the name of your debugger, in most cases that will
  be 'gdb', but 'dbx' and others also occur.
  When the debugger has finished loading the core file and presents you a
  prompt, enter 'where' (without the quotes) and press return.
  The list that is presented is the stack trace. If everything worked, it is
  supposed to contain the chain of functions that were called when curl
  crashed. Include the stack trace with your detailed bug report. It'll help a
  lot.
1.8 Bugs in libcurl bindings
  There will of course pop up bugs in libcurl bindings. You should then
  primarily approach the team that works on that particular binding and see
  what you can do to help them fix the problem.
  If you suspect that the problem exists in the underlying libcurl, then
  please convert your program over to plain C and follow the steps outlined
  above.
1.9 Bugs in old versions
  The curl project typically releases new versions every other month, and we
  fix several hundred bugs per year. For a huge table of releases, number of
  bug fixes and more, see: https://curl.haxx.se/docs/releases.html
  The developers in the curl project do not have bandwidth or energy enough to
  maintain several branches or to spend much time on hunting down problems in
  old versions when chances are we already fixed them or at least that they've
  changed nature and appearance in later versions.
  When you experience a problem and want to report it, you really SHOULD
  include the version number of the curl you're using when you experience the
  issue. If that version number shows us that you're using an out-of-date
  curl, you should also try out a modern curl version to see if the problem
  persists or how/if it has changed in appearance.
  Even if you cannot immediately upgrade your application/system to run the
  latest curl version, you can most often at least run a test version or
  experimental build or similar, to get this confirmed or not.
  At times people insist that they cannot upgrade to a modern curl version,
  but instead they "just want the bug fixed". That's fine, just don't count on
  us spending many cycles on trying to identify which single commit, if that's
  even possible, that at some point in the past fixed the problem you're now
  experiencing.
  Security wise, it is almost always a bad idea to lag behind the current curl
  versions by a lot. We keeping discovering and reporting security problems
  over time see you can see in this table:
  https://curl.haxx.se/docs/vulnerabilities.html
2. Bug fixing procedure
2.1 What happens on first filing
  When a new issue is posted in the issue tracker or on the mailing list, the
  team of developers first need to see the report. Maybe they took the day
  off, maybe they're off in the woods hunting. Have patience. Allow at least a
  few days before expecting someone to have responded.
  In the issue tracker you can expect that some labels will be set on the
  issue to help categorize it.
2.2 First response
  If your issue/bug report wasn't perfect at once (and few are), chances are
  that someone will ask follow-up questions. Which version did you use? Which
  options did you use? How often does the problem occur? How can we reproduce
  this problem? Which protocols does it involve? Or perhaps much more specific
  and deep diving questions. It all depends on your specific issue.
  You should then respond to these follow-up questions and provide more info
  about the problem, so that we can help you figure it out. Or maybe you can
  help us figure it out. An active back-and-forth communication is important
  and the key for finding a cure and landing a fix.
2.3 Not reproducible
  For problems that we can't reproduce and can't understand even after having
  gotten all the info we need and having studied the source code over again,
  are really hard to solve so then we may require further work from you who
  actually see or experience the problem.
2.4 Unresponsive
  If the problem haven't been understood or reproduced, and there's nobody
  responding to follow-up questions or questions asking for clarifications or
  for discussing possible ways to move forward with the task, we take that as
  a strong suggestion that the bug is not important.
  Unimportant issues will be closed as inactive sooner or later as they can't
  be fixed. The inactivity period (waiting for responses) should not be
  shorter than two weeks but may extend months.
2.5 Lack of time/interest
  Bugs that are filed and are understood can unfortunately end up in the
  "nobody cares enough about it to work on it" category. Such bugs are
  perfectly valid problems that *should* get fixed but apparently aren't. We
  try to mark such bugs as "KNOWN_BUGS material" after a time of inactivity
  and if no activity is noticed after yet some time those bugs are added to
  KNOWN_BUGS and are closed in the issue tracker.
2.6 KNOWN_BUGS
  This is a list of known bugs. Bugs we know exist and that have been pointed
  out but that haven't yet been fixed. The reasons for why they haven't been
  fixed can involve anything really, but the primary reason is that nobody has
  considered these problems to be important enough to spend the necessary time
  and effort to have them fixed.
  The KNOWN_BUGS are always up for grabs and we will always love the ones who
  bring one of them back to live and offers solutions to them.
  The KNOWN_BUGS document has a sibling document known as TODO.
2.7 TODO
  Issues that are filed or reported that aren't really bugs but more missing
  features or ideas for future improvements and so on are marked as
  'enhancement' or 'feature-request' and will be added to the TODO document
  instead and the issue is closed. We don't keep TODO items in the issue
  tracker.
  The TODO document is full of ideas and suggestions of what we can add or fix
  one day. You're always encouraged and free to grab one of those items and
  take up a discussion with the curl development team on how that could be
  implemented or provided in the project so that you can work on ticking it
  odd that document.
  If the issue is rather a bug and not a missing feature or functionality, it
  is listed in KNOWN_BUGS instead.
2.8 Closing off stalled bugs
  The issue and pull request trackers on https://github.com/curl/curl will
  only hold "active" entries (using a non-precise definition of what active
  actually is, but they're at least not completely dead). Those that are
  abandoned or in other ways dormant will be closed and sometimes added to
  TODO and KNOWN_BUGS instead.
  This way, we only have "active" issues open on github. Irrelevant issues and
  pull requests will not distract developers or casual visitors.
                                  _   _ ____  _
                              ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
                                  Changelog
Version 7.61.1 (4 Sep 2018)
Daniel Stenberg (4 Sep 2018)
- THANKS: 7.61.1 status
- RELEASE-NOTES: 7.61.1
- Curl_getoff_all_pipelines: ignore unused return values
  Since scan-build would warn on the dead "Dead store/Dead increment"
Viktor Szakats (4 Sep 2018)
- sftp: fix indentation
Daniel Stenberg (4 Sep 2018)
- [Przemys
aw Tomaszewski brought this change]
  sftp: don't send post-qoute sequence when retrying a connection
  Fixes #2939
  Closes #2940
Kamil Dudka (3 Sep 2018)
- url, vtls: make CURLOPT{,_PROXY}_TLS13_CIPHERS work
  This is a follow-up to PR #2607 and PR #2926.
  Closes #2936
Daniel Stenberg (3 Sep 2018)
- [Jay Satiro brought this change]
  tool_operate: Add http code 408 to transient list for --retry
  - Treat 408 request timeout as transient so that curl will retry the
    request if --retry was used.
  Closes #2925
- [Jay Satiro brought this change]
  openssl: Fix setting TLS 1.3 cipher suites
  The flag indicating TLS 1.3 cipher support in the OpenSSL backend was
  missing.
  Bug: https://github.com/curl/curl/pull/2607#issuecomment-417283187
  Reported-by: Kamil Dudka
  Closes #2926
- Curl_ntlm_core_mk_nt_hash: return error on too long password
  ... since it would cause an integer overflow if longer than (max size_t
  / 2).
  This is CVE-2018-14618
  Bug: https://curl.haxx.se/docs/CVE-2018-14618.html
  Closes #2756
  Reported-by: Zhaoyang Wu
- [Rikard Falkeborn brought this change]
  http2: Use correct format identifier for stream_id
  Closes #2928
Marcel Raad (2 Sep 2018)
- test1148: fix precheck output
  "precheck command error" is not very helpful.
Daniel Stenberg (1 Sep 2018)
- all: s/int/size_t cleanup
  Assisted-by: Rikard Falkeborn
  Closes #2922
- ssh-libssh: use FALLTHROUGH to silence gcc8
Jay Satiro (31 Aug 2018)
- tool_operate: Fix setting proxy TLS 1.3 ciphers
Daniel Stenberg (31 Aug 2018)
- [Daniel Gustafsson brought this change]
  cookies: support creation-time attribute for cookies
  According to RFC6265 section 5.4, cookies with equal path lengths
  SHOULD be sorted by creation-time (earlier first). This adds a
  creation-time record to the cookie struct in order to make cookie
  sorting more deterministic. The creation-time is defined as the
  order of the cookies in the jar, the first cookie read fro the
  jar being the oldest. The creation-time is thus not serialized
  into the jar. Also remove the strcmp() matching in the sorting as
  there is no lexicographic ordering in RFC6265. Existing tests are
  updated to match.
  Closes #2524
Marcel Raad (31 Aug 2018)
- Don't use Windows path %PWD for SSH tests
  All these tests failed on Windows because something like
  sftp://%HOSTIP:%SSHPORT%PWD/
  expanded to
  sftp://127.0.0.1:1234c:/msys64/home/bla/curl
  and then curl complained about the port number ending with a letter.
  Use the original POSIX path instead of the Windows path created in
  checksystem to fix this.
  Closes https://github.com/curl/curl/pull/2920
Jay Satiro (29 Aug 2018)
- CURLOPT_SSL_CTX_FUNCTION.3: clarify connection reuse warning
  Reported-by: Daniel Stenberg
  Closes https://github.com/curl/curl/issues/2916
Daniel Stenberg (28 Aug 2018)
- THANKS-filter: dedup Daniel Jeli
- RELEASE-NOTES: synced
- CURLOPT_ACCEPT_ENCODING.3: list them comma-separated [ci skip]
- CURLOPT_SSL_CTX_FUNCTION.3: might cause unintended connection reuse [ci skip]
  Added a warning!
  Closes #2915
- curl: fix time-of-check, time-of-use race in dir creation
  Patch-by: Jay Satiro
  Detected by Coverity
  Fixes #2739
  Closes #2912
- cmdline-opts/page-footer: fix edit mistake
  There was a missing newline.
  follow-up to a7ba60bb7250
- docs: clarify NO_PROXY env variable functionality
  Reported-by: Kirill Marchuk
  Fixes #2773
  Closes #2911
Marcel Raad (24 Aug 2018)
- lib1522: fix curl_easy_setopt argument type
  CURLOPT_POSTFIELDSIZE is a long option.
- curl_threads: silence bad-function-cast warning
  As uintptr_t and HANDLE are always the same size, this warning is
  harmless. Just silence it using an intermediate uintptr_t variable.
  Closes https://github.com/curl/curl/pull/2908
Daniel Stenberg (24 Aug 2018)
- README: add appveyor build badge [ci skip]
  Closes #2913
- [Ihor Karpenko brought this change]
  schannel: client certificate store opening fix
  1) Using CERT_STORE_OPEN_EXISTING_FLAG ( or CERT_STORE_READONLY_FLAG )
  while opening certificate store would be sufficient in this scenario and
  less-demanding in sense of required user credentials ( for example,
  IIS_IUSRS will get "Access Denied" 0x05 error for existing CertOpenStore
  call without any of flags mentioned above ),
  2) as 'cert_store_name' is a DWORD, attempt to format its value like a
  string ( in "Failed to open cert store" error message ) will throw null
  pointer exception
  3) adding GetLastError(), in my opinion, will make error message more
  useful.
  Bug: https://curl.haxx.se/mail/lib-2018-08/0198.html
  Closes #2909
- [Leonardo Taccari brought this change]
  gopher: Do not translate `?' to `%09'
  Since GOPHER support was added in curl `?' character was automatically
  translated to `%09' (`\t').
  However, this behaviour does not seems documented in RFC 4266 and for
  search selectors it is documented to directly use `%09' in the URL.
  Apart that several gopher servers in the current gopherspace have CGI
  support where `?' is used as part of the selector and translating it to
  `%09' often leads to surprising results.
  Closes #2910
Marcel Raad (23 Aug 2018)
- cookie tests: treat files as text
  Fixes test failures because of wrong line endings on Windows.
Daniel Stenberg (23 Aug 2018)
- libcurl-thread.3: expand somewhat on the NO_SIGNAL motivation
  Multi-threaded applictions basically MUST set CURLOPT_NO_SIGNAL to 1L to
  avoid the risk of getting a SIGPIPE.
  Either way, a multi-threaded application that uses libcurl/openssl needs
  to have a signhandler for or ignore SIGPIPE on its own.
  Based on discussions in #2800
  Closes #2904
- RELEASE-NOTES: synced
Marcel Raad (22 Aug 2018)
- Tests: fixes for Windows
  - test 1268 requires unix sockets
  - test 2072 must be disabled also for MSYS/MinGW
Daniel Stenberg (22 Aug 2018)
- http2: abort the send_callback if not setup yet
  When Curl_http2_done() gets called before the http2 data is setup all
  the way, we cannot send anything and this should just return an error.
  Detected by OSS-Fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=10012
- http2: remove four unused nghttp2 callbacks
  Closes #2903
- x509asn1: use FALLTHROUGH
  ... as no other comments are accepted since 014ed7c22f51463
Marcel Raad (21 Aug 2018)
- test1148: disable if decimal separator is not point
  Modifying the locale with environment variables doesn't work for native
  Windows applications. Just disable the test in this case if the decimal
  separator is something different than a point. Use a precheck with a
  small C program to achieve that.
  Closes https://github.com/curl/curl/pull/2786
- Enable more GCC warnings
  This enables the following additional warnings:
  -Wold-style-definition
  -Warray-bounds=2 instead of the default 1
  -Wformat=2, but only for GCC 4.8+ as Wno-format-nonliteral is not
   respected for older versions
  -Wunused-const-variable, which enables level 2 instead of the default 1
  -Warray-bounds also in debug mode through -ftree-vrp
  -Wnull-dereference also in debug mode through
   -fdelete-null-pointer-checks
  Closes https://github.com/curl/curl/pull/2747
- curl-compilers: enable -Wimplicit-fallthrough=4 for GCC
  This enables level 4 instead of the default level 3, which of the
  currently used comments only allows /* FALLTHROUGH */ to silence the
  warning.
  Closes https://github.com/curl/curl/pull/2747
- curl-compilers: enable -Wbad-function-cast on GCC
  This warning used to be enabled only for clang as it's a bit stricter
  on GCC. Silence the remaining occurrences and enable it on GCC too.
  Closes https://github.com/curl/curl/pull/2747
- configure: conditionally enable pedantic-errors
  Enable pedantic-errors for GCC >= 5 with --enable-werror. Before GCC 5,
  pedantic-errors was synonymous to -Werror=pedantic [0], which is still
  the case for clang [1]. With GCC 5, it became complementary [2].
  Also fix a resulting error in acinclude.m4 as main's return type was
  missing, which is illegal in C99.
  [0] https://gcc.gnu.org/onlinedocs/gcc-4.9.0/gcc/Warning-Options.html
  [1] https://clang.llvm.org/docs/UsersManual.html#options-to-control-error-and-warning-messages
  [2] https://gcc.gnu.org/onlinedocs/gcc-5.1.0/gcc/Warning-Options.html
  Closes https://github.com/curl/curl/pull/2747
- Remove unused definitions
  Closes https://github.com/curl/curl/pull/2747
Daniel Stenberg (21 Aug 2018)
- x509asn1: make several functions static
  and remove the private SIZE_T_MAX define and use the generic one.
  Closes #2902
- INTERNALS: require GnuTLS >= 2.11.3
  Since the public pinning support was brought in e644866caf4. GnuTLS
  2.11.3 was released in October 2010.
  Figured out in #2890
- http2: avoid set_stream_user_data() before stream is assigned
  ... before the stream is started, we have it set to -1.
  Fixes #2894
  Closes #2898
- SSLCERTS: improve the openssl command line
  ... for extracting certs from a live HTTPS server to make a cacerts.pem
  from them.
- docs/SECURITY-PROCESS: now we name the files after the CVE id
- RELEASE-NOTES: synced
- upload: change default UPLOAD_BUFSIZE to 64KB
  To make uploads significantly faster in some circumstances.
  Part 2 of #2888
  Closes #2892
- upload: allocate upload buffer on-demand
  Saves 16KB on the easy handle for operations that don't need that
  buffer.
  Part 1 of #2888
- [Laurent Bonnans brought this change]
  vtls: reinstantiate engine on duplicated handles
  Handles created with curl_easy_duphandle do not use the SSL engine set
  up in the original handle. This fixes the issue by storing the engine
  name in the internal url state and setting the engine from its name
  inside curl_easy_duphandle.
  Reported-by: Anton Gerasimov
  Signed-of-by: Laurent Bonnans
  Fixes #2829
  Closes #2833
- http2: make sure to send after RST_STREAM
  If this is the last stream on this connection, the RST_STREAM might not
  get pushed to the wire otherwise.
  Fixes #2882
  Closes #2887
  Researched-by: Michael Kaufmann
- test1268: check the stderr output as "text"
  Follow-up to 099f37e9c57
  Pointed-out-by: Marcel Raad
- urldata: remove unused pipe_broke struct field
  This struct field is never set TRUE in any existing code path. This
  change removes the field completely.
  Closes #2871
- curl: warn the user if a given file name looks like an option
  ... simply because this is usually a sign of the user having omitted the
  file name and the next option is instead "eaten" by the parser as a file
  name.
  Add test1268 to verify
  Closes #2885
- http2: check nghttp2_session_set_stream_user_data return code
  Might help bug #2688 debugging
  Closes #2880
- travis: revert back to gcc-7 for coverage builds
  ... since the gcc-8 ones seem to fail frequently.
  Follow-up from b85207199544ca
  Closes #2886
- RELEASE-NOTES: synced
  ... and now listed in alphabetical order!
- [Adrien brought this change]
  CMake: CMake config files are defining CURL_STATICLIB for static builds
  This change allows to use the CMake config files generated by Curl's
  CMake scripts for static builds of the library.
  The symbol CURL_STATIC lib must be defined to compile downstream,
  thus the config package is the perfect place to do so.
  Fixes #2817
  Closes #2823
  Reported-by: adnn on github
  Reviewed-by: Sergei Nikulov
- TODO: host name sections in config files
Kamil Dudka (14 Aug 2018)
- ssh-libssh: fix infinite connect loop on invalid private key
  Added test 656 (based on test 604) to verify the fix.
  Bug: https://bugzilla.redhat.com/1595135
  Closes #2879
- ssh-libssh: reduce excessive verbose output about pubkey auth
  The verbose message "Authentication using SSH public key file" was
  printed each time the ssh_userauth_publickey_auto() was called, which
  meant each time a packet was transferred over network because the API
  operates in non-blocking mode.
  This patch makes sure that the verbose message is printed just once
  (when the authentication state is entered by the SSH state machine).
Daniel Stenberg (14 Aug 2018)
- travis: disable h2 torture tests for "coverage"
  Since they started to fail almost 100% since a few days.
  Closes #2876
Marcel Raad (14 Aug 2018)
- travis: update to GCC 8
  Closes https://github.com/curl/curl/pull/2869
Daniel Stenberg (13 Aug 2018)
- http: fix for tiny "HTTP/0.9" response
  Deal with tiny "HTTP/0.9" (header-less) responses by checking the
  status-line early, even before a full "HTTP/" is received to allow
  detecting 0.9 properly.
  Test 1266 and 1267 added to verify.
  Fixes #2420
  Closes #2872
Kamil Dudka (13 Aug 2018)
- docs: add disallow-username-in-url.d and haproxy-protocol.d on the list
  ... to make make the files appear in distribution tarballs
  Closes #2856
- .travis.yml: verify that man pages can be regenerated
  ... when curl is built from distribution tarball
  Closes #2856
Marcel Raad (11 Aug 2018)
- Split non-portable part off test 1133
  Split off testing file names with double quotes into new test 1158.
  Disable it for MSYS using a precheck as it doesn't support file names
  with double quotes (but Cygwin does, for example).
  Fixes https://github.com/curl/curl/issues/2796
  Closes https://github.com/curl/curl/pull/2854
Jay Satiro (11 Aug 2018)
- projects: Improve Windows perl detection in batch scripts
  - Determine if perl is in the user's PATH by running perl.exe.
  Prior to this change detection was done by checking the PATH for perl/
  but that did not work in all cases (eg git install includes perl but
  not in perl/ path).
  Bug: https://github.com/curl/curl/pull/2865
  Reported-by: Daniel Jeli
- [Michael Kaufmann brought this change]
  docs: Improve the manual pages of some callbacks
  - CURLOPT_HEADERFUNCTION: add newlines
  - CURLOPT_INTERLEAVEFUNCTION: fix the description of 'userdata'
  - CURLOPT_READDATA: mention crashes, same as in CURLOPT_WRITEDATA
  - CURLOPT_READFUNCTION: rename 'instream' to 'userdata' and explain
    how to set it
  Closes https://github.com/curl/curl/pull/2868
Marcel Raad (11 Aug 2018)
- GCC: silence -Wcast-function-type uniformly
  Pointed-out-by: Rikard Falkeborn
  Closes https://github.com/curl/curl/pull/2860
- Silence GCC 8 cast-function-type warnings
  On Windows, casting between unrelated function types is fine and
  sometimes even necessary, so just use an intermediate cast to
  (void (*) (void)) to silence the warning as described in [0].
  [0] https://gcc.gnu.org/onlinedocs/gcc-8.1.0/gcc/Warning-Options.html
  Closes https://github.com/curl/curl/pull/2860
Daniel Stenberg (11 Aug 2018)
- CURLINFO_SIZE_UPLOAD: fix missing counter update
  Adds test 1522 for verification.
  Reported-by: cjmsoregan
  Fixes #2847
  Closes #2864
- [Daniel Jelinski brought this change]
  Documentation: fix CURLOPT_SSH_COMPRESSION copy/paste bug
  Closes #2867
- RELEASE-NOTES: synced
- openssl: fix potential NULL pointer deref in is_pkcs11_uri
  Follow-up to 298d2565e
  Coverity CID 1438387
Marcel Raad (10 Aug 2018)
- travis: execute "set -eo pipefail" for coverage build
  Follow-up to 2de63ab179eb78630ee039ad94fb2a5423df522d and
  0b87c963252d3504552ee0c8cf4402bd65a80af5.
  Closes https://github.com/curl/curl/pull/2862
Daniel Stenberg (10 Aug 2018)
- lib1502: fix memory leak in torture test
  Reported-by: Marcel Raad
  Fixes #2861
  Closes #2863
- docs: mention NULL is fine input to several functions
  Fixes #2837
  Closes #2858
  Reported-by: Markus Elfring
- [Bas van Schaik brought this change]
  README.md: add LGTM.com code quality grade for C/C++
  Closes #2857
- [Rikard Falkeborn brought this change]
  test1531: Add timeout
  Previously, the macro TEST_HANG_TIMEOUT was unused, but since there is
  looping going on, we might as well add timing instead of removing it.
  Closes #2853
- [Rikard Falkeborn brought this change]
  test1540: Remove unused macro TEST_HANG_TIMEOUT
  The macro has never been used, and it there is not really any place
  where it would make sense to add timing checks.
  Closes #2852
- [Rikard Falkeborn brought this change]
  asyn-thread: Remove unused macro
  The macro seems to never have been used.
  Closes #2852
- [Rikard Falkeborn brought this change]
  http_proxy: Remove unused macro SELECT_TIMEOUT
  Usage was removed in 5113ad0424044458ac497fa1458ebe0101356b22.
  Closes #2852
- [Rikard Falkeborn brought this change]
  formdata: Remove unused macro HTTPPOST_CONTENTTYPE_DEFAULT
  Its usage was removed in
  84ad1fd3047815f9c6e78728bb351b828eac10b1.
  Closes #2852
- [Rikard Falkeborn brought this change]
  telnet: Remove unused macros TELOPTS and TELCMDS
  Their usage was removed in 3a145180cc754a5959ca971ef3cd243c5c83fc51.
  Closes #2852
- [Daniel Jelinski brought this change]
  openssl: fix debug messages
  Fixes #2806
  Closes #2843
- configure: fix for -lpthread detection with OpenSSL and pkg-config
  ... by making sure it uses the -I provided by pkg-config!
  Reported-by: pszemus on github
  Fixes #2848
  Closes #2850
- RELEASE-NOTES: synced
- windows: follow up to the buffer-tuning 1ba1dba7
  Somehow I didn't include the amended version of the previous fix. This
  is the missing piece.
  Pointed-out-by: Viktor Szakats
- [Daniel Jelinski brought this change]
  windows: implement send buffer tuning
  Significantly enhances upload performance on modern Windows versions.
  Bug: https://curl.haxx.se/mail/lib-2018-07/0080.html
  Closes #2762
  Fixes #2224
- [Anderson Toshiyuki Sasaki brought this change]
  ssl: set engine implicitly when a PKCS#11 URI is provided
  This allows the use of PKCS#11 URI for certificates and keys without
  setting the corresponding type as "ENG" and the engine as "pkcs11"
  explicitly. If a PKCS#11 URI is provided for certificate, key,
  proxy_certificate or proxy_key, the corresponding type is set as "ENG"
  if not provided and the engine is set to "pkcs11" if not provided.
  Acked-by: Nikos Mavrogiannopoulos
  Closes #2333
- [Ruslan Baratov brought this change]
  CMake: Respect BUILD_SHARED_LIBS
  Use standard CMake variable BUILD_SHARED_LIBS instead of introducing
  custom option CURL_STATICLIB.
  Use '-DBUILD_SHARED_LIBS=%SHARED%' in appveyor.yml.
  Reviewed-by: Sergei Nikulov
  Closes #2755
- [John Butterfield brought this change]
  cmake: bumped minimum version to 3.4
  Closes #2753
- [John Butterfield brought this change]
  cmake: link curl to the OpenSSL targets instead of lib absolute paths
  Reviewed-by: Jakub Zakrzewski
  Reviewed-by: Sergei Nikulov
  Closes #2753
- travis: build darwinssl on macos 10.12
  ... as building on 10.13.x before 10.13.4 leads to link errors.
  Assisted-by: Nick Zitzmann
  Fixes #2835
  Closes #2845
- DEPRECATE: remove release date from 7.62.0
  Since it will slip and the version is the important part there, not the
  date.
- lib/Makefile: only do symbol hiding if told to
  This restores the ability to build a static lib with
  --disable-symbol-hiding to keep non-curl_ symbols.
  Researched-by: Dan Fandrich
  Reported-by: Ran Mozes
  Fixes #2830
  Closes #2831
Marcel Raad (2 Aug 2018)
- hostip: fix unused variable warning
  addresses is only used in an infof call, which is a macro expanding to
  nothing if CURL_DISABLE_VERBOSE_STRINGS is set.
Daniel Stenberg (2 Aug 2018)
- test1307: disabled
  Turns out that since we're using the native fnmatch function now when
  available, and they simply disagree on a huge number of test patterns
  that make it hard to test this function like this...
  Fixes #2825
- smb: don't mark it done in smb_do
  Follow-up to 09e401e01bf9. The SMB protocol handler needs to use its
  doing function too, which requires smb_do() to not mark itself as
  done...
  Closes #2822
- [Rikard Falkeborn brought this change]
  general: fix printf specifiers
  Closes #2818
- RELEASE-NOTES: synced
- mailmap: Daniel Jelinski
- [Harry Sintonen brought this change]
  HTTP: Don't attempt to needlessly decompress redirect body
  This change fixes a regression where redirect body would needlessly be
  decompressed even though it was to be ignored anyway. As it happens this
  causes secondary issues since there appears to be a bug in apache2 that
  it in certain conditions generates a corrupt zlib response. The
  regression was created by commit:
  dbcced8e32b50c068ac297106f0502ee200a1ebd
  Discovered-by: Harry Sintonen
  Closes #2798
- curl: use Content-Disposition before the "URL end" for -OJ
  Regression introduced in 7.61.0
  Reported-by: Thomas Klausner
  Fixes #2783
  Closes #2813
- [Daniel Jelinski brought this change]
  retry: return error if rewind was necessary but didn't happen
  Fixes #2801
  Closes #2812
- http2: clear the drain counter in Curl_http2_done
  Reported-by: Andrei Virtosu
  Fixes #2800
  Closes #2809
- smb: fix memory leak on early failure
  ... by making sure connection related data (->share) is stored in the
  connection and not in the easy handle.
  Detected by OSS-fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=9369
  Fixes #2769
  Closes #2810
- travis: run a 'make checksrc' too
  ... to make sure the examples are all checked.
  Closes #2811
Jay Satiro (29 Jul 2018)
- examples/ephiperfifo: checksrc compliance
- [Michael Kaufmann brought this change]
  sws: handle EINTR when calling select()
  Closes https://github.com/curl/curl/pull/2808
Daniel Stenberg (29 Jul 2018)
- test1157: follow-up to 35ecffb9
  Ignore the user-agent line.
  Pointed-out-by: Marcel Raad
Michael Kaufmann (29 Jul 2018)
- tests/http_pipe.py: Use /usr/bin/env to find python
Daniel Stenberg (28 Jul 2018)
- TODO: Support Authority Information Access certificate extension (AIA)
  Closes #2793
- conn_free: updated comment to clarify
  Let's call it disassociate instead of disconnect since the latter term
  is used so much for (TCP) connections already.
- test1157: test -H from empty file
  Verifies bugfix #2797
- [Tobias Blomberg brought this change]
  curl: Fix segfault when -H @headerfile is empty
  The curl binary would crash if the -H command line option was given a
  filename to read using the @filename syntax but that file was empty.
  Closes #2797
- mime: check Curl_rand_hex's return code
  Bug: https://curl.haxx.se/mail/archive-2018-07/0015.html
  Reported-by: Jeffrey Walton
  Closes #2795
- [Josh Bialkowski brought this change]
  docs/examples: add hiperfifo example using linux epoll/timerfd
  Closes #2804
- [Dar
o Here
 brought this change]
  docs/INSTALL.md: minor formatting fixes
  Closes #2794
- [Christopher Head brought this change]
  docs/CURLOPT_URL: fix indentation
  The statement, 
The application does not have to keep the string around
  after setting this option,
 appears to be indented under the RTMP
  paragraph. It actually applies to all protocols, not just RTMP.
  Eliminate the extra indentation.
  Closes #2788
- [Christopher Head brought this change]
  docs/CURLOPT_WRITEFUNCTION: size is always 1
  For compatibility with `fwrite`, the `CURLOPT_WRITEFUNCTION` callback is
  passed two `size_t` parameters which, when multiplied, designate the
  number of bytes of data passed in. In practice, CURL always sets the
  first parameter (`size`) to 1.
  This practice is also enshrined in documentation and cannot be changed
  in future. The documentation states that the default callback is
  `fwrite`, which means `fwrite` must be a suitable function for this
  purpose. However, the documentation also states that the callback must
  return the number of *bytes* it successfully handled, whereas ISO C
  `fwrite` returns the number of items (each of size `size`) which it
  wrote. The only way these numbers can be equal is if `size` is 1.
  Since `size` is 1 and can never be changed in future anyway, document
  that fact explicitly and let users rely on it.
  Closes #2787
- [Carie Pointer brought this change]
  wolfSSL/CyaSSL: Fix memory leak in Curl_cyassl_random
  RNG structure must be freed by call to FreeRng after its use in
  Curl_cyassl_random. This call fixes Valgrind failures when running the
  test suite with wolfSSL.
  Closes #2784
- [Even Rouault brought this change]
  reuse_conn(): free old_conn->options
  This fixes a memory leak when CURLOPT_LOGIN_OPTIONS is used, together with
  connection reuse.
  I found this with oss-fuzz on GDAL and curl master:
  https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=9582
  I couldn't reproduce with the oss-fuzz original test case, but looking
  at curl source code pointed to this well reproducable leak.
  Closes #2790
Marcel Raad (25 Jul 2018)
- [Daniel Jelinski brought this change]
  system_win32: fix version checking
  In the current version, VERSION_GREATER_THAN_EQUAL 6.3 will return false
  when run on windows 10.0. This patch addresses that error.
  Closes https://github.com/curl/curl/pull/2792
Daniel Stenberg (24 Jul 2018)
- [Johannes Schindelin brought this change]
  auth: pick Bearer authentication whenever a token is available
  So far, the code tries to pick an authentication method only if
  user/password credentials are available, which is not the case for
  Bearer authentictation...
  Signed-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>
  Closes #2754
- [Johannes Schindelin brought this change]
  auth: only ever pick CURLAUTH_BEARER if we *have* a Bearer token
  The Bearer authentication was added to cURL 7.61.0, but there is a
  problem: if CURLAUTH_ANY is selected, and the server supports multiple
  authentication methods including the Bearer method, we strongly prefer
  that latter method (only CURLAUTH_NEGOTIATE beats it), and if the Bearer
  authentication fails, we will never even try to attempt any other
  method.
  This is particularly unfortunate when we already know that we do not
  have any Bearer token to work with.
  Such a scenario happens e.g. when using Git to push to Visual Studio
  Team Services (which supports Basic and Bearer authentication among
  other methods) and specifying the Personal Access Token directly in the
  URL (this aproach is frequently taken by automated builds).
  Let's make sure that we have a Bearer token to work with before we
  select the Bearer authentication among the available authentication
  methods.
  Signed-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>
  Closes #2754
Marcel Raad (22 Jul 2018)
- test320: treat curl320.out file as binary
  Otherwise, LF line endings are converted to CRLF on Windows,
  but no conversion is done for the reply, so the test case fails.
  Closes https://github.com/curl/curl/pull/2776
Daniel Stenberg (22 Jul 2018)
- vtls: set conn->data when closing TLS
  Follow-up to 1b76c38904f0. The VTLS backends that close down the TLS
  layer for a connection still needs a Curl_easy handle for the session_id
  cache etc.
  Fixes #2764
  Closes #2771
Marcel Raad (21 Jul 2018)
- tests: fixes for Windows line endlings
  Set mode="text" when line endings depend on the system representation.
  Closes https://github.com/curl/curl/pull/2772
- test214: disable MSYS2's POSIX path conversion for URL
  By default, the MSYS2 bash converts all backslashes to forward slashes
  in URLs. Disable this with MSYS2_ARG_CONV_EXCL for the test to pass.
  Ref https://github.com/msys2/msys2/wiki/Porting#filesystem-namespaces
Daniel Stenberg (20 Jul 2018)
- http2: several cleanups
  - separate easy handle from connections better
  - added asserts on a number of places
  - added sanity check of pipelines for debug builds
  Closes #2751
- smb_getsock: always wait for write socket too
  ... the protocol is doing read/write a lot, so it needs to write often
  even when downloading. A more proper fix could check for eactly when it
  wants to write and only ask for it then.
  Without this fix, an SMB download could easily get stuck when the event-driven
  API was used.
  Closes #2768
Marcel Raad (20 Jul 2018)
- test1143: disable MSYS2's POSIX path conversion
  By default, the MSYS2 bash interprets http:/%HOSTIP:%HTTPPORT/want/1143
  as a POSIX file list and converts it to a Windows file list.
  Disable this with MSYS2_ARG_CONV_EXCL for the test to pass.
  Ref https://github.com/msys2/msys2/wiki/Porting#filesystem-namespaces
  Closes https://github.com/curl/curl/pull/2765
Daniel Stenberg (18 Jul 2018)
- RELEASE-NOTES: sync
  ... and work toward 7.61.1
- [Ruslan Baratov brought this change]
  CMake: Update scripts to use consistent style
  Closes #2727
  Reviewed-by: Sergei Nikulov
- header output: switch off all styles, not just unbold
  ... the "unbold" sequence doesn't work on the mac Terminal.
  Reported-by: Zero King
  Fixes #2736
  Closes #2738
Nick Zitzmann (14 Jul 2018)
- [Rodger Combs brought this change]
  darwinssl: add support for ALPN negotiation
Marcel Raad (14 Jul 2018)
- test1422: add required file feature
  curl configured with --enable-debug --disable-file currently complains
  on test1422:
  Info: Protocol "file" not supported or disabled in libcurl
  Make test1422 dependend on enabled FILE protocol to fix this.
  Fixes https://github.com/curl/curl/issues/2741
  Closes https://github.com/curl/curl/pull/2742
Patrick Monnerat (12 Jul 2018)
- content_encoding: accept up to 4 unknown trailer bytes after raw deflate data
  Some servers issue raw deflate data that may be followed by an undocumented
  trailer. This commit makes curl tolerate such a trailer of up to 4 bytes
  before considering the data is in error.
  Reported-by: clbr on github
  Fixes #2719
Daniel Stenberg (12 Jul 2018)
- smb: fix memory-leak in URL parse error path
  Detected by OSS-Fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=9369
  Closes #2740
Marcel Raad (12 Jul 2018)
- schannel: enable CALG_TLS1PRF for w32api >= 5.1
  The definition of CALG_TLS1PRF has been fixed in the 5.1 branch:
  https://osdn.net/projects/mingw/scm/git/mingw-org-wsl/commits/73aedcc0f2e6ba370de0d86ab878ad76a0dda7b5
Daniel Stenberg (12 Jul 2018)
- docs/SECURITY-PROCESS: mention bounty, drop pre-notify
  + The hackerone bounty and its process
  - We don't and can't handle pre-notification
- multi: always do the COMPLETED procedure/state
  It was previously erroneously skipped in some situations.
  libtest/libntlmconnect.c wrongly depended on wrong behavior (that it
  would get a zero timeout) when no handles are "running" in a multi
  handle. That behavior is no longer present with this fix. Now libcurl
  will always return a -1 timeout when all handles are completed.
  Closes #2733
- Curl_getoff_all_pipelines: improved for multiplexed
  On multiplexed connections, transfers can be removed from anywhere not
  just at the head as for pipelines.
- ares: check for NULL in completed-callback
- conn: remove the boolean 'inuse' field
  ... as the usage needs to be counted.
- [Paul Howarth brought this change]
  openssl: assume engine support in 1.0.0 or later
  Commit 38203f1585da changed engine detection to be version-based,
  with a baseline of openssl 1.0.1. This does in fact break builds
  with openssl 1.0.0, which has engine support - the configure script
  detects that ENGINE_cleanup() is available - but <openssl/engine.h>
  doesn't get included to declare it.
  According to upstream documentation, engine support was added to
  mainstream openssl builds as of version 0.9.7:
  https://github.com/openssl/openssl/blob/master/README.ENGINE
  This commit drops the version test down to 1.0.0 as version 1.0.0d
  is the oldest version I have to test with.
  Closes #2732
Marcel Raad (11 Jul 2018)
- schannel: fix MinGW compile break
  Original MinGW's w32api has a sytax error in its definition of
  CALG_TLS1PRF [0]. Don't use original MinGW w32api's CALG_TLS1PRF
  until this bug [1] is fixed.
  [0] https://osdn.net/projects/mingw/scm/git/mingw-org-wsl/blobs/d1d4a17e51a2b78e252ef0147d483267d56c90cc/w32api/include/wincrypt.h
  [1] https://osdn.net/projects/mingw/ticket/38391
  Fixes https://github.com/curl/curl/pull/2721#issuecomment-403636043
  Closes https://github.com/curl/curl/pull/2728
Daniel Stenberg (11 Jul 2018)
- examples/crawler.c: move #ifdef to column 0
  Apparently the C => HTML converter on the web site doesn't quite like it
  otherwise.
  Reported-by: Jeroen Ooms
Version 7.61.0 (11 Jul 2018)
Daniel Stenberg (11 Jul 2018)
- release: 7.61.0
- TODO: Configurable loading of OpenSSL configuration file
  Closes #2724
- post303.d: clarify that this is an RFC violation
  ... and not the other way around, which this previously said.
  Reported-by: Vasiliy Faronov
  Fixes #2723
  Closes #2726
- [Ruslan Baratov brought this change]
  CMake: remove redundant and old end-of-block syntax
  Reviewed-by: Jakub Zakrzewski
  Closes #2715
Jay Satiro (9 Jul 2018)
- lib/curl_setup.h: remove unicode character
  Follow-up to 82ce416.
  Ref: https://github.com/curl/curl/commit/8272ec5#commitcomment-29646818
Daniel Stenberg (9 Jul 2018)
- lib/curl_setup.h: remove unicode bom from 8272ec50f02
Marcel Raad (9 Jul 2018)
- schannel: fix -Wsign-compare warning
  MinGW warns:
  /lib/vtls/schannel.c:219:64: warning: signed and unsigned type in
  conditional expression [-Wsign-compare]
  Fix this by casting the ptrdiff_t to size_t as we know it's positive.
  Closes https://github.com/curl/curl/pull/2721
- schannel: workaround for wrong function signature in w32api
  Original MinGW's w32api has CryptHashData's second parameter as BYTE *
  instead of const BYTE *.
  Closes https://github.com/curl/curl/pull/2721
- schannel: make more cipher options conditional
  They are not defined in the original MinGW's <wincrypt.h>.
  Closes https://github.com/curl/curl/pull/2721
- curl_setup: include <winerror.h> before <windows.h>
  Otherwise, only part of it gets pulled in through <windows.h> on
  original MinGW.
  Fixes https://github.com/curl/curl/issues/2361
  Closes https://github.com/curl/curl/pull/2721
- examples: fix -Wformat warnings
  When size_t is not a typedef for unsigned long (as usually the case on
  Windows), GCC emits -Wformat warnings when using lu and lx format
  specifiers with size_t. Silence them with explicit casts to
  unsigned long.
  Closes https://github.com/curl/curl/pull/2721
Daniel Stenberg (9 Jul 2018)
- smtp: use the upload buffer size for scratch buffer malloc
  ... not the read buffer size, as that can be set smaller and thus cause
  a buffer overflow! CVE-2018-0500
  Reported-by: Peter Wu
  Bug: https://curl.haxx.se/docs/adv_2018-70a2.html
- [Dave Reisner brought this change]
  scripts: include _curl as part of CLEANFILES
  Closes #2718
- [Nick Zitzmann brought this change]
  darwinssl: allow High Sierra users to build the code using GCC
  ...but GCC users lose out on TLS 1.3 support, since we can't weak-link
  enumeration constants.
  Fixes #2656
  Closes #2703
- [Ruslan Baratov brought this change]
  CMake: Remove unused 'output_var' from 'collect_true'
  Variable 'output_var' is not used and can be removed.
  Function 'collect_true' renamed to 'count_true'.
- [Ruslan Baratov brought this change]
  CMake: Remove unused functions
  Closes #2711
- KNOWN_BUGS: Stick to same family over SOCKS proxy
- libssh: goto DISCONNECT state on error, not SSH_SESSION_FREE
  ... because otherwise not everything get closed down correctly.
  Fixes #2708
  Closes #2712
- libssh: include line number in state change debug messages
  Closes #2713
- KNOWN_BUGS: Borland support is dropped, AIX problem is too old
- [Jeroen Ooms brought this change]
  example/crawler.c: simple crawler based on libxml2
  Closes #2706
- RELEASE-NOTES: synced
- DEPRECATE: include year when specifying date
- DEPRECATE: linkified
- DEPRECATE: mention the PR that disabled axTLS
- docs/DEPRECATE.md: spelling and minor formatting
- DEPRECATE: new doc describing planned item removals
  Closes #2704
- [Gisle Vanem brought this change]
  telnet: fix clang warnings
  telnet.c(1401,28): warning: cast from function call of type 'int' to
  non-matching type 'HANDLE' (aka 'void *') [-Wbad-function-cast]
  Fixes #2696
  Closes #2700
- docs: fix missed option name markups
- [Gaurav Malhotra brought this change]
  openssl: Remove some dead code
  Closes #2698
- openssl: make the requested TLS version the *minimum* wanted
  The code treated the set version as the *exact* version to require in
  the TLS handshake, which is not what other TLS backends do and probably
  not what most people expect either.
  Reported-by: Andreas Olsson
  Assisted-by: Gaurav Malhotra
  Fixes #2691
  Closes #2694
- RELEASE-NOTES: synced
- openssl: allow TLS 1.3 by default
  Reported-by: Andreas Olsson
  Fixes #2692
  Closes #2693
- [Adrian Peniak brought this change]
  CURLINFO_TLS_SSL_PTR.3: improve the example
  The previous example was a little bit confusing, because SSL* structure
  (or other "in use" SSL connection pointer) is not accessible after the
  transfer is completed, therefore working with the raw TLS library
  specific pointer needs to be done during transfer.
  Closes #2690
- travis: add a build using the synchronous name resolver
  ... since default uses the threaded one and we test the c-ares build
  already.
  Closes #2689
- configure: remove CURL_CHECK_NI_WITHSCOPEID too
  Since it isn't used either and requires the getnameinfo check
  Follow-up to 0aeca41702d2
- getnameinfo: not used
  Closes #2687
- easy_perform: use *multi_timeout() to get wait times
  ... and trim the threaded Curl_resolver_getsock() to return zero
  millisecond wait times during the first three milliseconds so that
  localhost or names in the OS resolver cache gets detected and used
  faster.
  Closes #2685
Max Dymond (27 Jun 2018)
- configure: Add dependent libraries after crypto
  The linker is pretty dumb and processes things left to right, keeping a
  tally of symbols it hasn't resolved yet. So, we need -ldl to appear
  after -lcrypto otherwise the linker won't find the dl functions.
  Closes #2684
Daniel Stenberg (27 Jun 2018)
- GOVERNANCE: linkify, changed some titles
- GOVERNANCE: add maintainer details/duties
- url: check Curl_conncache_add_conn return code
  ... it was previously unchecked in two places and thus errors could
  remain undetected and cause trouble.
  Closes #2681
- include/README: remove "hacking" advice, not the right place
- RELEASE-NOTES: synced
- CURLOPT_SSL_VERIFYPEER.3: fix syntax mistake
  Follow-up to b6a16afa0aa5
- netrc: use a larger buffer
  ... to work with longer passwords etc. Grow it from a 256 to a 4096
  bytes buffer.
  Reported-by: Dario Nieuwenhuis
  Fixes #2676
  Closes #2680
- [Patrick Schlangen brought this change]
  CURLOPT_SSL_VERIFYPEER.3: Add performance note
  Closes #2673
- [Javier Blazquez brought this change]
  multi: fix crash due to dangling entry in connect-pending list
  Fixes #2677
  Closes #2679
- ConnectionExists: make sure conn->data is set when "taking" a connection
  Follow-up to 2c15693.
  Bug #2674
  Closes #2675
- [Kevin R. Bulgrien brought this change]
  system.h: fix for gcc on 32 bit OpenServer
  Bug: https://curl.haxx.se/mail/lib-2018-06/0100.html
- [Raphael Gozzo brought this change]
  cmake: allow multiple SSL backends
  This will make possible to select the SSL backend (using
  curl_global_sslset()) even when the libcurl is built using CMake
  Closes #2665
- url: fix dangling conn->data pointer
  By masking sure to use the *current* easy handle with extracted
  connections from the cache, and make sure to NULLify the ->data pointer
  when the connection is put into the cache to make this mistake easier to
  detect in the future.
  Reported-by: Will Dietz
  Fixes #2669
  Closes #2672
- CURLOPT_INTERFACE.3: interface names not supported on Windows
- travis: run more tests for coverage check
  ... run a few more tortured based and run all tests event-based.
  Closes #2664
- multi: fix memory leak when stopped during name resolve
  When the application just started the transfer and then stops it while
  the name resolve in the background thread hasn't completed, we need to
  wait for the resolve to complete and then cleanup data accordingly.
  Enabled test 1553 again and added test 1590 to also check when the host
  name resolves successfully.
  Detected by OSS-fuzz.
  Closes #1968
Viktor Szakats (15 Jun 2018)
- maketgz: delete .bak files, fix indentation
  Ref: https://github.com/curl/curl/pull/2660
  Closes https://github.com/curl/curl/pull/2662
Daniel Stenberg (15 Jun 2018)
- runtests.pl: remove debug leftover from bb9a340c73f3
- curl-confopts.m4: fix typo from ed224f23d5beb
  Fixes my local configure to detect a custom installed c-ares without
  pkgconfig.
- docs/RELEASE-PROCEDURE.md: renamed to use .md extension
  Closes #2663
- RELEASE-PROCEDURE: gpg sign the tags
- RELEASE-NOTES: synced
- CURLOPT_HTTPAUTH.3: CURLAUTH_BEARER was added in 7.61.0
- [Mamta Upadhyay brought this change]
  maketgz: fix sed issues on OSX
  maketgz creates release tarballs and removes the -DEV string in curl
  version (e.g. 7.58.0-DEV), else -DEV shows up on command line when curl
  is run. maketgz works fine on linux but fails on OSX. Problem is with
  the sed commands that use option -i without an extension. Maketgz
  expects GNU sed instead of BSD and this simply won't work on OSX. Adding
  a backup extension .bak after -i fixes this issue
  Running the script as if on OSX gives this error:
  sed: -e: No such file or directory
  Adding a .bak extension resolves it
  Closes #2660
- configure: enhance ability to detect/build with static openssl
  Fix the -ldl and -ldl + -lpthread checks for OpenSSL, necessary for
  building with static libs without pkg-config.
  Reported-by: Marcel Raad
  Fixes #2199
  Closes #2659
- configure: use pkg-config for c-ares detection
  First check if there's c-ares information given as pkg-config info and use
  that as first preference.
  Reported-by: pszemus on github
  Fixes #2203
  Closes #2658
- GOVERNANCE.md: explains how this project is run
  Closes #2657
- KNOWN_BUGS: NTLM doen't support password with 
 character
  Closes #2120
- KNOWN_BUGS: slow connect to localhost on Windows
  Closes #2281
- [Matteo Bignotti brought this change]
  mk-ca-bundle.pl: make -u delete certdata.txt if found not changed
  certdata.txt should be deleted also when the process is interrupted by
  "same certificate downloaded, exiting"
  The certdata.txt is currently kept on disk even if you give the -u
  option
  Closes #2655
- progress: remove a set of unused defines
  Reported-by: Peter Wu
  Closes #2654
- TODO: "Option to refuse usernames in URLs" done
  Implemented by Bj
rn in 946ce5b61f
- [Lyman Epp brought this change]
  Curl_init_do: handle NULL connection pointer passed in
  Closes #2653
- runtests: support variables in <strippart>
  ... and make use of that to make 1455 work better without using a fixed
  local port number.
  Fixes #2649
  Closes #2650
- Curl_debug: remove dead printhost code
  The struct field is never set (since 5e0d9aea3) so remove the use of it
  and remove the connectdata pointer from the prototype.
  Reported-by: Tejas
  Bug: https://curl.haxx.se/mail/lib-2018-06/0054.html
  Closes #2647
Viktor Szakats (12 Jun 2018)
- schannel: avoid incompatible pointer warning
  with clang-6.0:
  ```
  vtls/schannel_verify.c: In function 'add_certs_to_store':
  vtls/schannel_verify.c:212:30: warning: passing argument 11 of 'CryptQueryObject' from incompatible pointer type [-Wincompatible-pointer-types]
                                &cert_context)) {
                                ^
  In file included from /usr/share/mingw-w64/include/schannel.h:10:0,
                   from /usr/share/mingw-w64/include/schnlsp.h:9,
                   from vtls/schannel.h:29,
                   from vtls/schannel_verify.c:40:
  /usr/share/mingw-w64/include/wincrypt.h:4437:26: note: expected 'const void **' but argument is of type 'CERT_CONTEXT ** {aka struct _CERT_CONTEXT **}'
     WINIMPM WINBOOL WINAPI CryptQueryObject (DWORD dwObjectType, const void *pvObject, DWORD dwExpectedContentTypeFlags, DWORD dwExpectedFormatTypeFlags, DWORD dwFlags,
                            ^~~~~~~~~~~~~~~~
  ```
  Ref: https://msdn.microsoft.com/library/windows/desktop/aa380264
  Closes https://github.com/curl/curl/pull/2648
Daniel Stenberg (12 Jun 2018)
- [Robert Prag brought this change]
  schannel: support selecting ciphers
  Given the contstraints of SChannel, I'm exposing these as the algorithms
  themselves instead; while replicating the ciphersuite as specified by
  OpenSSL would have been preferable, I found no way in the SChannel API
  to do so.
  To use this from the commandline, you need to pass the names of contants
  defining the desired algorithms. For example, curl --ciphers
  "CALG_SHA1:CALG_RSA_SIGN:CALG_RSA_KEYX:CALG_AES_128:CALG_DH_EPHEM"
  https://github.com The specific names come from wincrypt.h
  Closes #2630
- [Bernhard M. Wiedemann brought this change]
  test 46: make test pass after 2025
  shifting the expiry date to 2037 for now
  to be before the possibly problematic year 2038
  similar in spirit to commit e6293cf8764e9eecb
  Closes #2646
- [Marian Klymov brought this change]
  cppcheck: fix warnings
  - Get rid of variable that was generating false positive warning
  (unitialized)
  - Fix issues in tests
  - Reduce scope of several variables all over
  etc
  Closes #2631
- openssl: assume engine support in 1.0.1 or later
  Previously it was checked for in configure/cmake, but that would then
  leave other build systems built without engine support.
  While engine support probably existed prior to 1.0.1, I decided to play
  safe. If someone experience a problem with this, we can widen the
  version check.
  Fixes #2641
  Closes #2644
- RELEASE-NOTES: synced
- RELEASE-PROCEDURE: update the release calendar for 2019
- [Gisle Vanem brought this change]
  boringssl + schannel: undef X509_NAME in lib/schannel.h
  Fixes the build problem when both boringssl and schannel are enabled.
  Fixes #2634
  Closes #2643
- [Vladimir Kotal brought this change]
  mk-ca-bundle.pl: leave certificate name untouched in decode()
  Closes #2640
- [Rikard Falkeborn brought this change]
  tests/libtests/Makefile.am: Add lib1521.c to CLEANFILES
  This removes the generated lib1521.c when running make clean.
  Closes #2633
- [Rikard Falkeborn brought this change]
  tests/libtest: Add lib1521 to nodist_SOURCES
  Since 467da3af0, lib1521.c is generated instead of checked in. According
  to the commit message, the intention was to remove it from the tarball
  as well. However, it is still present when running make dist. To remove
  it, add it to nodist_lib1521_SOURCES. This also means there is no need
  for the manually added dist-rule in the Makefile.
  Also update CMakelists.txt to handle the fact that we now may have
  nodist_SOURCES.
- [Stephan M
hlstrasser brought this change]
  system.h: add support for IBM xlc C compiler
  Added a section to system.h guarded with __xlc__ for the IBM xml C
  compiler. Before this change the section titled 'generic "safe guess" on
  old 32 bit style' was used, which resulted in a wrong definition of
  CURL_TYPEOF_CURL_SOCKLEN_T, and for 64-bit also CURL_TYPEOF_CURL_OFF_T
  was wrong.
  Compilation warnings fixed with this change:
    CC       libcurl_la-ftp.lo
  "ftp.c", line 290.55: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  "ftp.c", line 293.48: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  "ftp.c", line 1070.49: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  "ftp.c", line 1154.53: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  "ftp.c", line 1187.51: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
    CC       libcurl_la-connect.lo
  "connect.c", line 448.56: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  "connect.c", line 516.66: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  "connect.c", line 687.55: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  "connect.c", line 696.55: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
    CC       libcurl_la-tftp.lo
  "tftp.c", line 1115.33: 1506-280 (W) Function argument assignment between types "unsigned long* restrict" and "int*" is not allowed.
  Closes #2637
- cmdline-opts/cert-type.d: mention "p12" as a recognized type as well
Viktor Szakats (3 Jun 2018)
- spelling fixes
  Detected using the `codespell` tool (version 1.13.0).
  Also secure and fix an URL.
Daniel Stenberg (2 Jun 2018)
- axtls: follow-up spell fix of comment
- axTLS: not considered fit for use
  URL: https://curl.haxx.se/mail/lib-2018-06/0000.html
  This is step one. It adds #error statements that require source edits to
  make curl build again if asked to use axTLS. At a later stage we might
  remove the axTLS specific code completely.
  Closes #2628
- build: remove the Borland specific makefiles
  According to the user survey 2018, not even one out of 670 users use
  them. Nobody on the mailing list spoke up for them either.
  Closes #2629
- curl_addrinfo: use same #ifdef conditions in source as header
  ... for curl_dofreeaddrinfo
- multi: remove a DEBUGF()
  ... it might call infof() with a NULL first argument that isn't harmful
  but makes it not do anything. The infof() line is not very useful
  anymore, it has served it purpose. Good riddance!
  Fixes #2627
- [Alibek.Jorajev brought this change]
  CURLOPT_RESOLVE: always purge old entry first
  If there's an existing entry using the selected name.
  Closes #2622
- fnmatch: use the system one if available
  If configure detects fnmatch to be available, use that instead of our
  custom one for FTP wildcard pattern matching. For standard compliance,
  to reduce our footprint and to use already well tested and well
  exercised code.
  A POSIX fnmatch behaves slightly different than the internal function
  for a few test patterns currently and the macOS one yet slightly
  different. Test case 1307 is adjusted for these differences.
  Closes #2626
Patrick Monnerat (31 May 2018)
- os400: add new option in ILE/RPG binding
  Follow-up to commit 946ce5b
Daniel Stenberg (31 May 2018)
- tests/libtest/.gitignore: follow-up fix to ignore lib5* too
- KNOWN_BUGS: CURL_GLOBAL_SSL
  Closes #2276
- [Bernhard Walle brought this change]
  configure: check for declaration of getpwuid_r
  On our x86 Android toolchain, getpwuid_r is implemented but the header
  is missing:
   netrc.c:81:7: error: implicit declaration of function 'getpwuid_r' [-Werror=implicit-function-declaration]
  Unfortunately, the function is used in curl_ntlm_wb.c, too, so I moved
  the prototype to curl_setup.h.
  Signed-off-by: Bernhard Walle <bernhard@bwalle.de>
  Closes #2609
- [Rikard Falkeborn brought this change]
  tests: update .gitignore for libtests
  Closes #2624
- [Rikard Falkeborn brought this change]
  strictness: correct {infof, failf} format specifiers
  Closes #2623
- [Bj
rn Stenberg brought this change]
  option: disallow username in URL
  Adds CURLOPT_DISALLOW_USERNAME_IN_URL and --disallow-username-in-url. Makes
  libcurl reject URLs with a username in them.
  Closes #2340
- libcurl-security.3: improved layout for two rememdy lists
- libcurl-security.3: refer to URL instead of in-source markdown file
Viktor Szakats (30 May 2018)
- curl.rc: embed manifest for correct Windows version detection
  * enable it in `src/Makefile.m32`
  * enable it in `winbuild/MakefileBuild.vc` if a custom manifest is
    _not_ enabled via the existing `EMBED_MANIFEST` option
  * enable it for all Windows CMake builds (also disable the built-in
    minimal manifest, added by CMake by default.)
  For other build systems, add the `-DCURL_EMBED_MANIFEST` option to
  the list of RC (Resource Compiler) flags to enable the manifest
  included in `src/curl.rc`. This may require to disable whatever
  automatic or other means in which way another manifest is added to
  `curl.exe`.
  Notice that Borland C doesn't support this method due to a
  long-pending resource compiler bug. Watcom C may also not handle
  it correctly when the `-zm` `wrc` option is used (this option may
  be unnecessary though) and regardless of options in certain earlier
  revisions of the 2.0 beta version.
  Closes https://github.com/curl/curl/pull/1221
  Fixes https://github.com/curl/curl/issues/2591
Patrick Monnerat (30 May 2018)
- os400: sync EBCDIC wrappers and ILE/RPG binding with latest options
- os400: implement mime api EBCDIC wrappers
  Also sync ILE/RPG binding to define the new functions.
Daniel Stenberg (29 May 2018)
- setopt: add TLS 1.3 ciphersuites
  Adds CURLOPT_TLS13_CIPHERS and CURLOPT_PROXY_TLS13_CIPHERS.
  curl: added --tls13-ciphers and --proxy-tls13-ciphers
  Fixes #2435
  Reported-by: zzq1015 on github
  Closes #2607
- configure: override AR_FLAGS to silence warning
  The automake default ar flags are 'cru', but the 'u' flag in there
  causes warnings on many modern Linux distros. Removing 'u' may have a
  minor performance impact on older distros but should not cause harm.
  Explained on the automake mailing list already back in April 2015:
  https://www.mail-archive.com/automake-patches@gnu.org/msg07705.html
  Reported-by: elephoenix on github
  Fixes #2617
  Closes #2619
Sergei Nikulov (29 May 2018)
- cmake: fixed comments in compile checks code
Daniel Stenberg (29 May 2018)
- INSTALL: LDFLAGS=-Wl,-R/usr/local/ssl/lib
  ... the older description doesn't work
  Reported-by: Peter Varga
  Fixes #2615
  Closes #2616
- [Will Dietz brought this change]
  KNOWN_BUGS: restore text regarding #2101.
  This was added earlier but appears to have been removed accidentally.
  AFAICT this is very much still an issue.
  -----
  I say "accidentally" because the text seems to have harmlessly snuck
  into [1] (which makes no mention of it).  [1] was later reverted for
  unspecified reasons in [2], presumably because the mentioned issue was
  fixed or invalid.
  [1] de9fac00c40db321d44fa6fbab6eb62ec4c83998
  [2] 16d1f369403cbb04bd7b085eabbeebf159473fc2
  Closes #2618
- fnmatch: insist on escaped bracket to match
  A non-escaped bracket ([) is for a character group - as documented. It
  will *not* match an individual bracket anymore. Test case 1307 updated
  accordingly to match.
  Problem detected by OSS-Fuzz, although this fix is probably not a final
  fix for the notorious timeout issues.
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=8525
  Closes #2614
Patrick Monnerat (28 May 2018)
- psl: use latest psl and refresh it periodically
  The latest psl is cached in the multi or share handle. It is refreshed
  before use after 72 hours.
  New share lock CURL_LOCK_DATA_PSL controls the psl cache sharing.
  If the latest psl is not available, the builtin psl is used.
  Reported-by: Yaakov Selkowitz
  Fixes #2553
  Closes #2601
Daniel Stenberg (28 May 2018)
- [Fabrice Fontaine brought this change]
  configure: fix ssh2 linking when built with a static mbedtls
  The ssh2 pkg-config file could contain the following lines when build
  with a static version of mbedtls:
     Libs: -L${libdir} -lssh2 /xxx/libmbedcrypto.a
     Libs.private: /xxx/libmbedcrypto.a
  This static mbedtls library must be used to correctly detect ssh2
  support and this library must be copied in libcurl.pc otherwise
  compilation of any application (such as upmpdcli) with libcurl will fail
  when trying to found mbedtls functions included in libssh2.  So, replace
  pkg-config --libs-only-l by pkg-config --libs.
  Fixes:
   - http://autobuild.buildroot.net/results/43e24b22a77f616d6198c10435dcc23cc3b9088a
  Signed-off-by: Fabrice Fontaine <fontaine.fabrice@gmail.com>
  Closes #2613
- RELEASE-NOTES: synced
- [Bernhard Walle brought this change]
  cmake: check for getpwuid_r
  The autotools-based build system does it, so we do it also in CMake.
  Bug: #2609
  Signed-off-by: Bernhard Walle <bernhard@bwalle.de>
- cmdline-opts/gen.pl: warn if mutexes: or see-also: list non-existing options
- [Frank Gevaerts brought this change]
  curl.1: Fix cmdline-opts reference errors.
  --data, --form, and --ntlm were declared to be mutually exclusive with
  non-existing options. --data and --form referred to --upload (which is
  short for --upload-file and therefore did work, so this one was merely
  a bit confusing), --ntlm referred to --negotiated instead of --negotiate.
  Closes #2612
- [Frank Gevaerts brought this change]
  docs: fix cmdline-opts metadata headers case consistency.
  Almost all headers start with an uppercase letter, but some didn't.
- mailmap: Max Savenkov
Sergei Nikulov (28 May 2018)
- [Max Savenkov brought this change]
  Fix the test for fsetxattr and strerror_r tests in CMake to work without compiling
Daniel Stenberg (27 May 2018)
- mailmap: a Richard Alcock fixup
- [Richard Alcock brought this change]
  schannel: add failf calls for client certificate failures
  Closes #2604
- [Richard Alcock brought this change]
  winbuild: In MakefileBuild.vc fix typo DISTDIR->DIRDIST
  Change requirement from $(DISTDIR) to $(DIRDIST)
  closes #2603
- [Richard Alcock brought this change]
  winbuild: only delete OUTFILE if it exists
  This removes the slightly annoying "Could not file LIBCURL_OBJS.inc" and
  "Could not find CURL_OBJS.inc.inc" message when building into a clean
  folder.
  closes #2602
- [Alejandro R. Sede
o brought this change]
  content_encoding: handle zlib versions too old for Z_BLOCK
  Fallback on Z_SYNC_FLUSH when Z_BLOCK is not available.
  Fixes #2606
  Closes #2608
- multi: provide a socket to wait for in Curl_protocol_getsock
  ... even when there's no protocol specific handler setup.
  Bug: https://curl.haxx.se/mail/lib-2018-05/0062.html
  Reported-by: Sean Miller
  Closes #2600
- [Linus Lewandowski brought this change]
  httpauth: add support for Bearer tokens
  Closes #2102
- TODO: CURLINFO_PAUSE_STATE
  Closes #2588
Sergei Nikulov (24 May 2018)
- cmake: set -d postfix for debug builds if not specified
         using -DCMAKE_DEBUG_POSTFIX explicitly
         fixes #2121, obsoletes #2384
Daniel Stenberg (23 May 2018)
- configure: add basic test of --with-ssl prefix
  When given a prefix, the $PREFIX_OPENSSL/lib/openssl.pc or
  $PREFIX_OPENSSL/include/openssl/ssl.h files must be present or cause an
  error. Helps users detect when giving configure the wrong path.
  Reported-by: Oleg Pudeyev
  Assisted-by: Per Malmberg
  Fixes #2580
Patrick Monnerat (22 May 2018)
- http resume: skip body if http code 416 (range error) is ignored.
  This avoids appending error data to already existing good data.
  Test 92 is updated to match this change.
  New test 1156 checks all combinations of --range/--resume, --fail,
  Content-Range header and http status code 200/416.
  Fixes #1163
  Reported-By: Ithubg on github
  Closes #2578
Daniel Stenberg (22 May 2018)
- tftp: make sure error is zero terminated before printfing it
- configure: add missing m4/ax_compile_check_sizeof.m4
  follow-up to mistake in 6876ccf90b4
Jay Satiro (22 May 2018)
- [Johannes Schindelin brought this change]
  schannel: make CAinfo parsing resilient to CR/LF
  OpenSSL has supported --cacert for ages, always accepting LF-only line
  endings ("Unix line endings") as well as CR/LF line endings ("Windows
  line endings").
  When we introduced support for --cacert also with Secure Channel (or in
  cURL speak: "WinSSL"), we did not take care to support CR/LF line
  endings, too, even if we are much more likely to receive input in that
  form when using Windows.
  Let's fix that.
  Happily, CryptQueryObject(), the function we use to parse the ca-bundle,
  accepts CR/LF input already, and the trailing LF before the END
  CERTIFICATE marker catches naturally any CR/LF line ending, too. So all
  we need to care about is the BEGIN CERTIFICATE marker. We do not
  actually need to verify here that the line ending is CR/LF. Just
  checking for a CR or an LF is really plenty enough.
  Signed-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>
  Closes https://github.com/curl/curl/pull/2592
Daniel Stenberg (22 May 2018)
- CURLOPT_ACCEPT_ENCODING.3: add brotli and clarify a bit
- RELEASE-NOTES: synced
- KNOWN_BUGS: mention the -O with %-encoded file names
  Closes #2573
- checksrc: make sure sizeof() is used *with* parentheses
  ... and unify the source code to adhere.
  Closes #2563
- curl: added --styled-output
  It is enabled by default, so --no-styled-output will switch off the
  detection/use of bold headers.
  Closes #2538
- curl: show headers in bold
  The feature is only enabled if the output is believed to be a tty.
  -J: There's some minor differences and improvements in -J handling, as
  now J should work with -i and it actually creates a file first using the
  initial name and then *renames* that to the one found in
  Content-Disposition (if any).
  -i: only shows headers for HTTP transfers now (as documented).
  Previously it would also show for pieces of the transfer that were HTTP
  (for example when doing FTP over a HTTP proxy).
  -i: now shows trailers as well. Previously they were not shown at all.
  --libcurl: the CURLOPT_HEADER is no longer set, as the header output is
  now done in the header callback.
- configure: compile-time SIZEOF checks
  ... instead of exeucting code to get the size. Removes the use of
  LD_LIBRARY_PATH for this.
  Fixes #2586
  Closes #2589
  Reported-by: Bernhard Walle
- configure: replace AC_TRY_RUN with CURL_RUN_IFELSE
  ... and export LD_LIBRARY_PATH properly. This is a follow-up from
  2d4c215.
  Fixes #2586
  Reported-by: Bernhard Walle
- docs: clarify CURLOPT_HTTPGET somewhat
  Reported-by: bsammon on github
  Fixes #2590
- curl_fnmatch: only allow two asterisks for matching
  The previous limit of 5 can still end up in situation that takes a very
  long time and consumes a lot of CPU.
  If there is still a rare use case for this, a user can provide their own
  fnmatch callback for a version that allows a larger set of wildcards.
  This commit was triggered by yet another OSS-Fuzz timeout due to this.
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=8369
  Closes #2587
- checksrc: fix too long line
  follow-up to e05ad5d
- [Aleks brought this change]
  docs: mention HAproxy protocol "version 1"
  ...as there's also a version 2.
  Closes #2579
- examples/progressfunc: make it build on older libcurls
  This example was changed in ce2140a8c1 to use the new microsecond based
  getinfo option. This change makes it conditionally keep using the older
  option so that the example still builds with older libcurl versions.
  Closes #2584
- stub_gssapi: fix numerous 'unused parameter' warnings
  follow-up to d9e92fd9fd1d
- [Philip Prindeville brought this change]
  getinfo: add microsecond precise timers for various intervals
  Provide a set of new timers that return the time intervals using integer
  number of microseconds instead of floats.
  The new info names are as following:
  CURLINFO_APPCONNECT_TIME_T
  CURLINFO_CONNECT_TIME_T
  CURLINFO_NAMELOOKUP_TIME_T
  CURLINFO_PRETRANSFER_TIME_T
  CURLINFO_REDIRECT_TIME_T
  CURLINFO_STARTTRANSFER_TIME_T
  CURLINFO_TOTAL_TIME_T
  Closes #2495
- openssl: acknowledge --tls-max for default version too
  ... previously it only used the max setting if a TLS version was also
  explicitly asked for.
  Reported-by: byte_bucket
  Fixes #2571
  Closes #2572
- bump: start working on the pending 7.61.0
- [Dagobert Michelsen brought this change]
  tests/libtest/Makefile: Do not unconditionally add gcc-specific flags
  The warning flag leads e.g. Sun Studio compiler to bail out.
  Closes #2576
- schannel_verify: fix build for non-schannel
Jay Satiro (16 May 2018)
- rand: fix typo
- schannel: disable manual verify if APIs not available
  .. because original MinGW and old compilers do not have the Windows API
  definitions needed to support manual verification.
- [Archangel_SDY brought this change]
  schannel: disable client cert option if APIs not available
  Original MinGW targets Windows 2000 by default, which lacks some APIs and
  definitions for this feature. Disable it if these APIs are not available.
  Closes https://github.com/curl/curl/pull/2522
Version 7.60.0 (15 May 2018)
Daniel Stenberg (15 May 2018)
- RELEASE-NOTES: 7.60.0 release
- THANKS: added people from the curl 7.60.0 release
- docs/libcurl/index.html: removed
  The HTML files are long gone from the dist, now remove the last HTML
  file pointing to those missing files.
- [steini2000 brought this change]
  http2: remove unused variable
  Closes #2570
- [steini2000 brought this change]
  http2: use easy handle of stream for logging
- gcc: disable picky gcc-8 function pointer warnings in two places
  Reported-by: Rikard Falkeborn
  Bug: #2560
  Closes #2569
- http2: use the correct function pointer typedef
  Fixes gcc-8 picky compiler warnings
  Reported-by: Rikard Falkeborn
  Bug: #2560
  Closes #2568
- CODE_STYLE: mention return w/o parens, but sizeof with
  ... and remove the github markdown syntax so that it renders better on
  the web site. Also, don't use back-ticks inlined to allow the CSS to
  highlight source code better.
- [Rikard Falkeborn brought this change]
  examples: Fix format specifiers
  Closes #2561
- [Rikard Falkeborn brought this change]
  tool: Fix format specifiers
- [Rikard Falkeborn brought this change]
  ntlm: Fix format specifiers
- [Rikard Falkeborn brought this change]
  tests: Fix format specifiers
- [Rikard Falkeborn brought this change]
  lib: Fix format specifiers
- contributors.sh: use "on github", not at
- http2: getsock fix for uploads
  When there's an upload in progress, make sure to wait for the socket to
  become writable.
  Detected-by: steini2000 on github
  Bug: #2520
  Closes #2567
- pingpong: fix response cache memcpy overflow
  Response data for a handle with a large buffer might be cached and then
  used with the "closure" handle when it has a smaller buffer and then the
  larger cache will be copied and overflow the new smaller heap based
  buffer.
  Reported-by: Dario Weisser
  CVE: CVE-2018-1000300
  Bug: https://curl.haxx.se/docs/adv_2018-82c2.html
- http: restore buffer pointer when bad response-line is parsed
  ... leaving the k->str could lead to buffer over-reads later on.
  CVE: CVE-2018-1000301
  Assisted-by: Max Dymond
  Detected by OSS-Fuzz.
  Bug: https://curl.haxx.se/docs/adv_2018-b138.html
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=7105
Patrick Monnerat (13 May 2018)
- cookies: do not take cookie name as a parameter
  RFC 6265 section 4.2.1 does not set restrictions on cookie names.
  This is a follow-up to commit 7f7fcd0.
  Also explicitly check proper syntax of cookie name/value pair.
  New test 1155 checks that cookie names are not reserved words.
  Reported-By: anshnd at github
  Fixes #2564
  Closes #2566
Daniel Stenberg (12 May 2018)
- smb: reject negative file sizes
  Assisted-by: Max Dymond
  Detected by OSS-Fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=8245
- setup_transfer: deal with both sockets being -1
  Detected by Coverity; CID 1435559.  Follow-up to f8d608f38d00. It would
  index the array with -1 if neither index was a socket.
- travis: add build using NSS
  Closes #2558
- [Sunny Purushe brought this change]
  openssl: change FILE ops to BIO ops
  To make builds with VS2015 work. Recent changes in VS2015 _IOB_ENTRIES
  handling is causing problems. This fix changes the OpenSSL backend code
  to use BIO functions instead of FILE I/O functions to circumvent those
  problems.
  Closes #2512
- travis: add a build using WolfSSL
  Assisted-by: Dan Fandrich
  Closes #2528
- RELEASE-NOTES: typo
- RELEASE-NOTES: synced
- [Daniel Gustafsson brought this change]
  URLs: fix one more http url
  This file wasn't included in commit 4af40b3646d3b09 which updated all
  haxx.se http urls to https. The file was committed prior to that update,
  but may have been merged after it and hence didn't get updated.
  Closes #2550
- github/lock: auto-lock closed issues after 90 days of inactivity
- vtls: fix missing commas
  follow-up to e66cca046cef
- vtls: use unified "supports" bitfield member in backends
  ... instead of previous separate struct fields, to make it easier to
  extend and change individual backends without having to modify them all.
  closes #2547
- transfer: don't unset writesockfd on setup of multiplexed conns
  Curl_setup_transfer() can be called to setup a new individual transfer
  over a multiplexed connection so it shouldn't unset writesockfd.
  Bug: #2520
  Closes #2549
- [Frank Gevaerts brought this change]
  configure: put CURLDEBUG and DEBUGBUILD in lib/curl_config.h
  They are removed from the compiler flags.
  This ensures that make dependency tracking will force a rebuild whenever
  configure --enable-debug or --enable-curldebug changes.
  Closes #2548
- http: don't set the "rewind" flag when not uploading anything
  It triggers an assert.
  Detected by OSS-Fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=8144
  Closes #2546
- travis: add an mbedtls build
  Closes #2531
- configure: only check for CA bundle for file-using SSL backends
  When only building with SSL backends that don't use the CA bundle file
  (by default), skip the check.
  Fixes #2543
  Fixes #2180
  Closes #2545
- ssh-libssh.c: fix left shift compiler warning
  ssh-libssh.c:2429:21: warning: result of '1 << 31' requires 33 bits to
  represent, but 'int' only has 32 bits [-Wshift-overflow=]
  'len' will never be that big anyway so I converted the run-time check to
  a regular assert.
- [Stephan M
hlstrasser brought this change]
  URL: fix ASCII dependency in strcpy_url and strlen_url
  Commit 3c630f9b0af097663a64e5c875c580aa9808a92b partially reverted the
  changes from commit dd7521bcc1b7a6fcb53c31f9bd1192fcc884bd56 because of
  the problem that strcpy_url() was modified unilaterally without also
  modifying strlen_url(). As a consequence strcpy_url() was again
  depending on ASCII encoding.
  This change fixes strlen_url() and strcpy_url() in parallel to use a
  common host-encoding independent criterion for deciding whether an URL
  character must be %-escaped.
  Closes #2535
- [Denis Ollier brought this change]
  docs: remove extraneous commas in man pages
  Closes #2544
- RELEASE-NOTES: synced
- Revert "TODO: remove configure --disable-pthreads"
  This reverts commit d5d683a97f9765bddfd964fe32e137aa6e703ed3.
  --disable-pthreads can be used to disable pthreads and get the threaded
  resolver to use the windows threading when building with mingw.
- vtls: don't define MD5_DIGEST_LENGTH for wolfssl
  ... as it defines it (too)
- TODO: remove configure --disable-pthreads
Jay Satiro (2 May 2018)
- [David Garske brought this change]
  wolfssl: Fix non-blocking connect
  Closes https://github.com/curl/curl/pull/2542
Daniel Stenberg (30 Apr 2018)
- CURLOPT_URL.3: add ENCODING section [ci skip]
  Feedback-by: Michael Kilburn
- KNOWN_BUGS: Client cert with Issuer DN differs between backends
  Closes #1411
- KNOWN_BUGS: Passive transfer tries only one IP address
  Closes #1508
- KNOWN_BUGS: --upload-file . hang if delay in STDIN
  Closes #2051
- KNOWN_BUGS: Connection information when using TCP Fast Open
  Closes #1332
- travis: enable libssh2 on both macos and Linux
  It seems to not be detected by default anymore (which is a bug I
  believe)
  Closes #2541
- TODO: Support the clienthello extension
  Closes #2299
- TODO: CLOEXEC
  Closes #2252
- tests: provide 'manual' as a feature to optionally require
  ... and make test 1026 rely on that feature so that --disable-manual
  builds don't cause test failures.
  Reported-by: Max Dymond and Anders Roxell
  Fixes #2533
  Closes #2540
- CURLINFO_PROTOCOL.3: mention the existing defined names
Jay Satiro (27 Apr 2018)
- [Daniel Gustafsson brought this change]
  cookies: remove unused macro
  Commit 2bc230de63 made the macro MAX_COOKIE_LINE_TXT become unused,
  so remove as it's not part of the published API.
  Closes https://github.com/curl/curl/pull/2537
Daniel Stenberg (27 Apr 2018)
- [Daniel Gustafsson brought this change]
  checksrc: force indentation of lines after an else
  This extends the INDENTATION case to also handle 'else' statements
  and require proper indentation on the following line. Also fixes the
  offending cases found in the codebase.
  Closes #2532
- http2: fix null pointer dereference in http2_connisdead
  This function can get called on a connection that isn't setup enough to
  have the 'recv_underlying' function pointer initialized so it would try
  to call the NULL pointer.
  Reported-by: Dario Weisser
  Follow-up to db1b2c7fe9b093f8 (never shipped in a release)
  Closes #2536
- http2: get rid of another strstr()
  Follow-up to 1514c44655e12e: replace another strstr() call done on a
  buffer that might not be zero terminated - with a memchr() call, even if
  we know the substring will be found.
  Assisted-by: Max Dymond
  Detected by OSS-Fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=8021
  Closes #2534
- cyassl: adapt to libraries without TLS 1.0 support built-in
  WolfSSL doesn't enable it by default anymore
- configure: provide --with-wolfssl as an alias for --with-cyassl
- RELEASE-NOTES: synced
- [Daniel Gustafsson brought this change]
  os400.c: fix ASSIGNWITHINCONDITION checksrc warnings
  All occurrences of assignment within conditional expression in
  os400sys.c rewritten into two steps: first assignment and then the check
  on the success of the assignment. Also adjust related incorrect brace
  positions to match project indentation style.
  This was spurred by seeing "if((inp = input_token))", but while in there
  all warnings were fixed.
  There should be no functional change from these changes.
  Closes #2525
- [Daniel Gustafsson brought this change]
  cookies: ensure that we have cookies before writing jar
  The jar should be written iff there are cookies, so ensure that we still
  have cookies after expiration to avoid creating an empty file.
  Closes #2529
- strcpy_url: only %-encode values >= 0x80
  OSS-Fuzz detected
  https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=8000
  Broke in dd7521bcc1b7
- mime: avoid NULL pointer dereference risk
  Coverity detected, CID 1435120
  Closes #2527
- [Stephan M
hlstrasser brought this change]
  ctype: restore character classification for non-ASCII platforms
  With commit 4272a0b0fc49a1ac0ceab5c4a365c9f6ab8bf8e2 curl-speficic
  character classification macros and functions were introduced in
  curl_ctype.[ch] to avoid dependencies on the locale. This broke curl on
  non-ASCII, e.g. EBCDIC platforms. This change restores the previous set
  of character classification macros when CURL_DOES_CONVERSIONS is
  defined.
  Closes #2494
- ftplistparser: keep state between invokes
  Fixes FTP wildcard parsing when done over a number of read buffers.
  Regression from f786d1f14
  Reported-by: wncboy on github
  Fixes #2445
  Closes #2526
- examples/http2-upload: expand buffer to avoid silly warning
  http2-upload.c:135:44: error: 
%02d
 directive output may be truncated
  writing between 2 and 11 bytes into a region of size between 8 and 17
- examples/sftpuploadresume: typecast fseek argument to long
  /docs/examples/sftpuploadresume.c:102:12: warning: conversion to 'long
  int' from 'curl_off_t {aka long long int}' may alter its value
- Revert "ftplistparser: keep state between invokes"
  This reverts commit abbc8457d85aca74b7cfda1d394b0844932b2934.
  Caused fuzzer problems on travis not seen when this was a PR!
- Curl_memchr: zero length input can't match
  Avoids undefined behavior.
  Reported-by: Geeknik Labs
- ftplistparser: keep state between invokes
  Fixes FTP wildcard parsing when doing over a number of read buffers.
  Regression from f786d1f14
  Reported-by: wncboy on github
  Fixes #2445
  Closes #2519
- ftplistparser: renamed some members and variables
  ... to make them better spell out what they're for.
- RELEASE-NOTES: synced
- [Christian Schmitz brought this change]
  curl_global_sslset: always provide available backends
  Closes #2499
- http2: convert an assert to run-time check
  Fuzzing has proven we can reach code in on_frame_recv with status_code
  not having been set, so let's detect that in run-time (instead of with
  assert) and error error accordingly.
  (This should no longer happen with the latest nghttp2)
  Detected by OSS-Fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=7903
  Closes #2514
- curl.1: clarify that options and URLs can be mixed
  Fixes #2515
  Closes #2517
Jay Satiro (23 Apr 2018)
- [Archangel_SDY brought this change]
  CURLOPT_SSLCERT.3: improve WinSSL-specific usage info
  Ref: https://github.com/curl/curl/pull/2376#issuecomment-381858780
  Closes https://github.com/curl/curl/pull/2504
- [Archangel_SDY brought this change]
  schannel: fix build error on targets <= XP
  - Use CRYPT_STRING_HEX instead of CRYPT_STRING_HEXRAW since XP doesn't
    support the latter.
  Ref: https://github.com/curl/curl/pull/2376#issuecomment-382153668
  Closes https://github.com/curl/curl/pull/2504
Daniel Stenberg (23 Apr 2018)
- Revert "ftplistparser: keep state between invokes"
  This reverts commit 8fb78f9ddc6d858d630600059b8ad84a80892fd9.
  Unfortunately this fix introduces memory leaks I've not been able to fix
  in several days. Reverting this for now to get the leaks fixed.
Jay Satiro (21 Apr 2018)
- tool_help: clarify --max-time unit of time is seconds
  Before:
   -m, --max-time <time> Maximum time allowed for the transfer
  After:
   -m, --max-time <seconds> Maximum time allowed for the transfer
Daniel Stenberg (20 Apr 2018)
- http2: handle GOAWAY properly
  When receiving REFUSED_STREAM, mark the connection for close and retry
  streams accordingly on another/fresh connection.
  Reported-by: Terry Wu
  Fixes #2416
  Fixes #1618
  Closes #2510
- http2: clear the "drain counter" when a stream is closed
  This fixes the notorious "httpc->drain_total >= data->state.drain"
  assert.
  Reported-by: Anders Bakken
  Fixes #1680
  Closes #2509
- http2: avoid strstr() on data not zero terminated
  It's not strictly clear if the API contract allows us to call strstr()
  on a string that isn't zero terminated even when we know it will find
  the substring, and clang's ASAN check dislikes us for it.
  Also added a check of the return code in case it fails, even if I can't
  think of a situation how that can trigger.
  Detected by OSS-Fuzz
  Closes #2513
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=7760
- [Stephan M
hlstrasser brought this change]
  openssl: fix subjectAltName check on non-ASCII platforms
  Curl_cert_hostcheck operates with the host character set, therefore the
  ASCII subjectAltName string retrieved with OpenSSL must be converted to
  the host encoding before comparison.
  Closes #2493
Jay Satiro (20 Apr 2018)
- openssl: Add support for OpenSSL 1.1.1 verbose-mode trace messages
  - Support handling verbose-mode trace messages of type
    SSL3_RT_INNER_CONTENT_TYPE, SSL3_MT_ENCRYPTED_EXTENSIONS,
    SSL3_MT_END_OF_EARLY_DATA, SSL3_MT_KEY_UPDATE, SSL3_MT_NEXT_PROTO,
    SSL3_MT_MESSAGE_HASH
  Reported-by: iz8mbw@users.noreply.github.com
  Fixes https://github.com/curl/curl/issues/2403
Daniel Stenberg (19 Apr 2018)
- ftplistparser: keep state between invokes
  Regression from f786d1f14
  Reported-by: wncboy on github
  Fixes #2445
  Closes #2508
- detect_proxy: only show proxy use if it had contents
- http2: handle on_begin_headers() called more than once
  This triggered an assert if called more than once in debug mode (and a
  memory leak if not debug build). With the right sequence of HTTP/2
  headers incoming it can happen.
  Detected by OSS-Fuzz
  Closes #2507
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=7764
Jay Satiro (18 Apr 2018)
- [Dan McNulty brought this change]
  schannel: add support for CURLOPT_CAINFO
  - Move verify_certificate functionality in schannel.c into a new
    file called schannel_verify.c. Additionally, some structure defintions
    from schannel.c have been moved to schannel.h to allow them to be
    used in schannel_verify.c.
  - Make verify_certificate functionality for Schannel available on
    all versions of Windows instead of just Windows CE. verify_certificate
    will be invoked on Windows CE or when the user specifies
    CURLOPT_CAINFO and CURLOPT_SSL_VERIFYPEER.
  - In verify_certificate, create a custom certificate chain engine that
    exclusively trusts the certificate store backed by the CURLOPT_CAINFO
    file.
  - doc updates of --cacert/CAINFO support for schannel
  - Use CERT_NAME_SEARCH_ALL_NAMES_FLAG when invoking CertGetNameString
    when available. This implements a TODO in schannel.c to improve
    handling of multiple SANs in a certificate. In particular, all SANs
    will now be searched instead of just the first name.
  - Update tool_operate.c to not search for the curl-ca-bundle.crt file
    when using Schannel to maintain backward compatibility. Previously,
    any curl-ca-bundle.crt file found in that search would have been
    ignored by Schannel. But, with CAINFO support, the file found by
    that search would have been used as the certificate store and
    could cause issues for any users that have curl-ca-bundle.crt in
    the search path.
  - Update url.c to not set the build time CURL_CA_BUNDLE if the selected
    SSL backend is Schannel. We allow setting CA location for schannel
    only when explicitly specified by the user via CURLOPT_CAINFO /
    --cacert.
  - Add new test cases 3000 and 3001. These test cases check that the first
    and last SAN, respectively, matches the connection hostname. New test
    certificates have been added for these cases. For 3000, the certificate
    prefix is Server-localhost-firstSAN and for 3001, the certificate
    prefix is Server-localhost-secondSAN.
  - Remove TODO 15.2 (Add support for custom server certificate
    validation), this commit addresses it.
  Closes https://github.com/curl/curl/pull/1325
- schannel: fix warning
  - Fix warning 'integer from pointer without a cast' on 3rd arg in
    CertOpenStore. The arg type HCRYPTPROV may be a pointer or integer
    type of the same size.
  Follow-up to e35b025.
  Caught by Marc's CI builds.
- [Jakub Wilk brought this change]
  docs: fix typos
  Closes https://github.com/curl/curl/pull/2503
Daniel Stenberg (17 Apr 2018)
- RELEASE-NOTES: synced
Jay Satiro (17 Apr 2018)
- [Kees Dekker brought this change]
  winbuild: Support custom devel paths for each dependency
  - Support custom devel paths for c-ares, mbedTLS, nghttp2, libSSH2,
    OpenSSL and zlib. Respectively: CARES_PATH, MBEDTLS_PATH,
    NGHTTP2_PATH, SSH2_PATH, SSL_PATH and ZLIB_PATH.
  - Use lib.exe for making the static library instead of link.exe /lib.
    The latter is undocumented and could cause problems as noted in the
    comments.
  - Remove a dangling URL that no longer worked. (I was not able to find
    the IDN download at MSDN/microsoft.com, so it seems to be removed.)
  - Remove custom override for release-ssh2-ssl-dll-zlib configuration.
    Nobody knows why it was there and as far as we can see is unnecessary.
  Closes https://github.com/curl/curl/pull/2474
Daniel Stenberg (17 Apr 2018)
- [Jess brought this change]
  README.md: add backers and sponsors
  Closes #2484
- [Archangel_SDY brought this change]
  schannel: add client certificate authentication
  Users can now specify a client certificate in system certificates store
  explicitly using expression like `--cert "CurrentUser\MY\<thumbprint>"`
  Closes #2376
Marcel Raad (16 Apr 2018)
- [toughengineer brought this change]
  ntlm_sspi: fix authentication using Credential Manager
  If you pass empty user/pass asking curl to use Windows Credential
  Storage (as stated in the docs) and it has valid credentials for the
  domain, e.g.
  curl -v -u : --ntlm example.com
  currently authentication fails.
  This change fixes it by providing proper SPN string to the SSPI API
  calls.
  Fixes https://github.com/curl/curl/issues/1622
  Closes https://github.com/curl/curl/pull/1660
Daniel Stenberg (16 Apr 2018)
- configure: keep LD_LIBRARY_PATH changes local
  ... only set it when we actually have to run tests to reduce its impact
  on for example build commands etc.
  Fixes #2490
  Closes #2492
  Reported-by: Dmitry Mikhirev
Marcel Raad (16 Apr 2018)
- urldata: make service names unconditional
  The ifdefs have become quite long. Also, the condition for the
  definition of CURLOPT_SERVICE_NAME and for setting it from
  CURLOPT_SERVICE_NAME have diverged. We will soon also need the two
  options for NTLM, at least when using SSPI, for
  https://github.com/curl/curl/pull/1660.
  Just make the definitions unconditional to make that easier.
  Closes https://github.com/curl/curl/pull/2479
Daniel Stenberg (16 Apr 2018)
- test1148: tolerate progress updates better
  Fixes #2446
  Closes #2488
- [Christian Schmitz brought this change]
  ssh: show libSSH2 error code when closing fails
  Closes #2500
Jay Satiro (15 Apr 2018)
- [Daniel Gustafsson brought this change]
  vauth: Fix typo
  Address various spellings of "credentials".
  Closes https://github.com/curl/curl/pull/2496
- [Dagobert Michelsen brought this change]
  system.h: Add sparcv8plus to oracle/sunpro 32-bit detection
  With specific compiler options selecting the arch like -xarch=sparc on
  newer compilers like Oracle Studio 12.4 there is no definition of
  __sparcv8 but __sparcv8plus which means the V9 ISA, but limited to the
  32
bit subset defined by the V8plus ISA specification, without the
  Visual Instruction Set (VIS), and without other implementation-specific
  ISA extensions. So it should be the same as __sparcv8.
  Closes https://github.com/curl/curl/pull/2491
- [Daniel Gustafsson brought this change]
  checksrc: Fix typo
  Fix typo in "semicolon" spelling and remove stray tab character.
  Closes https://github.com/curl/curl/pull/2498
- [Daniel Gustafsson brought this change]
  all: Refactor malloc+memset to use calloc
  When a zeroed out allocation is required, use calloc() rather than
  malloc() followed by an explicit memset(). The result will be the
  same, but using calloc() everywhere increases consistency in the
  codebase and avoids the risk of subtle bugs when code is injected
  between malloc and memset by accident.
  Closes https://github.com/curl/curl/pull/2497
Daniel Stenberg (12 Apr 2018)
- duphandle: make sure CURLOPT_RESOLVE is duplicated fine too
  Verified in test 1502 now
  Fixes #2485
  Closes #2486
  Reported-by: Ernst Sj
strand
- mailmap: add a monnerat fixup [ci skip]
- proxy: show getenv proxy use in verbose output
  ... to aid debugging etc as it sometimes isn't immediately obvious why
  curl uses or doesn't use a proxy.
  Inspired by #2477
  Closes #2480
- travis: build libpsl and make builds use it
  closes #2471
- travis: bump to clang 6 and gcc 7
  Extra-eye-on-this-by: Marcel Raad
  Closes #2478
Marcel Raad (10 Apr 2018)
- travis: use trusty for coverage build
  This works now and precise is in the process of being decommissioned.
  Closes https://github.com/curl/curl/pull/2476
- lib: silence null-dereference warnings
  In debug mode, MingGW-w64's GCC 7.3 issues null-dereference warnings
  when dereferencing pointers after DEBUGASSERT-ing that they are not
  NULL.
  Fix this by removing the DEBUGASSERTs.
  Suggested-by: Daniel Stenberg
  Ref: https://github.com/curl/curl/pull/2463
- [Kees Dekker brought this change]
  winbuild: fix URL
  Follow up on https://github.com/curl/curl/pull/2472.
  Now using en-us instead of nl-nl as language code in the URL.
  Closes https://github.com/curl/curl/pull/2475
Daniel Stenberg (9 Apr 2018)
- [Kees Dekker brought this change]
  winbuild: updated the documentation
  The setenv command no longer exists and visual studio build prompts got
  changed. Used Visual Studio 2015/2017 as reference.
  Closes #2472
- test1136: fix cookie order after commit c990eadd1277
- build: cleanup to fix clang warnings/errors
  unit1309 and vtls/gtls: error: arithmetic on a null pointer treated as a
  cast from integer to pointer is a GNU extension
  Reported-by: Rikard Falkeborn
  Fixes #2466
  Closes #2468
Jay Satiro (7 Apr 2018)
- examples/sftpuploadresmue: Fix Windows large file seek
  - Use _fseeki64 instead of fseek (long) to seek curl_off_t in Windows.
  - Use CURL_FORMAT_CURL_OFF_T specifier instead of %ld to print
    curl_off_t.
  Caught by Marc's CI builds.
Daniel Stenberg (7 Apr 2018)
- curl_setup: provide a CURL_SA_FAMILY_T type if none exists
  ... and use this type instead of 'sa_family_t' in the code since several
  platforms don't have it.
  Closes #2463
- [Eric Gallager brought this change]
  build: add picky compiler warning flags for gcc 6 and 7
- configure: detect sa_family_t
Jay Satiro (7 Apr 2018)
- [Stefan Agner brought this change]
  tool_operate: Fix retry on FTP 4xx to ignore other protocols
  Only treat response code as FTP response codes in case the
  protocol type is FTP.
  This fixes an issue where an HTTP download was treated as FTP
  in case libcurl returned with 33. This happens when the
  download has already finished and the server responses 416:
    HTTP/1.1 416 Requested Range Not Satisfiable
  This should not be treated as an FTP error.
  Fixes #2464
  Closes #2465
Daniel Stenberg (6 Apr 2018)
- hash: calculate sizes with size_t instead of longs
  ... since they return size_t anyway!
  closes #2462
- RELEASE-NOTES: synced
- [Jay Satiro brought this change]
  build-openssl.bat: Refer to VS2017 as VC14.1 instead of VC15
  .. and do the same for build-wolfssl.bat.
  Because MS calls it VC14.1.
  Closes https://github.com/curl/curl/pull/2189
- [Kees Dekker brought this change]
  winbuild: make the clean target work without build-type
  Due to the check in Makefile.vc and MakefileBuild.vc, no make call can
  be invoked unless a build-type was specified. However, a clean target
  only existed when a build type was specified. As a result, the clean
  target was unreachable. Made clean target unconditional.
  Closes #2455
- [patelvivekv1993 brought this change]
  build-openssl.bat: allow custom paths for VS and perl
  Fixes #2430
  Closes #2457
- [Laurie Clark-Michalek brought this change]
  FTP: allow PASV on IPv6 connections when a proxy is being used
  In the situation of a client connecting to an FTP server using an IPv6
  tunnel proxy, the connection info will indicate that the connection is
  IPv6. However, because the server behing the proxy is IPv4, it is
  permissable to attempt PSV mode. In the case of the FTP server being
  IPv4 only, EPSV will always fail, and with the current logic curl will
  be unable to connect to the server, as the IPv6 fwdproxy causes curl to
  think that EPSV is impossible.
  Closes #2432
- [Jon DeVree brought this change]
  file: restore old behavior for file:////foo/bar URLs
  curl 7.57.0 and up interpret this according to Appendix E.3.2 of RFC
  8089 but then returns an error saying this is unimplemented. This is
  actually a regression in behavior on both Windows and Unix.
  Before curl 7.57.0 this URL was treated as a path of "//foo/bar" and
  then passed to the relevant OS API. This means that the behavior of this
  case is actually OS dependent.
  The Unix path resolution rules say that the OS must handle swallowing
  the extra "/" and so this path is the same as "/foo/bar"
  The Windows path resolution rules say that this is a UNC path and
  automatically handles the SMB access for the program. So curl on Windows
  was already doing Appendix E.3.2 without any special code in curl.
  Regression
  Closes #2438
- [Gaurav Malhotra brought this change]
  Revert "openssl: Don't add verify locations when verifypeer==0"
  This reverts commit dc85437736e1fc90e689bb1f6c51c8f1aa9430eb.
  libcurl (with the OpenSSL backend) performs server certificate verification
  even if verifypeer == 0 and the verification result is available using
  CURLINFO_SSL_VERIFYRESULT. The commit that is being reverted caused the
  CURLINFO_SSL_VERIFYRESULT to not have useful information for the
  verifypeer == 0 use case (it would always have
  X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY).
  Closes #2451
- [Wyatt O'Day brought this change]
  tls: fix mbedTLS 2.7.0 build + handle sha256 failures
  (mbedtls 2.70 compiled with MBEDTLS_DEPRECATED_REMOVED)
  Closes #2453
- [Lauri Kasanen brought this change]
  cookie: case-insensitive hashing for the domains
  closes #2458
Patrick Monnerat (4 Apr 2018)
- cookie: fix and optimize 2nd top level domain name extraction
  This fixes a segfault occurring when a name of the (invalid) form "domain..tld"
  is processed.
  test46 updated to cover this case.
  Follow-up to commit c990ead.
  Ref: https://github.com/curl/curl/pull/2440
Daniel Stenberg (4 Apr 2018)
- openssl: provide defines for argument typecasts to build warning-free
  ... as OpenSSL >= 1.1.0 and libressl >= 2.7.0 use different argument types.
- [Bernard Spil brought this change]
  openssl: fix build with LibreSSL 2.7
   - LibreSSL 2.7 implements (most of) OpenSSL 1.1 API
  Fixes #2319
  Closes #2447
  Closes #2448
  Signed-off-by: Bernard Spil <brnrd@FreeBSD.org>
- [Lauri Kasanen brought this change]
  cookie: store cookies per top-level-domain-specific hash table
  This makes libcurl handle thousands of cookies much better and speedier.
  Closes #2440
- [Lauri Kasanen brought this change]
  cookies: when reading from a file, only remove_expired once
  This drops the cookie load time for 8k cookies from 178ms to 15ms.
  Closes #2441
- test1148: set a fixed locale for the test
  ...as otherwise it might use a different decimal sign.
  Bug: #2436
  Reported-by: Oumph on github
Jay Satiro (31 Mar 2018)
- docs: fix CURLINFO_*_T examples use of CURL_FORMAT_CURL_OFF_T
  - Put a percent sign before each CURL_FORMAT_CURL_OFF_T in printf.
  For example "%" CURL_FORMAT_CURL_OFF_T becomes %lld or similar.
  Bug: https://curl.haxx.se/mail/lib-2018-03/0140.html
  Reported-by: David L.
Sergei Nikulov (27 Mar 2018)
- [Micha
 Janiszewski brought this change]
  cmake: Add advapi32 as explicit link library for win32
  ARM targets need advapi32 explicitly.
  Closes #2363
Daniel Stenberg (27 Mar 2018)
- TODO: connection cache sharing is now supporte
Jay Satiro (26 Mar 2018)
- travis: enable apt retry on fail
  This is a workaround for an unsolved travis issue that is causing CI
  instances to sporadically fail due to 'unable to connect' issues during
  apt stage.
  Ref: https://github.com/travis-ci/travis-ci/issues/8507
  Ref: https://github.com/travis-ci/travis-ci/issues/9112#issuecomment-376305909
Michael Kaufmann (26 Mar 2018)
- runtests.pl: fix warning 'use of uninitialized value'
  follow-up to a9a7b60
  Closes #2428
Daniel Stenberg (24 Mar 2018)
- gitignore: ignore more generated files
- threaded resolver: track resolver time and set suitable timeout values
  In order to make curl_multi_timeout() return suitable "sleep" times even
  when there's no socket to wait for while the name is being resolved in a
  helper thread.
  It will increases the timeouts as time passes.
  Closes #2419
- [Howard Chu brought this change]
  openldap: fix for NULL return from ldap_get_attribute_ber()
  Closes #2399
GitHub (22 Mar 2018)
- [Sergei Nikulov brought this change]
  travis-ci: enable -Werror for CMake builds (#2418)
- [Sergei Nikulov brought this change]
  cmake: avoid warn-as-error during config checks (#2411)
  - Move the CURL_WERROR option processing after the configuration checks
    to avoid failures in case of warnings during the configuration checks.
  This is a partial fix for #2358
- [Sergei Nikulov brought this change]
  timeval: remove compilation warning by casting (#2417)
  This is fixes #2358
Daniel Stenberg (22 Mar 2018)
- http2: read pending frames (including GOAWAY) in connection-check
  If a connection has received a GOAWAY frame while not being used, the
  function now reads frames off the connection before trying to reuse it
  to avoid reusing connections the server has told us not to use.
  Reported-by: Alex Baines
  Fixes #1967
  Closes #2402
- [Bas van Schaik brought this change]
  CI: add lgtm.yml for tweaking lgtm.com analysis
  Closes #2414
- CURLINFO_SSL_VERIFYRESULT.3: fix the example, add some text
  Reported-by: Michal Trybus
  Fixes #2400
- TODO: expand ~/ in config files
  Closes #2317
- cookie.d: mention that "-" as filename means stdin
  Reported-by: Dongliang Mu
  Fixes #2410
- CURLINFO_COOKIELIST.3: made the example not leak memory
  Reported-by: Muz Dima
- vauth/cleartext: fix integer overflow check
  Make the integer overflow check not rely on the undefined behavior that
  a size_t wraps around on overflow.
  Detected by lgtm.com
  Closes #2408
- lib/curl_path.h: add #ifdef header guard
  Detected by lgtm.com
- vauth/ntlm.h: fix the #ifdef header guard
  Detected by lgtm.com
Jay Satiro (20 Mar 2018)
- examples/hiperfifo: checksrc compliance
Daniel Stenberg (19 Mar 2018)
- [Nikos Tsipinakis brought this change]
  parsedate: support UT timezone
  RFC822 section 5.2 mentions Universal Time, 'UT', to be synonymous with
  GMT.
  Closes #2401
- RELEASE-NOTES: synced
- [Don brought this change]
  cmake: add support for brotli
  Currently CMake cannot detect Brotli support. This adds detection of the
  libraries and associated header files. It also adds this to the
  generated config.
  Closes #2392
- [Chris Araman brought this change]
  darwinssl: fix iOS build
Patrick Monnerat (18 Mar 2018)
- ILE/RPG binding: Add CURLOPT_HAPROXYPROTOCOL/Fix CURLOPT_DNS_SHUFFLE_ADDRESSES
Daniel Stenberg (17 Mar 2018)
- [Rick Deist brought this change]
  resolve: add CURLOPT_DNS_SHUFFLE_ADDRESSES
  This patch adds CURLOPT_DNS_SHUFFLE_ADDRESSES to explicitly request
  shuffling of IP addresses returned for a hostname when there is more
  than one. This is useful when the application knows that a round robin
  approach is appropriate and is willing to accept the consequences of
  potentially discarding some preference order returned by the system's
  implementation.
  Closes #1694
- add_handle/easy_perform: clear errorbuffer on start if set
  To offer applications a more defined behavior, we clear the buffer as
  early as possible.
  Assisted-by: Jay Satiro
  Fixes #2190
  Closes #2377
- [Lawrence Matthews brought this change]
  CURLOPT_HAPROXYPROTOCOL: support the HAProxy PROXY protocol
  Add --haproxy-protocol for the command line tool
  Closes #2162
- curl_version_info.3: fix ssl_version description
  Reported-by: Vincas Razma
  Fixes #2364
- multi: improved pending transfers handling => improved performance
  When a transfer is requested to get done and it is put in the pending
  queue when limited by number of connections, total or per-host, libcurl
  would previously very aggressively retry *ALL* pending transfers to get
  them transferring. That was very time consuming.
  By reducing the aggressiveness in how pending are being retried, we
  waste MUCH less time on putting transfers back into pending again.
  Some test cases got a factor 30(!) speed improvement with this change.
  Reported-by: Cyril B
  Fixes #2369
  Closes #2383
- pause: when changing pause state, update socket state
  Especially unpausing a transfer might have to move the socket back to the
  "currently used sockets" hash to get monitored. Otherwise it would never get
  any more data and get stuck. Easily triggered with pausing using the
  multi_socket API.
  Reported-by: Philip Prindeville
  Bug: https://curl.haxx.se/mail/lib-2018-03/0048.html
  Fixes #2393
  Closes #2391
- [Philip Prindeville brought this change]
  examples/hiperfifo.c: improved
   * use member struct event
s instead of pointers to alloc
d struct
     events
   * simplify the cases for the mcode_or_die() function via macros;
   * make multi_timer_cb() actually do what the block comment says it
     should;
   * accept a 
stop
 command on the FIFO to shut down the service;
   * use cleaner notation for unused variables than the (void) hack;
   * allow following redirections (304
- rate-limit: use three second window to better handle high speeds
  Due to very frequent updates of the rate limit "window", it could
  attempt to rate limit within the same milliseconds and that then made
  the calculations wrong, leading to it not behaving correctly on very
  fast transfers.
  This new logic updates the rate limit "window" to be no shorter than the
  last three seconds and only updating the timestamps for this when
  switching between the states TOOFAST/PERFORM.
  Reported-by: 
  Fixes #2386
  Closes #2388
- [luz.paz brought this change]
  cleanup: misc typos in strings and comments
  Found via `codespell`
  Closes #2389
- RELEASE-NOTES: toward 7.60.0
- [Kobi Gurkan brought this change]
  http2: fixes typo
  Closes #2387
- user-agent.d:: mention --proxy-header as well
  Bug: https://github.com/curl/curl/issues/2381
- transfer: make HTTP without headers count correct body size
  This is what "HTTP/0.9" basically looks like.
  Reported on IRC
  Closes #2382
- test1208: marked flaky
  It fails somewhere between every 3rd to 10th travis-CI run
- SECURITY-PROCESS: mention how we write/add advisories
- [dasimx brought this change]
  FTP: fix typo in recursive callback detection for seeking
  Fixes #2380
Version 7.59.0 (13 Mar 2018)
Daniel Stenberg (13 Mar 2018)
- release: 7.59.0
Kamil Dudka (13 Mar 2018)
- tests/.../spnego.py: fix identifier typo
  Detected by Coverity Analysis:
  Error: IDENTIFIER_TYPO:
  curl-7.58.0/tests/python_dependencies/impacket/spnego.py:229: identifier_typo: Using "SuportedMech" appears to be a typo:
  * Identifier "SuportedMech" is only known to be referenced here, or in copies of this code.
  * Identifier "SupportedMech" is referenced elsewhere at least 4 times.
  curl-7.58.0/tests/python_dependencies/impacket/smbserver.py:2651: identifier_use: Example 1: Using identifier "SupportedMech".
  curl-7.58.0/tests/python_dependencies/impacket/smbserver.py:2308: identifier_use: Example 2: Using identifier "SupportedMech".
  curl-7.58.0/tests/python_dependencies/impacket/spnego.py:252: identifier_use: Example 3: Using identifier "SupportedMech" (2 total uses in this function).
  curl-7.58.0/tests/python_dependencies/impacket/spnego.py:229: remediation: Should identifier "SuportedMech" be replaced by "SupportedMech"?
  Closes #2379
Daniel Stenberg (13 Mar 2018)
- CURLOPT_COOKIEFILE.3: "-" as file name means stdin
  Reported-by: Aron Bergman
  Bug: https://curl.haxx.se/mail/lib-2018-03/0049.html
  [ci skip]
- Revert "hostip: fix compiler warning: 'variable set but not used'"
  This reverts commit a577059f92fc65bd6b81717f0737f897a5b34248.
  The assignment really needs to be there or we risk working with an
  uninitialized pointer.
Michael Kaufmann (12 Mar 2018)
- limit-rate: fix compiler warning
  follow-up to 72a0f62
Viktor Szakats (12 Mar 2018)
- checksrc.pl: add -i and -m options
  To sync it with changes made for the libssh2 project.
  Also cleanup some whitespace.
- curl-openssl.m4: fix spelling [ci skip]
- FAQ: fix a broken URL [ci skip]
Daniel Stenberg (12 Mar 2018)
- http2: mark the connection for close on GOAWAY
  ... don't consider it an error!
  Assisted-by: Jay Satiro
  Reported-by: 
ukasz Domeradzki
  Fixes #2365
  Closes #2375
- credits: Viktor prefers without accent
- openldap: white space changes, fixed up the copyright years
- openldap: check ldap_get_attribute_ber() results for NULL before using
  CVE-2018-1000121
  Reported-by: Dario Weisser
  Bug: https://curl.haxx.se/docs/adv_2018-97a2.html
- FTP: reject path components with control codes
  Refuse to operate when given path components featuring byte values lower
  than 32.
  Previously, inserting a %00 sequence early in the directory part when
  using the 'singlecwd' ftp method could make curl write a zero byte
  outside of the allocated buffer.
  Test case 340 verifies.
  CVE-2018-1000120
  Reported-by: Duy Phan Thanh
  Bug: https://curl.haxx.se/docs/adv_2018-9cd6.html
- readwrite: make sure excess reads don't go beyond buffer end
  CVE-2018-1000122
  Bug: https://curl.haxx.se/docs/adv_2018-b047.html
  Detected by OSS-fuzz
- BUGS: updated link to security process
- limit-rate: kick in even before "limit" data has been received
  ... and make sure to avoid integer overflows with really large values.
  Reported-by: 
  Fixes #2371
  Closes #2373
- docs/SECURITY.md -> docs/SECURITY-PROCESS.md
- SECURITY.md: call it the security process
Michael Kaufmann (11 Mar 2018)
- Curl_range: fix FTP-only and FILE-only builds
  follow-up to e04417d
- hostip: fix compiler warning: 'variable set but not used'
Daniel Stenberg (11 Mar 2018)
- HTTP: allow "header;" to replace an internal header with a blank one
  Reported-by: Michael Kaufmann
  Fixes #2357
  Closes #2362
- http2: verbose output new MAX_CONCURRENT_STREAMS values
  ... as it is interesting for many users.
- SECURITY: distros' max embargo time is 14 days now
Patrick Monnerat (8 Mar 2018)
- curl tool: accept --compressed also if Brotli is enabled and zlib is not.
Daniel Stenberg (5 Mar 2018)
- THANKS + mailmap: remove duplicates, fixup full names
- [sergii.kavunenko brought this change]
  WolfSSL: adding TLSv1.3
  Closes #2349
- RELEASE-NOTES/THANKS: synced with cc1d4c505
- [Richard Alcock brought this change]
  winbuild: prefer documented zlib library names
  Check for existence of import and static libraries with documented names
  and use them if they do. Fallback to previous names.
  According to
  https://github.com/madler/zlib/blob/master/win32/README-WIN32.txt on
  Windows, the names of the import library is "zdll.lib" and static
  library is "zlib.lib".
  closes #2354
Marcel Raad (4 Mar 2018)
- krb5: use nondeprecated functions
  gss_seal/gss_unseal have been deprecated in favor of
  gss_wrap/gss_unwrap with GSS-API v2 from January 1997 [1]. The first
  version of "The Kerberos Version 5 GSS-API Mechanism" [2] from June
  1996 already says "GSS_Wrap() (formerly GSS_Seal())" and
  "GSS_Unwrap() (formerly GSS_Unseal())".
  Use the nondeprecated functions to avoid deprecation warnings.
  [1] https://tools.ietf.org/html/rfc2078
  [2] https://tools.ietf.org/html/rfc1964
  Closes https://github.com/curl/curl/pull/2356
Daniel Stenberg (4 Mar 2018)
- curl.1: mention how to add numerical IP addresses in NO_PROXY
- CURLOPT_NOPROXY.3: mention how to list numerical IPv6 addresses
- NO_PROXY: fix for IPv6 numericals in the URL
  Added test 1265 that verifies.
  Reported-by: steelman on github
  Fixes #2353
  Closes #2355
- build: get CFLAGS (including -werror) used for examples and tests
  ... so that the CI and more detects compiler warnings/errors properly!
  Closes #2337
Marcel Raad (3 Mar 2018)
- curl_ctype: fix macro redefinition warnings
  On MinGW and Cygwin, GCC and clang have been complaining about macro
  redefinitions since 4272a0b0fc49a1ac0ceab5c4a365c9f6ab8bf8e2. Fix this
  by undefining the macros before redefining them as suggested in
  https://github.com/curl/curl/pull/2269.
  Suggested-by: Daniel Stenberg
Dan Fandrich (2 Mar 2018)
- unit1307: proper cleanup on OOM to fix torture tests
Marcel Raad (28 Feb 2018)
- unit1309: fix warning on Windows x64
  When targeting x64, MinGW-w64 complains about conversions between
  32-bit long and 64-bit pointers. Fix this by reusing the
  GNUTLS_POINTER_TO_SOCKET_CAST / GNUTLS_SOCKET_TO_POINTER_CAST logic
  from gtls.c, moving it to warnless.h as CURLX_POINTER_TO_INTEGER_CAST /
  CURLX_INTEGER_TO_POINTER_CAST.
  Closes https://github.com/curl/curl/pull/2341
- travis: update compiler versions
  Update clang to version 3.9 and GCC to version 6.
  Closes https://github.com/curl/curl/pull/2345
Daniel Stenberg (26 Feb 2018)
- docs/MANUAL: formfind.pl is not accessible on the site anymore
  Fixes #2342
Jay Satiro (24 Feb 2018)
- curl-openssl.m4: Fix version check for OpenSSL 1.1.1
  - Add OpenSSL 1.1.1 to the header/library version lists.
  - Detect OpenSSL 1.1.1 library using its function ERR_clear_last_mark,
    which was added in that version.
  Prior to this change an erroneous header/library mismatch was caused by
  lack of OpenSSL 1.1.1 detection. I tested using openssl-1.1.1-pre1.
Viktor Szakats (23 Feb 2018)
- lib655: silence compiler warning
  Closes https://github.com/curl/curl/pull/2335
- spelling fixes
  Detected using the `codespell` tool.
  Also contains one URL protocol upgrade.
  Closes https://github.com/curl/curl/pull/2334
Daniel Stenberg (24 Feb 2018)
- projects/README: remove reference to dead IDN link/package
  Reported-by: Stefan Kanthak and Rod Widdowson
  Fixes #2325
Jay Satiro (23 Feb 2018)
- [Rod Widdowson brought this change]
  winbuild: Use macros for the names of some build utilities
  - Add macros to the top of the makefile for rc and mt utilities so that
    it is easier to change their locations.
  Bug: https://curl.haxx.se/mail/lib-2018-02/0075.html
  Reported-by: Stefan Kanthak
  Closes https://github.com/curl/curl/issues/2329
Daniel Stenberg (23 Feb 2018)
- TODO: remove "sha-256 digest", added in 2b5b37cb9109e7c2
- curl_share_setopt.3: connection cache is shared within multi handles
Jay Satiro (22 Feb 2018)
- [Rod Widdowson brought this change]
  winbuild: Use CALL to run batch scripts
  Co-authored-by: Stefan Kanthak
  Closes https://github.com/curl/curl/issues/2330
  Closes https://github.com/curl/curl/pull/2331
Patrick Monnerat (22 Feb 2018)
- os400: add curl_resolver_start_callback type to ILE/RPG binding
Daniel Stenberg (22 Feb 2018)
- form.d: rephrased somewhat, added two example command lines
Jay Satiro (21 Feb 2018)
- [Francisco Sedano brought this change]
  url: Add option CURLOPT_RESOLVER_START_FUNCTION
  - Add new option CURLOPT_RESOLVER_START_FUNCTION to set a callback that
    will be called every time before a new resolve request is started
    (ie before a host is resolved) with a pointer to backend-specific
    resolver data. Currently this is only useful for ares.
  - Add new option CURLOPT_RESOLVER_START_DATA to set a user pointer to
    pass to the resolver start callback.
  Closes https://github.com/curl/curl/pull/2311
- lib: CURLOPT_HAPPY_EYEBALLS_TIMEOUT => CURLOPT_HAPPY_EYEBALLS_TIMEOUT_MS
  - In keeping with the naming of our other connect timeout options rename
    CURLOPT_HAPPY_EYEBALLS_TIMEOUT to CURLOPT_HAPPY_EYEBALLS_TIMEOUT_MS.
  This change adds the _MS suffix since the option expects milliseconds.
  This is more intuitive for our users since other connect timeout options
  that expect milliseconds use _MS such as CURLOPT_TIMEOUT_MS,
  CURLOPT_CONNECTTIMEOUT_MS, CURLOPT_ACCEPTTIMEOUT_MS.
  The tool option already uses an -ms suffix, --happy-eyeballs-timeout-ms.
  Follow-up to 2427d94 which added the lib and tool option yesterday.
  Ref: https://github.com/curl/curl/pull/2260
Patrick Monnerat (21 Feb 2018)
- sasl: prefer PLAIN mechanism over LOGIN
  SASL PLAIN is a standard, LOGIN only a draft. The LOGIN draft says
  PLAIN should be used instead if available.
Daniel Stenberg (21 Feb 2018)
- RELEASE-NOTES: synced with 2427d94c6
Jay Satiro (20 Feb 2018)
- [Anders Bakken brought this change]
  url: Add option CURLOPT_HAPPY_EYEBALLS_TIMEOUT
  - Add new option CURLOPT_HAPPY_EYEBALLS_TIMEOUT to set libcurl's happy
    eyeball timeout value.
  - Add new optval macro CURL_HET_DEFAULT to represent the default happy
    eyeballs timeout value (currently 200 ms).
  - Add new tool option --happy-eyeballs-timeout-ms to expose
    CURLOPT_HAPPY_EYEBALLS_TIMEOUT. The -ms suffix is used because the
    other -timeout options in the tool expect seconds not milliseconds.
  Closes https://github.com/curl/curl/pull/2260
- hostip: fix 'potentially uninitialized variable' warning
  Follow-up to 50d1b33.
  Caught by AppVeyor.
Daniel Stenberg (20 Feb 2018)
- TODO: warning if curl version is not in sync with libcurl version
Jay Satiro (20 Feb 2018)
- [Anders Bakken brought this change]
  CURLOPT_RESOLVE: Add support for multiple IP addresses per entry
  This enables users to preresolve but still take advantage of happy
  eyeballs and trying multiple addresses if some are not connecting.
  Ref: https://github.com/curl/curl/pull/2260
Daniel Stenberg (20 Feb 2018)
- [Sergio Borghese brought this change]
  examples/sftpuploadresume: resume upload via CURLOPT_APPEND
  URL: https://curl.haxx.se/mail/lib-2018-02/0072.html
- curl --version: show PSL if the run-time lib has it enabled
  ... not of the #define was set at build-time!
- TODO: "Support in-memory certs/ca certs/keys"
  removed SSLKEYLOGFILE support (fixed)
  removed "consider SSL patches" (outdated)
  Closes #2310
- CURLOPT_HEADER.3: clarify problems with different data sizes
- test1556: verify >16KB headers to the header callback
- header callback: don't chop headers into smaller pieces
  Reported-by: Guido Berhoerster
  Fixes #2314
  Closes #2316
- test1154: verify that long HTTP headers get rejected
- http: fix the max header length detection logic
  Previously, it would only check for max length if the existing alloc
  buffer was to small to fit it, which often would make the header still
  get used.
  Reported-by: Guido Berhoerster
  Bug: https://curl.haxx.se/mail/lib-2018-02/0056.html
  Closes #2315
- CURLOPT_HEADERFUNCTION.3: fix typo from d939226813
  Reported-by: Erik Johansson
  Bug: https://github.com/curl/curl/commit/d9392268131c1b8d18dec3fa30e0bded833a5db7#commitcomment-27607495
- CURLOPT_HEADERFUNCTION.3: mention folded headers
- TODO: 1.1 Option to refuse usernames in URLs
  Also expanded the CURL_REFUSE_CLEARTEXT section with more ideas.
- TODO: 1.7 Support HTTP/2 for HTTP(S) proxies
- ssh: add two missing state names
  The list of state names (used in debug builds) was out of sync in
  relation to the list of states (used in all builds).
  I now added an assert to make sure the sizes of the two lists match, to
  aid in detecting this mistake better in the future.
  Regression since c92d2e14cf, shipped in 7.58.0.
  Reported-by: Somnath Kundu
  Fixes #2312
  Closes #2313
- Revert "KNOWN_BUGS: 2.5 curl should not offer "ALPN: h2" when using https-proxy"
  This reverts commit de9fac00c40db321d44fa6fbab6eb62ec4c83998.
  Reported-by: Jay Satiro
Jay Satiro (15 Feb 2018)
- non-ascii: fix implicit declaration warning
  Follow-up to b46cfbc.
  Caught by Travis CI.
Daniel Stenberg (15 Feb 2018)
- travis: add build with iconv enabled
  ... to verify it builds and works fine.
  Ref: https://curl.haxx.se/mail/lib-2017-09/0031.html
  Closes #1872
- TODO: 18.18 retry on network is unreachable
  Closes #1603
- KNOWN_BUGS: 2.5 curl should not offer "ALPN: h2" when using https-proxy
  Closes #1254
Kamil Dudka (15 Feb 2018)
- nss: use PK11_CreateManagedGenericObject() if available
  ... so that the memory allocated by applications using libcurl does not
  grow per each TLS connection.
  Bug: https://bugzilla.redhat.com/1510247
  Closes #2297
Daniel Stenberg (15 Feb 2018)
- [Bj
rn Stenberg brought this change]
  TODO fixed: Detect when called from within callbacks
  Closes #2302
- BINDINGS: fix curb link (and remove ruby-curl-multi)
  Reported-by: Klaus Stein
- curl_gssapi: make sure this file too uses our *printf()
- libcurl-security.3: separate file:// section
  ... just to make it more apparent. Even if it repeats
  some pieces of information.
- libcurl-security.3: the http://192.168.0.1/my_router_config case
  Mentioned-By: Rich Moore
- libcurl-security.3: mention the URL standards problems too
- libcurl-security.3: split out from libcurl-tutorial.3
  To make more accessible.
  Merged in some new language from "URLs are dangerous things" as discussed on
  the mailing list a few days ago:
  Bug: https://curl.haxx.se/mail/lib-2018-02/0013.html
- RELEASE-NOTES: synced with e551910f8
Patrick Monnerat (13 Feb 2018)
- tests: new tests for http raw mode
  Test 319 checks proper raw mode data with non-chunked gzip
  transfer-encoded server data.
  Test 326 checks raw mode with chunked server data.
  Bug: #2303
  Closes #2308
Kamil Dudka (12 Feb 2018)
- tlsauthtype.d: works only if libcurl is built with TLS-SRP support
  Bug: https://bugzilla.redhat.com/1542256
  Closes #2306
Patrick Monnerat (12 Feb 2018)
- smtp: fix processing of initial dot in data
  RFC 5321 4.1.1.4 specifies the CRLF terminating the DATA command
  should be taken into account when chasing the <CRLF>.<CRLF> end marker.
  Thus a leading dot character in data is also subject to escaping.
  Tests 911 and test server are adapted to this situation.
  New tests 951 and 952 check proper handling of initial dot in data.
  Closes #2304
Daniel Stenberg (12 Feb 2018)
- sha256: avoid redefine
- [Douglas Mencken brought this change]
  sha256: build with OpenSSL < 0.9.8 too
  support for SHA-2 was introduced in OpenSSL 0.9.8
  Closes #2305
- [Bruno Grasselli brought this change]
  README: language fix
  s/off/from
  Closes #2300
Patrick Monnerat (12 Feb 2018)
- http_chunks: don't write chunks twice with CURLOPT_HTTP_TRANSFER_DECODING on
  Bug: #2303
  Reported-By: Henry Roeland
Daniel Stenberg (9 Feb 2018)
- get_posix_time: only check for overflows if they can happen!
Michael Kaufmann (9 Feb 2018)
- schannel: fix "no previous prototype" compiler warning
Jay Satiro (9 Feb 2018)
- [Mohammad AlSaleh brought this change]
  content_encoding: Add "none" alias to "identity"
  Some servers return a "content-encoding" header with a non-standard
  "none" value.
  Add "none" as an alias to "identity" as a work-around, to avoid
  unrecognised content encoding type errors.
  Signed-off-by: Mohammad AlSaleh <CE.Mohammad.AlSaleh@gmail.com>
  Closes https://github.com/curl/curl/pull/2298
Steve Holme (8 Feb 2018)
- build-openssl.bat: Follow up to 648679ab8e to suppress copy/move output
- build-openssl.bat: Fixed incorrect move if destination build folder exists
Michael Kaufmann (8 Feb 2018)
- schannel: fix compiler warnings
  Closes #2296
Steve Holme (7 Feb 2018)
- curl_addrinfo.c: Allow Unix Domain Sockets to compile under Windows
  Windows 10.0.17061 SDK introduces support for Unix Domain Sockets.
  Added the necessary include file to curl_addrinfo.c.
  Note: The SDK (which is considered beta) has to be installed, VS 2017
  project file has to be re-targeted for Windows 10.0.17061 and #define
  enabled in config-win32.h.
Patrick Monnerat (7 Feb 2018)
- fnmatch: optimize processing of consecutive *s and ?s pattern characters
  Reported-By: Daniel Stenberg
  Fixes #2291
  Closes #2293
Steve Holme (6 Feb 2018)
- build-openssl.bat/build-wolfssl.bat: Build platform is optional
  Whilst the compiler parameter is mandatory, platform is optional as it
  is automatically calculated by the :configure section.
  This partially reverts commit 6d62d2c55d.
Daniel Stenberg (6 Feb 2018)
- [Patrick Schlangen brought this change]
  openssl: Don't add verify locations when verifypeer==0
  When peer verification is disabled, calling
  SSL_CTX_load_verify_locations is not necessary. Only call it when
  verification is enabled to save resources and increase performance.
  Closes #2290
Steve Holme (5 Feb 2018)
- build-wolfssl.bat: Extend VC15 support to include Enterprise and Professional
  ...and not just the Community Edition.
- build-openssl.bat: Extend VC15 support to include Enterprise and Professional
  ...and not just the Community Edition.
Michael Kaufmann (5 Feb 2018)
- time-cond: fix reading the file modification time on Windows
  On Windows, stat() may adjust the unix file time by a daylight saving time
  offset. Avoid this by calling GetFileTime() instead.
  Fixes #2164
  Closes #2204
Daniel Stenberg (5 Feb 2018)
- formdata: use the mime-content type function
  Reduce code duplication by making Curl_mime_contenttype available and
  used by the formdata function. This also makes the formdata function
  recognize a set of more file extensions by default.
  PR #2280 brought this to my attention.
  Closes #2282
- getdate: return -1 for out of range
  ...as that's how the function is documented to work.
  Reported-by: Michael Kaufmann
  Bug found in an autobuild with 32 bit time_t
  Closes #2278
- [Ben Greear brought this change]
  build: fix termios issue on android cross-compile
  Bug: https://curl.haxx.se/mail/lib-2018-01/0122.html
  Signed-off-by: Ben Greear <greearb@candelatech.com>
- time_t-fixes: remove typecasts to 'long' for info.filetime
  They're now wrong.
  Reported-by: Michael Kaufmann
  Closes #2277
- curl_setup: move the precautionary define of SIZEOF_TIME_T
  ... up to before it may be used for the TIME_T_MAX/MIN logic.
  Reported-by: Michael Kaufmann
- parsedate: s/#if/#ifdef
  Reported-by: Michael Kaufmann
  Bug: https://github.com/curl/curl/commit/1c39128d974666107fc6d9ea15f294036851f224#commitcomment-27246479
Patrick Monnerat (31 Jan 2018)
- fnmatch: pattern syntax can no longer fail
  Whenever an expected pattern syntax rule cannot be matched, the
  character starting the rule loses its special meaning and the parsing
  is resumed:
  - backslash at the end of pattern string matches itself.
  - Error in [:keyword:] results in set containing :\[dekorwy.
  Unit test 1307 updated for this new situation.
  Closes #2273
- fnmatch: accept an alphanum to be followed by a non-alphanum in char set
  Also be more tolerant about set pattern syntax.
  Update unit test 1307 accordingly.
  Bug: https://curl.haxx.se/mail/lib-2018-01/0114.html
- fnmatch: do not match the empty string with a character set
Jay Satiro (30 Jan 2018)
- build: fix windows build methods for curl_ctype.c
  - Fix winbuild and the VS project generator to treat curl_ctype.{c,h} as
    curlx files since they are required by both src and lib.
  Follow-up to 4272a0b which added curl_ctype.
Daniel Stenberg (30 Jan 2018)
- progress-bar.d: update to match implementation
  ... since commit 993dd5651a6
  Reported-by: Martin Dreher
  Bug: https://github.com/curl/curl/pull/2242#issuecomment-361059228
  Closes #2271
- http2: set DEBUG_HTTP2 to enable more HTTP/2 logging
  ... instead of doing it unconditionally in debug builds. It cluttered up
  the output a little too much.
- [Max Dymond brought this change]
  file: Check the return code from Curl_range and bail out on error
- [Max Dymond brought this change]
  Curl_range: add check to ensure "from <= to"
- [Max Dymond brought this change]
  Curl_range: commonize FTP and FILE range handling
  Closes #2205
- RELEASE-NOTES: synced with 811beab9f
- curlver: next release will be 7.59.0
- [Micha
 Janiszewski brought this change]
  curl/curl.h: fix comment typo for CURLOPT_DNS_LOCAL_IP6
  Closes #2275
- time: support > year 2038 time stamps for system with 32bit long
  ... with the introduction of CURLOPT_TIMEVALUE_LARGE and
  CURLINFO_FILETIME_T.
  Fixes #2238
  Closes #2264
- curl_easy_reset: clear digest auth state
  Bug: https://curl.haxx.se/mail/lib-2018-01/0074.html
  Reported-by: Ruurd Beerstra
  Fixes #2255
  Closes #2272
- [Adam Marcionek brought this change]
  winbuild: make linker generate proper PDB
  Link.exe requires /DEBUG to properly generate a full pdb file on release
  builds.
  Closes #2274
- curl: add --proxy-pinnedpubkey
  To verify a proxy's public key. For when using HTTPS proxies.
  Fixes #2192
  Closes #2268
- configure: set PATH_SEPARATOR to colon for PATH w/o separator
  The logic tries to figure out what the path separator in the $PATH
  variable is, but if there's only one directory in the $PATH it
  fails. This change make configure *guess* on colon instead of erroring
  out, simply because that is probably the more common character.
  PATH_SEPARATOR can always be set by the user to override the guessing.
  (tricky bug to reproduce, as in my case for example the configure script
  requires binaries in more than one directory so passing in a PATH with a
  single dir fails.)
  Reported-by: Earnestly on github
  Fixes #2202
  Closes #2265
- curl_ctype: private is*() type macros and functions
  ... since the libc provided one are locale dependent in a way we don't
  want. Also, the "native" isalnum() (for example) works differently on
  different platforms which caused test 1307 failures on macos only.
  Closes #2269
Marcel Raad (29 Jan 2018)
- build: open VC15 projects with VS 2017
  Previously, they were opened with Visual Studio 2015 by default, which
  cannot build them.
Daniel Stenberg (29 Jan 2018)
- RELEASE-NOTES: synced with 094647fca
- TODO: UTF-8 filenames in Content-Disposition
  Closes #1888
- KNOWN_BUGS: DICT responses show the underlying protocol
  Closes #1809
Jay Satiro (27 Jan 2018)
- [Alessandro Ghedini brought this change]
  docs: fix typos in man pages
  Closes https://github.com/curl/curl/pull/2266
Patrick Monnerat (26 Jan 2018)
- lib555: drop text conversion and encode data as ascii codes
  If CURL_DOES_CONVERSION is enabled, uploaded LFs are mapped to CRLFs,
  giving a result that is different from what is expected.
  This commit avoids using CURLOPT_TRANSFERTEXT and directly encodes data
  to upload in ascii.
  Bug: https://github.com/curl/curl/pull/1872
Daniel Stenberg (26 Jan 2018)
- lib517: make variable static to avoid compiler warning
  ... with clang on macos
Patrick Monnerat (26 Jan 2018)
- lib544: sync ascii code data with textual data
  Data mismatch caused test 545 to fail when character encoding
  conversion is enabled.
  Bug: https://github.com/curl/curl/pull/1872
Daniel Stenberg (25 Jan 2018)
- [Travis Burtrum brought this change]
  GSKit: restore pinnedpubkey functionality
  inadvertently removed in 283babfaf8d8f3bab9d3c63cea94eb0b84e79c37
  Closes #2263
- [Dair Grant brought this change]
  darwinssl: Don't import client certificates into Keychain on macOS
  Closes #2085
- configure: fix the check for unsigned time_t
  Assign the time_t variable negative value and then check if it is
  greater than zero, which will evaluate true for unsigned time_t but
  false for signed time_t.
- parsedate: fix date parsing for systems with 32 bit long
  Make curl_getdate() handle dates before 1970 as well (returning negative
  values).
  Make test 517 test dates for 64 bit time_t.
  This fixes bug (3) mentioned in #2238
  Closes #2250
- [McDonough, Tim brought this change]
  openssl: fix pinned public key build error in FIPS mode
  Here is a version that should work with all versions of openssl 0.9.7
  through 1.1.0.
  Links to the docs:
  https://www.openssl.org/docs/man1.0.2/crypto/EVP_DigestInit.html
  https://www.openssl.org/docs/man1.1.0/crypto/EVP_DigestInit.html
  At the very bottom of the 1.1.0 documentation there is a history section
  that states, " stack allocated EVP_MD_CTXs are no longer supported."
  If EVP_MD_CTX_create and EVP_MD_CTX_destroy are not defined, then a
  simple mapping can be used as described here:
  https://wiki.openssl.org/index.php/Talk:OpenSSL_1.1.0_Changes
  Closes #2258
- [Travis Burtrum brought this change]
  SChannel/WinSSL: Replace Curl_none_md5sum with Curl_schannel_md5sum
- [Travis Burtrum brought this change]
  SChannel/WinSSL: Implement public key pinning
  Closes #1429
- bump: towards 7.58.1
- cookies: remove verbose "cookie size:" output
  It was once used for some debugging/verifying logic but should never have
  ended up in git!
- TODO: hardcode the "localhost" addresses
- TODO: CURL_REFUSE_CLEARTEXT
  An idea that popped up in discussions on twitter.
- progress-bar: don't use stderr explicitly, use bar->out
  Reported-By: Gisle Vanem
  Bug: https://github.com/curl/curl/commit/993dd5651a6c853bfe3870f6a69c7b329fa4e8ce#commitcomment-27070080
GitHub (24 Jan 2018)
- [Gisle Vanem brought this change]
  Fixes for MSDOS etc.
  djgpp do have 'mkdir(dir, mode)'. Other DOS-compilers does not
  But djgpp seems the only choice for MSDOS anyway.
  PellesC do have a 'F_OK' defined in it's <unistd.h>.
  Update year in Copyright.
- [Gisle Vanem brought this change]
  Fix small typo.
Version 7.58.0 (23 Jan 2018)
Daniel Stenberg (23 Jan 2018)
- RELEASE: 7.58.0
- [Gisle Vanem brought this change]
  progress-bar: get screen width on windows
- test1454: --connect-to with IPv6 address w/o IPv6 support!
- CONNECT_TO: fail attempt to set an IPv6 numerical without IPv6 support
  Bug: https://curl.haxx.se/mail/lib-2018-01/0087.html
  Reported-by: John Hascall
  Closes #2257
- docs: fix man page syntax to make test 1140 OK again
- http: prevent custom Authorization headers in redirects
  ... unless CURLOPT_UNRESTRICTED_AUTH is set to allow them. This matches how
  curl already handles Authorization headers created internally.
  Note: this changes behavior slightly, for the sake of reducing mistakes.
  Added test 317 and 318 to verify.
  Reported-by: Craig de Stigter
  Bug: https://curl.haxx.se/docs/adv_2018-b3bf.html
- curl: progress bar refresh, get width using ioctl()
  Get screen width from the environment variable COLUMNS first, if set. If
  not, use ioctl(). If nether works, assume 79.
  Closes #2242
  The "refresh" is for the -# output when no total transfer size is
  known. It will now only use a single updated line even for this case:
  The "-=O=-" ship moves when data is transferred. The four flying
  "hashes" move (on a sine wave) on each refresh, independent of data.
- RELEASE-NOTES: synced with bb0ffcc36
- libcurl-env.3: first take
- TODO: two possible name resolver improvements
- [Kartik Mahajan brought this change]
  http2: don't close connection when single transfer is stopped
  Fixes #2237
  Closes #2249
- test558: fix for multissl builds
  vtls.c:multissl_init() might do a curl_free() call so strip that out to
  make this work with more builds. We just want to verify that
  memorytracking works so skipping one line is no harm.
- examples/url2file.c: add missing curl_global_cleanup() call
  Reported-by: XhstormR on github
  Fixes #2245
- [Michael Gmelin brought this change]
  SSH: Fix state machine for ssh-agent authentication
  In case an identity didn't match[0], the state machine would fail in
  state SSH_AUTH_AGENT instead of progressing to the next identity in
  ssh-agent. As a result, ssh-agent authentication only worked if the
  identity required happened to be the first added to ssh-agent.
  This was introduced as part of commit c4eb10e2f06fbd6cc904f1d78e4, which
  stated that the "else" statement was required to prevent getting stuck
  in state SSH_AUTH_AGENT. Given the state machine's logic and libssh2's
  interface I couldn't see how this could happen or reproduce it and I
  also couldn't find a more detailed description of the problem which
  would explain a test case to reproduce the problem this was supposed to
  fix.
  [0] libssh2_agent_userauth returning LIBSSH2_ERROR_AUTHENTICATION_FAILED
  Closes #2248
- openssl: fix potential memory leak in SSLKEYLOGFILE logic
  Coverity CID 1427646.
- openssl: fix the libressl build again
  Follow-up to 84fcaa2e7. libressl does not have the API even if it says it is
  late OpenSSL version...
  Fixes #2246
  Closes #2247
  Reported-by: jungle-boogie on github
- unit1307: test many wildcards too
- curl_fnmatch: only allow 5 '*' sections in a single pattern
  ... to avoid excessive recursive calls. The number 5 is totally
  arbitrary and could be modified if someone has a good motivation.
- ftp-wildcard: fix matching an empty string with "*[^a]"
  .... and avoid advancing the pointer to trigger an out of buffer read.
  Detected by OSS-fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=5251
  Assisted-by: Max Dymond
- SMB: fix numeric constant suffix and variable types
  1. don't use "ULL" suffix since unsupported in older MSVC
  2. use curl_off_t instead of custom long long ifdefs
  3. make get_posix_time() not do unaligned data access
  Fixes #2211
  Closes #2240
  Reported-by: Chester Liu
- [rouzier brought this change]
  CURLOPT_TCP_NODELAY.3: fix typo
  Closes #2239
- smtp/pop3/imap_get_message: decrease the data length too...
  Follow-up commit to 615edc1f73 which was incomplete.
  Assisted-by: Max Dymond
  Detected by OSS-fuzz
  Bug: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=5206
- openssl: enable SSLKEYLOGFILE support by default
  Fixes #2210
  Closes #2236
Patrick Monnerat (14 Jan 2018)
- mime: clone mime tree upon easy handle duplication.
  A mime tree attached to an easy handle using CURLOPT_MIMEPOST is
  strongly bound to the handle: there is a pointer to the easy handle in
  each item of the mime tree and following the parent pointer list
  of mime items ends in a dummy part stored within the handle.
  Because of this binding, a mime tree cannot be shared between different
  easy handles, thus it needs to be cloned upon easy handle duplication.
  There is no way for the caller to get the duplicated mime tree
  handle: it is then set to be automatically destroyed upon freeing the
  new easy handle.
  New test 654 checks proper mime structure duplication/release.
  Add a warning note in curl_mime_data_cb() documentation about sharing
  user data between duplicated handles.
  Closes #2235
- docs: comment about CURLE_READ_ERROR returned by curl_mime_filedata
Daniel Stenberg (13 Jan 2018)
- test395: HTTP with overflow Content-Length value
- test394: verify abort of rubbish in Content-Length: value
- test393: verify --max-filesize with excessive Content-Length
- HTTP: bail out on negative Content-Length: values
  ... and make the max filesize check trigger if the value is too big.
  Updates test 178.
  Reported-by: Brad Spencer
  Fixes #2212
  Closes #2223
Marcel Raad (13 Jan 2018)
- [Dan Johnson brought this change]
  configure.ac: append extra linker flags instead of prepending them.
  Link order should list libraries after the libraries that use them,
  so when we're guessing that we might also need to add -ldl in order
  to use -lssl, we should add -ldl after -lssl.
  Closes https://github.com/curl/curl/pull/2234
Daniel Stenberg (13 Jan 2018)
- RELEASE-NOTES: synced with 6fa10c8fa
Jay Satiro (13 Jan 2018)
- setopt: fix SSLVERSION to allow CURL_SSLVERSION_MAX_ values
  Broken since f121575 (precedes 7.56.1).
  Bug: https://github.com/curl/curl/issues/2225
  Reported-by: cmfrolick@users.noreply.github.com
  Closes https://github.com/curl/curl/pull/2227
Patrick Monnerat (13 Jan 2018)
- setopt: reintroduce non-static Curl_vsetopt() for OS400 support
  This also upgrades ILE/RPG bindings with latest setopt options.
  Reported-By: jonrumsey on github
  Fixes #2230
  Closes #2233
Jay Satiro (11 Jan 2018)
- [Zhouyihai Ding brought this change]
  http2: fix incorrect trailer buffer size
  Prior to this change the stored byte count of each trailer was
  miscalculated and 1 less than required. It appears any trailer
  after the first that was passed to Curl_client_write would be truncated
  or corrupted as well as the size. Potentially the size of some
  subsequent trailer could be erroneously extracted from the contents of
  that trailer, and since that size is used by client write an
  out-of-bounds read could occur and cause a crash or be otherwise
  processed by client write.
  The bug appears to have been born in 0761a51 (precedes 7.49.0).
  Closes https://github.com/curl/curl/pull/2231
- [Basuke Suzuki brought this change]
  easy: fix connection ownership in curl_easy_pause
  Before calling Curl_client_chop_write(), change the owner of connection
  to the current Curl_easy handle. This will fix the issue #2217.
  Fixes https://github.com/curl/curl/issues/2217
  Closes https://github.com/curl/curl/pull/2221
Daniel Stenberg (9 Jan 2018)
- [Dimitrios Apostolou brought this change]
  system.h: Additionally check __LONG_MAX__ for defining curl_off_t
  __SIZEOF_LONG__ was introduced in GCC 4.4, __LONG_MAX__ was introduced
  in GCC 3.3.
  Closes #2216
- COPYING: it's 2018!
- progress: calculate transfer speed on milliseconds if possible
  to increase accuracy for quick transfers
  Fixes #2200
  Closes #2206
Jay Satiro (7 Jan 2018)
- scripts: allow all perl scripts to be run directly
  - Enable execute permission (chmod +x)
  - Change interpreter to /usr/bin/env perl
  Closes https://github.com/curl/curl/pull/2222
- mail-rcpt.d: fix short-text description
- build: remove HAVE_LIMITS_H check
  .. because limits.h presence isn't optional, it's required by C89.
  Ref: http://port70.net/~nsz/c/c89/c89-draft.html#2.2.4.2
  Closes https://github.com/curl/curl/pull/2215
- openssl: fix memory leak of SSLKEYLOGFILE filename
  - Free the copy of SSLKEYLOGFILE env returned by curl_getenv during ossl
    initialization.
  Caught by ASAN.
- Revert "curl/system.h: fix compilation with gcc on AIX PPC and IA64 HP-UX"
  This reverts commit c97648b55080343bb371522bf4233e94a2a13a99.
  SIZEOF_LONG should not be checked in system.h since that macro is only
  defined when building libcurl.
  Ref: https://github.com/curl/curl/pull/2186#issuecomment-354767080
  Ref: https://gcc.gnu.org/onlinedocs/cpp/Common-Predefined-Macros.html
Michael Kaufmann (30 Dec 2017)
- test1554: improve the error handling
- test1554: add global initialization and cleanup
Daniel Stenberg (29 Dec 2017)
- curl_version_info.3: call the argument 'age'
  Reported-by: Pete Lomax
  Bug: https://curl.haxx.se/mail/lib-2017-12/0074.html
Patrick Monnerat (27 Dec 2017)
- [Mikalai Ananenka brought this change]
  brotli: data at the end of content can be lost
  Decoding loop implementation did not concern the case when all
  received data is consumed by Brotli decoder and the size of decoded
  data internally hold by Brotli decoder is greater than CURL_MAX_WRITE_SIZE.
  For content with unencoded length greater than CURL_MAX_WRITE_SIZE this
  can result in the loss of data at the end of content.
  Closes #2194
Jay Satiro (26 Dec 2017)
- examples/cacertinmem: ignore cert-already-exists error
  - Ignore X509_R_CERT_ALREADY_IN_HASH_TABLE errors in the CTX callback
    since it's possible the cert may have already been loaded by libcurl.
  - Remove the EXAMPLE code in the CURLOPT_SSL_CTX_FUNCTION.3 doc.
    Instead have it direct the reader to this cacertinmem.c example.
  - Fix the CA certificate to use the right CA for example.com, Digicert.
  Bug: https://curl.haxx.se/mail/lib-2017-12/0057.html
  Reported-by: Thomas van Hesteren
  Closes https://github.com/curl/curl/pull/2182
- [Gisle Vanem brought this change]
  tool_getparam: Support size modifiers for --max-filesize
  - Move the size modifier detection code from limit-rate to its own
    function so that it can also be used with max-filesize.
  Size modifiers are the suffixes such as G (gigabyte), M (megabyte) etc.
  For example --max-filesize 1G
  Ref: https://curl.haxx.se/mail/archive-2017-12/0000.html
  Closes https://github.com/curl/curl/pull/2179
Steve Holme (22 Dec 2017)
- build: Fixed incorrect script termination from commit ad1dc10e61
- Makefile.vc: Added our standard copyright header
- winbuild: Added support for VC15
- build: Added Visual Studio 2017 project files
- build-wolfssl.bat: Added support for VC15
- build-openssl.bat: Added support for VC15
Jay Satiro (22 Dec 2017)
- [Dimitrios Apostolou brought this change]
  curl/system.h: fix compilation with gcc on AIX PPC and IA64 HP-UX
  Closes https://github.com/curl/curl/pull/2186
- [Mattias Fornander brought this change]
  examples/rtsp: fix error handling macros
  Closes https://github.com/curl/curl/pull/2185
Patrick Monnerat (20 Dec 2017)
- curl_easy_reset: release mime-related data.
  Move curl_mime_initpart() and curl_mime_cleanpart() calls to lower-level
  functions dealing with UserDefined structure contents.
  This avoids memory leakages on curl-generated part mime headers.
  New test 2073 checks this using the cli tool --next option: it
  triggers a valgrind error if bug is present.
  Bug: https://curl.haxx.se/mail/lib-2017-12/0060.html
  Reported-by: Martin Galvan
- content_encoding: rework zlib_inflate
  - When zlib version is < 1.2.0.4, process gzip trailer before considering
  extra data as an error.
  - Inflate with Z_BLOCK instead of Z_SYNC_FLUSH to maximize correct data
  and minimize corrupt data output.
  - Do not try to restart deflate decompression in raw mode if output has
  started or if the leading data is not available anymore.
  - New test 232 checks inflating raw-deflated content.
  Closes #2068
- brotli: allow compiling with version 0.6.0.
  Some error codes were not yet defined in brotli 0.6.0: do not issue code
  for them in this case.
Daniel Stenberg (13 Dec 2017)
- CURLOPT_READFUNCTION.3: refer to argument with correct name
  Bug: #2175
  [ci skip]
- rand: add a clang-analyzer work-around
  scan-build would warn on a potential access of an uninitialized
  buffer. I deem it a false positive and had to add this somewhat ugly
  work-around to silence it.
- krb5: fix a potential access of uninitialized memory
  A scan-build warning.
- conncache: fix a return code [regression]
  This broke in 07cb27c98e. Make sure to return 'result' properly. Pointed
  out by scan-build!
- curl: support >256 bytes warning messsages
  Bug: #2174
Michael Kaufmann (12 Dec 2017)
- libssh: fix a syntax error in configure.ac
  Follow-up to c92d2e1
  Closes #2172
Daniel Stenberg (12 Dec 2017)
- examples/smtp-mail.c: use separate defines for options and mail
  ... to make it clearer that the options want address-only, while the
  headers in an email can also have the real name.
  Assisted-by: Sean MacLennan
- THANKS: added missing names
  ... as I reran the contrithanks script after the mailmap name fixups.
- mailmap: added/clarified several names
- setopt: less *or equal* than INT_MAX/1000 should be fine
  ... for the CURLOPT_TIMEOUT, CURLOPT_CONNECTTIMEOUT and
  CURLOPT_SERVER_RESPONSE_TIMEOUT range checks.
  Reported-by: Dominik H
  Bug: https://curl.haxx.se/mail/lib-2017-12/0037.html
  Closes #2173
- [Dmitry Kostjuchenko brought this change]
  vtls: replaced getenv() with curl_getenv()
  Fixed undefined symbol of getenv() which does not exist when compiling
  for Windows 10 App (CURL_WINDOWS_APP). Replaced getenv() with
  curl_getenv() which is aware of getenv() absence when CURL_WINDOWS_APP
  is defined.
  Closes #2171
- RELEASE-NOTES: synced with 3b9ea70ee
- TODO: Expose tried IP addresses that failed
  Suggested-by: Rainer Canavan
  Closes #2126
- curl.1: mention http:// and https:// as valid proxy prefixes
- curl.1: documented two missing valid exit codes
- CURLOPT_DNS_LOCAL_IP4.3: fixed the seel also to not self-reference
- Revert "curl: don't set CURLOPT_INTERLEAVEDATA"
  This reverts commit 9ffad8eb1329bb35c8988115ac7ed85cf91ef955.
  It was actually added rather recently in 8e8afa82cbb629 due to a crash
  that would otherwise happen in the RTSP code. As I don't think we've
  fixed that behavior yet, we better keep this work-around until we have
  fixed it better.
Michael Kaufmann (10 Dec 2017)
- tests: mark data files as non-executable in git
- tests: update .gitignore for libtests
Daniel Stenberg (10 Dec 2017)
- multi_done: prune DNS cache
  Prune the DNS cache immediately after the dns entry is unlocked in
  multi_done. Timed out entries will then get discarded in a more orderly
  fashion.
  Test506 is updated
  Reported-by: Oleg Pudeyev
  Fixes #2169
  Closes #2170
- mailmap: fixup two old git Author "aliases"
Jay Satiro (10 Dec 2017)
- openssl: Disable file buffering for Win32 SSLKEYLOGFILE
  Prior to this change SSLKEYLOGFILE used line buffering on WIN32 just
  like it does for other platforms. However, the Windows CRT does not
  actually support line buffering (_IOLBF) and will use full buffering
  (_IOFBF) instead. We can't use full buffering because multiple processes
  may be writing to the file and that could lead to corruption, and since
  full buffering is the only buffering available this commit disables
  buffering for Windows SSLKEYLOGFILE entirely (_IONBF).
  Ref: https://github.com/curl/curl/pull/1346#issuecomment-350530901
Daniel Stenberg (10 Dec 2017)
- RESOLVE: output verbose text when trying to set a duplicate name
  ... to help users understand what is or isn't done!
- CURLOPT_DNS_CACHE_TIMEOUT.3: see also CURLOPT_RESOLVE
- [John DeHelian brought this change]
  sftp: allow quoted commands to use relative paths
  Closes #1900
Jay Satiro (8 Dec 2017)
- [Richard Alcock brought this change]
  CURLOPT_PRIVATE.3: fix grammar
  - Change "never does nothing" double-negative to "never does anything".
  Closes https://github.com/curl/curl/pull/2168
Daniel Stenberg (8 Dec 2017)
- curl: remove __EMX__ #ifdefs
  These are OS/2-specific things added to the code in the year 2000. They
  were always ugly. If there's any user left, they still don't need it
  done this way.
  Closes #2166
Jay Satiro (8 Dec 2017)
- openssl: improve data-pending check for https proxy
  - Allow proxy_ssl to be checked for pending data even when connssl does
    not yet have an SSL handle.
  This change is for posterity. Currently there doesn't seem to be a code
  path that will cause a pending data check when proxyssl could have
  pending data and the connssl handle doesn't yet exist [1].
  [1]: Recall that an https proxy connection starts out in connssl but if
  the destination is also https then the proxy SSL backend data is moved
  from connssl to proxyssl, which means connssl handle is temporarily
  empty until an SSL handle for the destination can be created.
  Ref: https://github.com/curl/curl/commit/f4a6238#commitcomment-24396542
  Closes https://github.com/curl/curl/pull/1916
Daniel Stenberg (8 Dec 2017)
- curl: don't set CURLOPT_INTERLEAVEDATA
  That data is only ever used by the CURLOPT_INTERLEAVEFUNCTION callback
  and that option isn't set or used by the curl tool!
  Updates the 9 tests that verify --libcurl
  Closes #2167
- curl.h: remove incorrect comment about ERRORBUFFER
  ... error messages are _not_ sent to stderr if this is not set.
- [Michael Felt brought this change]
  configure: add AX_CODE_COVERAGE only if using gcc
  Fixes #2076
  Closes #2125
- curl: limit -# update frequency for unknown total size
  Make it use a max 10Hz update frequency for this case as well. Return
  early if the "point" hasn't moved since last invoke.
  Reported-by: Elliot Saba
  Fixes #2158
  Closes #2163
- BINDINGS: another PostgreSQL client
  ...the former link is dead.
  Reported-by: Frank Gevaerts
- [Zachary Seguin brought this change]
  CONNECT: keep close connection flag in http_connect_state struct
  Fixes #2088
  Closes #2157
- [Per Malmberg brought this change]
  include: get netinet/in.h before linux/tcp.h
  ... to allow build on older Linux dists (specifically CentOS 4.8 on gcc
  4.8.5)
  Closes #2160
- openldap: fix checksrc nits
- [Stepan Broz brought this change]
  openldap: add commented out debug possibilities
  ... to aid debugging openldap library using its built-in debug messages.
  Closes #2159
- examples: move threaded-shared-conn.c to the "complicated" ones
  ... due it relying on pthreads to link.
- RELEASE-NOTES: synced with b261c44e8
  ... and bump next release version to 7.58.0
- [Jan Ehrhardt brought this change]
  URL: tolerate backslash after drive letter for FILE:
  ... as in "file://c:\some\path\curl.out"
  Reviewed-by: Matthew Kerwin
  Closes #2154
- [Randall S. Becker brought this change]
  tests: added netinet/in6.h includes in test servers
- [Randall S. Becker brought this change]
  configure: check for netinet/in6.h
  Needed by HPE NonStop NSE and NSX systems
  Fixes #2146
  Closes #2155
- curl-config: add --ssl-backends
  Lists all SSL backends that were enabled at build-time.
  Suggested-by: Oleg Pudeyev
  Fixes #2128
- conncache: only allow multiplexing within same multi handle
  Connections that are used for HTTP/1.1 Pipelining or HTTP/2 multiplexing
  only get additional transfers added to them if the existing connection
  is held by the same multi or easy handle. libcurl does not support doing
  HTTP/2 streams in different threads using a shared connection.
  Closes #2152
- threaded-shared-conn.c: fixed typo in commenta
- threaded-shared-conn.c: new example
- conncache: fix several lock issues
  If the lock is released before the dealings with the bundle is over, it may
  have changed by another thread in the mean time.
  Fixes #2132
  Fixes #2151
  Closes #2139
- libssh: remove dead code in sftp_qoute
  ... by removing a superfluous NULL pointer check that also confuses
  Coverity.
  Fixes #2143
  Closes #2153
- sasl_getmesssage: make sure we have a long enough string to pass
  For pop3/imap/smtp, added test 891 to somewhat verify the pop3
  case.
  For this, I enhanced the pingpong test server to be able to send back
  responses with LF-only instead of always using CRLF.
  Closes #2150
- libssh2: remove dead code from SSH_SFTP_QUOTE
  Figured out while reviewing code in the libssh backend. The pointer was
  checked for NULL after having been dereferenced, so we know it would
  always equal true or it would've crashed.
  Pointed-out-by: Nikos Mavrogiannopoulos
  Bug #2143
  Closes #2148
- ssh-libssh.c: please checksrc
Nikos Mavrogiannopoulos (4 Dec 2017)
- libssh: fixed dereference in statvfs access
  The behavior is now equivalent to ssh.c when SSH_SFTP_QUOTE_STATVFS
  handling fails.
  Fixes #2142
Daniel Stenberg (4 Dec 2017)
- [Guitared brought this change]
  RESOURCES: update spec names
  Closes #2145
Nikos Mavrogiannopoulos (3 Dec 2017)
- libssh: corrected use of sftp_statvfs() in SSH_SFTP_QUOTE_STATVFS
  The previous code was incorrectly following the libssh2 error detection
  for libssh2_sftp_statvfs, which is not correct for libssh's sftp_statvfs.
  Fixes #2142
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@gnutls.org>
- libssh: no need to call sftp_get_error as ssh_get_error is sufficient
  Fixes #2141
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@gnutls.org>
Daniel Stenberg (2 Dec 2017)
- libssh: fix minor static code analyzer nits
  - remove superfluous NULL check which otherwise tricks the static code
  analyzers to assume NULL pointer dereferences.
  - fix fallthrough in switch()
  - indent mistake
- openssl: pkcs12 is supported by boringssl
  Removes another #ifdef for BoringSSL
  Pointed-out-by: David Benjamin
  Closes #2134
- [Jay Satiro brought this change]
  travis: use pip2 instead of pip
  .. since now mac osx image expects pip2 or pip3, and doesn't know pip:
  0.01s$ pip install --user cpp-coveralls
  /Users/travis/.travis/job_stages: line 57: pip: command not found
  Ref: https://github.com/travis-ci/travis-ci/issues/8829
  Closes https://github.com/curl/curl/pull/2133
- [Nikos Mavrogiannopoulos brought this change]
  lib582: do not verify host for SFTP
  This SFTP test fails with libssh back-end due to failure to verify
  the peer. Disable peer verification in the test as there seems to
  be the intention of the test.
  Note that the libssh back-end automatically verifies the peer's
  host using the default known_hosts file.
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@gnutls.org>
- [Nikos Mavrogiannopoulos brought this change]
  libssh: added SFTP support
  The SFTP back-end supports asynchronous reading only, limited
  to 32-bit file length. Writing is synchronous with no other
  limitations.
  This also brings keyboard-interactive authentication.
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@gnutls.org>
- [Nikos Mavrogiannopoulos brought this change]
  symbols-in-versions: added new symbols with 7.56.3 version
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@gnutls.org>
- [Nikos Mavrogiannopoulos brought this change]
  .travis.yml: added build --with-libssh
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@redhat.com>
- [Nikos Mavrogiannopoulos brought this change]
  libssh2: return CURLE_UPLOAD_FAILED on failure to upload
  This brings its in sync with the error code returned by the
  libssh backend.
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@gnutls.org>
- [Nikos Mavrogiannopoulos brought this change]
  libssh2: send the correct CURLE error code on scp file not found
  That also updates tests to expect the right error code
  libssh2 back-end returns CURLE_SSH error if the remote file
  is not found. Expect instead CURLE_REMOTE_FILE_NOT_FOUND
  which is sent by the libssh backend.
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@redhat.com>
- [Nikos Mavrogiannopoulos brought this change]
  Added support for libssh SSH SCP back-end
  libssh is an alternative library to libssh2.
  https://www.libssh.org/
  That patch set also introduces support for ECDSA
  ed25519 keys, as well as gssapi authentication.
  Signed-off-by: Nikos Mavrogiannopoulos <nmav@redhat.com>
- RELEASE-NOTES: synced with af8cc7a69
- curlver: towards 7.57.1
- [W. Mark Kubacki brought this change]
  lib: don't export all symbols, just everything curl_*
  Absent any 'symbol map' or script to limit what gets exported, static
  linking of libraries previously resulted in a libcurl with curl's and
  those other symbols being (re-)exported.
  This did not happen if 'versioned symbols' were enabled (which is not
  the default) because then a version script is employed.
  This limits exports to everything starting in 'curl_*'., which is
  what "libcurl.vers" exports.
  This avoids strange side-effects such as with mixing methods
  from system libraries and those erroneously offered by libcurl.
  Closes #2127
- [Johannes Schindelin brought this change]
  SSL: Avoid magic allocation of SSL backend specific data
  Originally, my idea was to allocate the two structures (or more
  precisely, the connectdata structure and the four SSL backend-specific
  strucutres required for ssl[0..1] and proxy_ssl[0..1]) in one go, so
  that they all could be free()d together.
  However, getting the alignment right is tricky. Too tricky.
  So let's just bite the bullet and allocate the SSL backend-specific
  data separately.
  As a consequence, we now have to be very careful to release the memory
  allocated for the SSL backend-specific data whenever we release any
  connectdata.
  Signed-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>
  Closes #2119
- examples/xmlstream.c: don't switch off CURL_GLOBAL_SSL
  Reported-by: Dima Tisnek
- travis: add boringssl build
  Uses a separate build without --enable-debug and no valgrind.
  The debug option causes far too many warnings in boringssl's headers
  (C++ comments, trailing commas etc).  Valgrind triggers some false
  positive errors in thread-local data used by boringssl.
  Closes #2118
Version 7.57.0 (29 Nov 2017)
Daniel Stenberg (29 Nov 2017)
- RELEASE-NOTES: curl 7.57.0
- THANKS: added contributors from 7.57.0 release
- openssl: fix boringssl build again
  commit d3ab7c5a21e broke the boringssl build since it doesn't have
  RSA_flags(), so we disable that code block for boringssl builds.
  Reported-by: W.
Mark Kubacki
  Fixes #2117
- curl_ntlm_core.c: use the limits.h's SIZE_T_MAX if provided
- libcurl-share.3: the connection cache is shareable now
- global_init: ignore CURL_GLOBAL_SSL's absense
  This bit is no longer used. It is not clear what it meant for users to
  "init the TLS" in a world with different TLS backends and since the
  introduction of multissl, libcurl didn't properly work if inited without
  this bit set.
  Not a single user responded to the call for users of it:
  https://curl.haxx.se/mail/lib-2017-11/0072.html
  Reported-by: Evgeny Grin
  Assisted-by: Jay Satiro
  Fixes #2089
  Fixes #2083
  Closes #2107
- ntlm: avoid integer overflow for malloc size
  Reported-by: Alex Nichols
  Assisted-by: Kamil Dudka and Max Dymond
  CVE-2017-8816
  Bug: https://curl.haxx.se/docs/adv_2017-11e7.html
- wildcardmatch: fix heap buffer overflow in setcharset
  The code would previous read beyond the end of the pattern string if the
  match pattern ends with an open bracket when the default pattern
  matching function is used.
  Detected by OSS-Fuzz:
  https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=4161
  CVE-2017-8817
  Bug: https://curl.haxx.se/docs/adv_2017-ae72.html
- [Jay Satiro brought this change]
  url: fix alignment of ssl_backend_data struct
  - Align the array of ssl_backend_data on a max 32 byte boundary.
  8 is likely to be ok but I went with 32 for posterity should one of
  the ssl_backend_data structs change to contain a larger sized variable
  in the future.
  Prior to this change (since dev 70f1db3, release 7.56) the connectdata
  structure was undersized by 4 bytes in 32-bit builds with ssl enabled
  because long long * was mistakenly used for alignment instead of
  long long, with the intention being an 8 byte boundary. Also long long
  may not be an available type.
  The undersized connectdata could lead to oob read/write past the end in
  what was expected to be the last 4 bytes of the connection's secondary
  socket https proxy ssl_backend_data struct (the secondary socket in a
  connection is used by ftp, others?).
  Closes https://github.com/curl/curl/issues/2093
  CVE-2017-8818
  Bug: https://curl.haxx.se/docs/adv_2017-af0a.html
- ssh: remove check for a NULL pointer (!)
  With this check present, scan-build warns that we might dereference this
  point in other places where it isn't first checked for NULL. Thus, if it
  *can* be NULL we have a problem on a few places. However, this pointer
  should not be possible to be NULL here so I remove the check and thus
  also three different scan-build warnings.
  Closes #2111
- [Matthew Kerwin brought this change]
  test: add test for bad UNC/SMB path in file: URL
- [Matthew Kerwin brought this change]
  test: add tests to ensure basic file: URLs
- [Matthew Kerwin brought this change]
  URL: update "file:" URL handling
  * LOTS of comment updates
  * explicit error for SMB shares (e.g. "file:////share/path/file")
  * more strict handling of authority (i.e. "//localhost/")
  * now accepts dodgy old "C:|" drive letters
  * more precise handling of drive letters in and out of Windows
    (especially recognising both "file:c:/" and "file:/c:/")
  Closes #2110
- metalink: fix memory-leak and NULL pointer dereference
  Reported by scan-build
  Closes #2109
- [Alessandro Ghedini brought this change]
  connect: add support for new TCP Fast Open API on Linux
  The new API added in Linux 4.11 only requires setting a socket option
  before connecting, without the whole sento() machinery.
  Notably, this makes it possible to use TFO with SSL connections on Linux
  as well, without the need to mess around with OpenSSL (or whatever other
  SSL library) internals.
  Closes #2056
- make: fix "make distclean"
  Fixes #2097
  Closes #2108
- RELEASE-NOTES: synced with 31f18d272
Jay Satiro (23 Nov 2017)
- connect: improve the bind error message
  eg consider a non-existent interface eth8, curl --interface eth8
  Before: curl: (45) Could not resolve host: eth8
  After: curl: (45) Couldn't bind to 'eth8'
  Bug: https://github.com/curl/curl/issues/2104
  Reported-by: Alfonso Martone
Daniel Stenberg (23 Nov 2017)
- examples/rtsp: clear RANGE again after use
  Fixes #2106
  Reported-by: youngchopin on github
- [Michael Kaufmann brought this change]
  test1264: verify URL with space in host name being rejected
- url: reject ASCII control characters and space in host names
  Host names like "127.0.0.1 moo" would otherwise be accepted by some
  getaddrinfo() implementations.
  Updated test 1034 and 1035 accordingly.
  Fixes #2073
  Closes #2092
- Curl_open: fix OOM return error correctly
  Closes #2098
- http2: fix "Value stored to 'end' is never read" scan-build error
- http2: fix "Value stored to 'hdbuf' is never read" scan-build error
- openssl: fix "Value stored to 'rc' is never read" scan-build error
- mime: fix "Value stored to 'sz' is never read" scan-build error
- Curl_llist_remove: fix potential NULL pointer deref
  Fixes a scan-build warning.
- ntlm: remove unnecessary NULL-check to please scan-build
- BUGS: spellchecked
Jay Satiro (18 Nov 2017)
- [fmmedeiros brought this change]
  examples/curlx: Fix code style
  - Add braces around multi-line if statement.
  Closes https://github.com/curl/curl/pull/2096
Daniel Stenberg (17 Nov 2017)
- resolve: allow IP address within [] brackets
  ... so that IPv6 addresses can be passed like they can for connect-to
  and how they're used in URLs.
  Added test 1324 to verify
  Reported-by: Alex Malinovich
  Fixes #2087
  Closes #2091
- [Pavol Markovic brought this change]
  macOS: Fix missing connectx function with Xcode version older than 9.0
  The previous fix https://github.com/curl/curl/pull/1788 worked just for
  Xcode 9. This commit extends the fix to older Xcode versions effectively
  by not using connectx function.
  Fixes https://github.com/curl/curl/issues/1330
  Fixes https://github.com/curl/curl/issues/2080
  Closes https://github.com/curl/curl/pull/1336
  Closes #2082
- [Dirk Feytons brought this change]
  openssl: fix too broad use of HAVE_OPAQUE_EVP_PKEY
  Fixes #2079
  Closes #2081
- TODO: ignore private IP addresses in PASV response
  Closes #1455
- RELEASE-NOTES: synced with ae7369b6d
Michael Kaufmann (14 Nov 2017)
- URL: return error on malformed URLs with junk after IPv6 bracket
  Follow-up to aadb7c7. Verified by new test 1263.
  Closes #2072
Daniel Stenberg (14 Nov 2017)
- INTERNALS: we may use libidn2 now, not libidn
Patrick Monnerat (13 Nov 2017)
- zlib/brotli: only include header files in modules needing them
  There is a conflict on symbol 'free_func' between openssl/crypto.h and
  zlib.h on AIX. This is an attempt to resolve it.
  Bug: https://curl.haxx.se/mail/lib-2017-11/0032.html
  Reported-By: Michael Felt
Daniel Stenberg (13 Nov 2017)
- SMB: fix uninitialized local variable
  Reported-by: Brian Carpenter
- [Orgad Shaneh brought this change]
  connect.c: remove executable bit on file
  Closes #2071
- [hsiao yi brought this change]
  README.md: fixed layout
  Closes #2069
- setopt: split out curl_easy_setopt() to its own file
  ... to make url.c smaller.
  Closes #1944
Jay Satiro (10 Nov 2017)
- [John Starks brought this change]
  cmake: Add missing setmode check
  Ensure HAVE_SETMODE is set to 1 on OSes that have setmode. Without this,
  curl will corrupt binary files when writing them to stdout on Windows.
  Closes https://github.com/curl/curl/pull/2067
Daniel Stenberg (10 Nov 2017)
- curl_share_setopt: va_end was not called if conncache errors
  CID 984459, detected by Coverity
Sergei Nikulov (10 Nov 2017)
- [John Starks brought this change]
  cmake: Correctly include curl.rc in Windows builds (#2064)
  Update CMakeLists.txt to add curl.rc to the correct list.
Daniel Stenberg (9 Nov 2017)
- RELEASE-NOTES: synced with 32828cc4f
- [Luca Boccassi brought this change]
  --interface: add support for Linux VRF
  The --interface command (CURLOPT_INTERFACE option) already uses
  SO_BINDTODEVICE on Linux, but it tries to parse it as an interface or IP
  address first, which fails in case the user passes a VRF.
  Try to use the socket option immediately and parse it as a fallback
  instead.  Update the documentation to mention this feature, and that it
  requires the binary to be ran by root or with CAP_NET_RAW capabilities
  for this to work.
  Closes #2024
- curl_share_setopt.3: document CURL_LOCK_DATA_CONNECT
  Closes #2043
- examples: add shared-connection-cache
- test1554: verify connection cache sharing
- share: add support for sharing the connection cache
- imap: deal with commands case insensitively
  As documented in RFC 3501 section 9:
  https://tools.ietf.org/html/rfc3501#section-9
  Closes #2061
- connect: store IPv6 connection status after valid connection
  ... previously it would store it already in the happy eyeballs stage
  which could lead to the IPv6 bit being set for an IPv4 connection,
  leading to curl not wanting to do EPSV=>PASV for FTP transfers.
  Closes #2053
- curl_multi_fdset.3: emphasize curl_multi_timeout
  ... even when there's no socket to wait for, the timeout can still be
  very short.
Jay Satiro (9 Nov 2017)
- content_encoding: fix inflate_stream for no bytes available
  - Don't call zlib's inflate() when avail_in stream bytes is 0.
  This is a follow up to the parent commit 19e66e5. Prior to that change
  libcurl's inflate_stream could call zlib's inflate even when no bytes
  were available, causing inflate to return Z_BUF_ERROR, and then
  inflate_stream would treat that as a hard error and return
  CURLE_BAD_CONTENT_ENCODING.
  According to the zlib FAQ, Z_BUF_ERROR is not fatal.
  This bug would happen randomly since packet sizes are arbitrary. A test
  of 10,000 transfers had 55 fail (ie 0.55%).
  Ref: https://zlib.net/zlib_faq.html#faq05
  Closes https://github.com/curl/curl/pull/2060
Patrick Monnerat (7 Nov 2017)
- content_encoding: do not write 0 length data
Daniel Stenberg (6 Nov 2017)
- fnmatch: remove dead code
  There was a duplicate check for backslashes in the setcharset()
  function.
  Coverity CID 1420611
- url: remove unncessary NULL-check
  Since 'conn' won't be NULL in there and we also access the pointer in
  there without the check.
  Coverity CID 1420610
Viktor Szakats (6 Nov 2017)
- src/Makefile.m32: fix typo in brotli lib customization
  Ref cc1f4436099decb9d1a7034b2bb773a9f8379d31
- Makefile.m32: allow to customize brotli libs
  It adds the ability to link against static brotli libs.
  Also fix brotli include path.
Patrick Monnerat (5 Nov 2017)
- travis: add a job with brotli enabled
- [Viktor Szakats brought this change]
  Makefile.m32: add brotli support
- HTTP: implement Brotli content encoding
  This uses the brotli external library (https://github.com/google/brotli).
  Brotli becomes a feature: additional curl_version_info() bit and
  structure fields are provided for it and CURLVERSION_NOW bumped.
  Tests 314 and 315 check Brotli content unencoding with correct and
  erroneous data.
  Some tests are updated to accomodate with the now configuration dependent
  parameters of the Accept-Encoding header.
- HTTP: support multiple Content-Encodings
  This is implemented as an output streaming stack of unencoders, the last
  calling the client write procedure.
  New test 230 checks this feature.
  Bug: https://github.com/curl/curl/pull/2002
  Reported-By: Daniel Bankhead
Jay Satiro (4 Nov 2017)
- url: remove arg value check from CURLOPT_SSH_AUTH_TYPES
  Since CURLSSH_AUTH_ANY (aka CURLSSH_AUTH_DEFAULT) is ~0 an arg value
  check on this option is incorrect; we have to accept any value.
  Prior to this change since f121575 (7.56.1+) CURLOPT_SSH_AUTH_TYPES
  erroneously rejected CURLSSH_AUTH_ANY with CURLE_BAD_FUNCTION_ARGUMENT.
  Bug: https://github.com/curl/curl/commit/f121575#commitcomment-25347120
Daniel Stenberg (4 Nov 2017)
- ntlm: avoid malloc(0) for zero length passwords
  It triggers an assert() when built with memdebug since malloc(0) may
  return NULL *or* a valid pointer.
  Detected by OSS-Fuzz: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=4054
  Assisted-by: Max Dymond
  Closes #2054
- RELEASE-NOTES: synced with ee8016b3d
- curl: speed up handling of many URLs
  By properly keeping track of the last entry in the list of URLs/uploads
  to handle, curl now avoids many meaningless traverses of the list which
  speeds up many-URL handling *MASSIVELY* (several magnitudes on 100K
  URLs).
  Added test 1291, to verify that it doesn't take ages - but we don't have
  any detection of "too slow" command in the test suite.
  Reported-by: arainchik on github
  Fixes #1959
  Closes #2052
- curl: pass through [] in URLs instead of calling globbing error
  Assisted-by: Per Lundberg
  Fixes #2044
  Closes #2046
  Closes #2048
- CURLOPT_INFILESIZE: accept -1
  Regression since f121575
  Reported-by: Petr Voytsik
  Fixes #2047
Jay Satiro (2 Nov 2017)
- url: fix CURLOPT_DNS_CACHE_TIMEOUT arg value check to allow -1
  Prior to this change since f121575 (7.56.1+) CURLOPT_DNS_CACHE_TIMEOUT
  erroneously rejected -1 with CURLE_BAD_FUNCTION_ARGUMENT.
Dan Fandrich (1 Nov 2017)
- http2: Fixed OOM handling in upgrade request
  This caused the torture tests on test 1800 to fail.
- tests: Fixed torture tests on tests 556 and 650
  Test cleanup after OOM wasn't being consistently performed.
Daniel Stenberg (1 Nov 2017)
- CURLOPT_MAXREDIRS: allow -1 as a value
  ... which is valid according to documentation. Regression since
  f121575c0b5f.
  Verified now in test 501.
  Reported-by: cbartl on github
  Fixes #2038
  Closes #2039
- include: remove conncache.h inclusion from where its not needed
Jay Satiro (1 Nov 2017)
- url: fix CURLOPT_POSTFIELDSIZE arg value check to allow -1
  .. also add same arg value check to CURLOPT_POSTFIELDSIZE_LARGE.
  Prior to this change since f121575 (7.56.1+) CURLOPT_POSTFIELDSIZE
  erroneously rejected -1 value with CURLE_BAD_FUNCTION_ARGUMENT.
  Bug: https://curl.haxx.se/mail/lib-2017-11/0000.html
  Reported-by: Andrew Lambert
Daniel Stenberg (31 Oct 2017)
- cookie: avoid NULL dereference
  ... when expiring old cookies.
  Reported-by: Pavel Gushchin
  Fixes #2032
  Closes #2035
Marcel Raad (30 Oct 2017)
- memdebug: use send/recv signature for curl_dosend/curl_dorecv
  This avoids build errors and warnings caused by implicit casts.
  Closes https://github.com/curl/curl/pull/2031
Daniel Stenberg (30 Oct 2017)
- [Juro Bystricky brought this change]
  mkhelp.pl: support reproducible build
  Do not generate line with the current date, such as:
  * Generation time: Tue Oct-24 18:01:41 2017
  This will improve reproducibility. The generated string is only
  part of a comment, so there should be no adverse consequences.
  Signed-off-by: Juro Bystricky <juro.bystricky@intel.com>
  closes #2026
Dan Fandrich (30 Oct 2017)
- runtests.pl: Fixed typo in message
Daniel Stenberg (30 Oct 2017)
- curlx: the timeval functions are no longer provided as curlx_*
  Pointed-out-by: Dmitri Tikhonov
  Bug: #2034
- select: update comments
  s/curlx_tvnow/Curl_now
- INTERNALS: remove curlx_tv* functions no longer provided
- [Dmitri Tikhonov brought this change]
  timeval: use mach time on MacOS
  If clock_gettime() is not supported, use mach_absolute_time() on MacOS.
  closes #2033
Patrick Monnerat (29 Oct 2017)
- cli tool: improve ";type=" handling in -F option arguments
- cli tool: in -F option arg, comma is a delimiter for files only
  Also upgrade test 1133 to cover this case and clarify man page about
  form data quoting.
  Bug: https://github.com/curl/curl/issues/2022
  Reported-By: omau on github
Daniel Stenberg (29 Oct 2017)
- timeleft: made two more users of Curl_timeleft use timediff_t
Jakub Zakrzewski (28 Oct 2017)
- cmake: Export libcurl and curl targets to use by other cmake projects
  The config files define curl and libcurl targets as imported targets
  CURL::curl and CURL::libcurl. For backward compatibility with CMake-
  provided find-module the CURL_INCLUDE_DIRS and CURL_LIBRARIES are
  also set.
  Closes #1879
Daniel Stenberg (28 Oct 2017)
- RELEASE-NOTES: synced with f20cbac97
- [Florin Petriuc brought this change]
  auth: Added test cases for RFC7616
  Updated docs to include support for RFC7616
  Signed-off-by: Florin <petriuc.florin@gmail.com>
  Closes #1934
- [Florin Petriuc brought this change]
  auth: add support for RFC7616 - HTTP Digest access authentication
  Signed-off-by: Florin <petriuc.florin@gmail.com>
- [Daniel Bankhead brought this change]
  TODO: support multiple Content-Encodings
  Closes #2002
- ROADMAP: cleanup
  Removed done stuff. Removed entries no longer considered for the near
  term.
- [Magicansk brought this change]
  ROADMAP.md: spelling fixes
  Closes #2028
- Curl_timeleft: change return type to timediff_t
  returning 'time_t' is problematic when that type is unsigned and we
  return values less than zero to signal "already expired", used in
  several places in the code.
  Closes #2021
- appveyor: add a win32 build
- setopt: fix CURLOPT_SSH_AUTH_TYPES option read
  Regression since f121575c0b5f
  Reported-by: Rob Cotrone
Marcel Raad (27 Oct 2017)
- resolvers: only include anything if needed
  This avoids warnings about unused stuff.
  Closes https://github.com/curl/curl/pull/2023
Daniel Stenberg (27 Oct 2017)
- HELP-US: rename the subtitle too since the label is changed
  "PR-welcome" was the former name.
- curl_setup.h: oops, shorten the too long line
- [Martin Storsjo brought this change]
  curl_setup: Improve detection of CURL_WINDOWS_APP
  If WINAPI_FAMILY is defined, it should be safe to try to include
  winapifamily.h to check what the define evaluates to.
  This should fix detection of CURL_WINDOWS_APP if building with
  _WIN32_WINNT set to 0x0600.
  Closes #2025
Jay Satiro (26 Oct 2017)
- transfer: Fix chunked-encoding upload bug
  - When uploading via chunked-encoding don't compare file size to bytes
    sent to determine whether the upload has finished.
  Chunked-encoding adds its own overhead which why the bytes sent is not
  equal to the file size. Prior to this change if a file was uploaded in
  chunked-encoding and its size was known it was possible that the upload
  could end prematurely without sending the final few chunks. That would
  result in a server hang waiting for the remaining data, likely followed
  by a disconnect.
  The scope of this bug is limited to some arbitrary file sizes which have
  not been determined. One size that triggers the bug is 475020.
  Bug: https://github.com/curl/curl/issues/2001
  Reported-by: moohoorama@users.noreply.github.com
  Closes https://github.com/curl/curl/pull/2010
Daniel Stenberg (26 Oct 2017)
- timeval: make timediff_t also work on 32bit windows
  ... by using curl_off_t for the typedef if time_t is larger than 4
  bytes.
  Reported-by: Gisle Vanem
  Bug: https://github.com/curl/curl/commit/b9d25f9a6b3ca791385b80a6a3c3fa5ae113e1e0#co
  mmitcomment-25205058
  Closes #2019
- curl_fnmatch: return error on illegal wildcard pattern
  ... instead of doing an infinite loop!
  Added test 1162 to verify.
  Reported-by: Max Dymond
  Fixes #2015
  Closes #2017
- [Max Dymond brought this change]
  wildcards: don't use with non-supported protocols
  Fixes timeouts in the fuzzing tests for non-FTP protocols.
  Closes #2016
- [Max Dymond brought this change]
  multi: allow table handle sizes to be overridden
  Allow users to specify their own hash define for
  CURL_CONNECTION_HASH_SIZE so that both values can be overridden.
  Closes #1982
- time: rename Curl_tvnow to Curl_now
  ... since the 'tv' stood for timeval and this function does not return a
  timeval struct anymore.
  Also, cleaned up the Curl_timediff*() functions to avoid typecasts and
  clean up the descriptive comments.
  Closes #2011
- ftplistparser: follow-up cleanup to remove PL_ERROR()
- [Max Dymond brought this change]
  ftplistparser: free off temporary memory always
  When using the FTP list parser, ensure that the memory that's
  allocated is always freed.
  Detected by OSS-fuzz: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=3682
  Closes #2013
- timediff: return timediff_t from the time diff functions
  ... to cater for systems with unsigned time_t variables.
  - Renamed the functions to curlx_timediff and Curl_timediff_us.
  - Added overflow protection for both of them in either direction for
    both 32 bit and 64 bit time_ts
  - Reprefixed the curlx_time functions to use Curl_*
  Reported-by: Peter Piekarski
  Fixes #2004
  Closes #2005
- [Paul Howarth brought this change]
  libtest: Add required test libraries for lib1552 and lib1553
  They use $(TESTUTIL) and thus should use $(TESTUTIL_LIBS) too.
  This fixes build failures on Fedora 13.
  Closes #2006
- [Alessandro Ghedini brought this change]
  libcurl-tutorial.3: fix typo
  closes #2008
Alessandro Ghedini (23 Oct 2017)
- curl_mime_filedata.3: fix typos
Daniel Stenberg (23 Oct 2017)
- RELEASE-NOTES: clean slate towards 7.57.0
- [Max Dymond brought this change]
  travis: exit if any steps fail
  We don't expect any steps to fail in travis. Exit the script if they do.
  Closes #1966
Version 7.56.1 (23 Oct 2017)
Daniel Stenberg (23 Oct 2017)
- RELEASE-NOTES: 7.56.1
- THANKS: update at 7.56.1 release time
- [Jon DeVree brought this change]
  mk-ca-bundle: Remove URL for aurora
  Aurora is no longer used by Mozilla
  https://hacks.mozilla.org/2017/04/simplifying-firefox-release-channels/
- [Jon DeVree brought this change]
  mk-ca-bundle: Fix URL for NSS
  The 'tip' is the most recent branch committed to, this should be
  'default' like the URLs for the browser are.
  Closes #1998
- imap: if a FETCH response has no size, don't call write callback
  CVE-2017-1000257
  Reported-by: Brian Carpenter and 0xd34db347
  Also detected by OSS-Fuzz: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=3586
- ftp: reject illegal IP/port in PASV 227 response
  ... by using range checks. Among other things, this avoids an undefined
  behavior for a left shift that could happen on negative or very large
  values.
  Closes #1997
  Detected by OSS-fuzz: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=3694
Patrick Monnerat (20 Oct 2017)
- test653: check reuse of easy handle after mime data change
  See issue #1999
- mime: do not reuse previously computed multipart size
  The contents might have changed: size must be recomputed.
  Reported-by: moteus on github
  Fixes #1999
- test308: disable if MultiSSL feature enabled
  Even if OpenSSL is enabled, it might not be the default backend when
  multi-ssl is enabled, causing the test to fail.
- runtests: support MultiSSL client feature
- vtls: change struct Curl_ssl `close' field name to `close_one'.
  On OS/400, `close' is an ASCII system macro that corrupts the code if
  not used in a context not targetting the close() system API.
- os400: add missing symbols in config file.
  Also adjust makefile to renamed files and warn about installation dirs mix-up.
- test652: curl_mime_data + base64 encoder with large contents
- mime: limit bas64-encoded lines length to 76 characters
Daniel Stenberg (16 Oct 2017)
- RELEASE-NOTES: synced with f121575c0
- setopt: range check most long options
  ... filter early instead of risking "funny values" having to be dealt
  with elsewhere.
- setopt: avoid integer overflows when setting millsecond values
  ... that are multiplied by 1000 when stored.
  For 32 bit long systems, the max value accepted (2147483 seconds) is >
  596 hours which is unlikely to ever be set by a legitimate application -
  and previously it didn't work either, it just caused undefined behavior.
  Also updated the man pages for these timeout options to mention the
  return code.
  Closes #1938
Viktor Szakats (15 Oct 2017)
- makefile.m32: allow to override gcc, ar and ranlib
  Allow to ovverride certain build tools, making it possible to
  use LLVM/Clang to build curl. The default behavior is unchanged.
  To build with clang (as offered by MSYS2), these settings can
  be used:
  CURL_CC=clang
  CURL_AR=llvm-ar
  CURL_RANLIB=llvm-ranlib
  Closes https://github.com/curl/curl/pull/1993
- ldap: silence clang warning
  Use memset() to initialize a structure to avoid LLVM/Clang warning:
  ldap.c:193:39: warning: missing field 'UserLength' initializer [-Wmissing-field-initializers]
  Closes https://github.com/curl/curl/pull/1992
Daniel Stenberg (14 Oct 2017)
- runtests: use valgrind for torture as well
  NOTE: it makes them terribly slow. I recommend only using valgrind for
  specific torture tests or using lots of patience.
- memdebug: trace send, recv and socket
  ... to allow them to be included in torture tests too.
  closes #1980
- configure: remove the C++ compiler check
  ... we used it only for the fuzzer, which we now have in a separate git
  repo.
  Closes #1990
Patrick Monnerat (13 Oct 2017)
- mime: do not call failf() if easy handle is NULL.
Daniel Stenberg (13 Oct 2017)
- test651: curl_formadd with huge COPYCONTENTS
- mime: fix the content reader to handle >16K data properly
  Reported-by: Jeroen Ooms
  Closes #1988
Patrick Monnerat (12 Oct 2017)
- mime: keep "text/plain" content type if user-specified.
  Include test cases in 554, 587, 650.
  Fixes https://github.com/curl/curl/issues/1986
- cli tool: use file2memory() to buffer stdin in -F option.
  Closes PR https://github.com/curl/curl/pull/1985
- cli tool: reimplement stdin buffering in -F option.
  If stdin is not a regular file, its content is memory-buffered to enable
  a possible data "rewind".
  In all cases, stdin data size is determined before real use to avoid
  having an unknown part's size.
  --libcurl generated code is left as an unbuffered stdin fread/fseek callback
  part with unknown data size.
  Buffering is not supported in deprecated curl_formadd() API.
Daniel Stenberg (12 Oct 2017)
- winbuild/BUILD.WINDOWS.txt: mention WITH_NGHTTP2
- HELP-US: the label "PR-welcome" is now renamed to "help wanted"
  following the new github "standard"
- RELEASE-NOTES: synced with 5505df7d2
Jay Satiro (11 Oct 2017)
- [Artak Galoyan brought this change]
  url: Update current connection SSL verify params in setopt
  Now VERIFYHOST, VERIFYPEER and VERIFYSTATUS options change during active
  connection updates the current connection's (i.e.'connectdata'
  structure) appropriate ssl_config (and ssl_proxy_config) structures
  variables, making these options effective for ongoing connection.
  This functionality was available before and was broken by the
  following change:
  "proxy: Support HTTPS proxy and SOCKS+HTTP(s)"
  CommitId: cb4e2be7c6d42ca0780f8e0a747cecf9ba45f151.
  Bug: https://github.com/curl/curl/issues/1941
  Closes https://github.com/curl/curl/pull/1951
Daniel Stenberg (11 Oct 2017)
- [David Benjamin brought this change]
  openssl: don't use old BORINGSSL_YYYYMM macros
  Those were temporary things we'd add and remove for our own convenience
  long ago. The last few stayed around for too long as an oversight but
  have since been removed. These days we have a running
  BORINGSSL_API_VERSION counter which is bumped when we find it
  convenient, but 2015-11-19 was quite some time ago, so just check
  OPENSSL_IS_BORINGSSL.
  Closes #1979
- test950; verify SMTP with custom request
- ftpserver: support case insensitive commands
- smtp_done: free data before returning (on send failure)
  ... as otherwise it could leak that memory.
  Detected by OSS-fuzz:
  https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=3600
  Assisted-by: Max Dymond
  Closes #1977
- FTP: URL decode path for dir listing in nocwd mode
  Reported-by: Zenju on github
  Test 244 added to verify
  Fixes #1974
  Closes #1976
- test298: verify --ftp-method nowcwd with URL encoded path
  Ref: #1974
- CURLOPT_XFERINFODATA.3: fix duplicate see also
- CURLOPT_NOPROGRESS.3: also refer to xferinfofunction
- FAQ: s/CURLOPT_PROGRESSFUNCTION/CURLOPT_XFERINFOFUNCTION
- openssl: enable PKCS12 support for !BoringSSL
  Enable PKCS12 for all non-boringssl builds without relying on configure
  or cmake checks.
  Bug: https://curl.haxx.se/mail/lib-2017-10/0007.html
  Reported-by: Christian Schmitz
  Closes #1948
- [Kristiyan Tsaklev brought this change]
  curl: don't pass semicolons when parsing Content-Disposition
  Test 1422 updated to verify.
  Closes #1964
Patrick Monnerat (9 Oct 2017)
- mime: properly unbind mime structure in curl_mime_free().
  This allows freeing a mime structure bound to the easy handle before
  curl_easy_cleanup().
  Fixes #1970.
Daniel Stenberg (9 Oct 2017)
- RTSP: avoid integer overflow on funny RTSP response
  ... like a very large non-existing RTSP version number.
  Added test 577 to verify.
  Detected by OSS-fuzz.
  Closes #1969
Patrick Monnerat (8 Oct 2017)
- ftpserver: properly reset $ftptargetdir.
- test643: verify curl_mime_subparts() rejects cyclic additions.
- mime: refuse to add subparts to one of their own descendants.
  Reported-by: Alexey Melnichuk
  Fixes #1962
- mime: avoid resetting a part's encoder when part's contents change.
- mime: improve unbinding top multipart from easy handle.
  Also avoid dangling pointers in referencing parts.
Daniel Stenberg (8 Oct 2017)
- RELEASE-NOTES: synced with a4c1c75da30af1
- curlver.h: next expected release is 7.57.0
Patrick Monnerat (8 Oct 2017)
- mime: be tolerant about setting twice the same header list in a part.
- docs: clarify form/mime usage of non-regular data files.
Daniel Stenberg (8 Oct 2017)
- Revert "multi_done: wait for name resolve to finish if still ongoing"
  This reverts commit f3e03f6c0ac52a1bf396e03f7d7e9b5b3b7165fe.
  Caused memory leaks in the fuzzer, needs to be done differently.
  Disable test 1553 for now too, as it causes memory leaks without this
  commit!
- remove_handle: call multi_done() first, then clear dns cache pointer
  Closes #1960
- multi_done: wait for name resolve to finish if still ongoing
  ... as we must clean up memory.
- pingpong: return error when trying to send without connection
  When imap_done() got called before a connection is setup, it would try
  to "finish up" and dereffed a NULL pointer.
  Test case 1553 managed to reproduce. I had to actually use a host name
  to try to resolve to slow it down, as using the normal local server IP
  will make libcurl get a connection in the first curl_multi_perform()
  loop and then the bug doesn't trigger.
  Fixes #1953
  Assisted-by: Max Dymond
Dan Fandrich (6 Oct 2017)
- tests: added flaky keyword to tests 587 and 644
  These are around 5% flaky in my Linux x86 autobuilds.
Marcel Raad (6 Oct 2017)
- vtls: fix warnings with --disable-crypto-auth
  When CURL_DISABLE_CRYPTO_AUTH is defined, Curl_none_md5sum's parameters
  are not used.
Daniel Stenberg (6 Oct 2017)
- multi_cleanup: call DONE on handles that never got that
  ... fixes a memory leak with at least IMAP when remove_handle is never
  called and the transfer is abruptly just abandoned early.
  Test 1552 added to verify
  Detected by OSS-fuzz
  Assisted-by: Max Dymond
  Closes #1954
- [Benbuck Nason brought this change]
  strtoofft: Remove extraneous null check
  Fixes #1950: curlx_strtoofft() doesn't fully protect against null 'str'
  argument.
  Closes #1952
- openssl: fix build without HAVE_OPAQUE_EVP_PKEY
  Reported-by: Javier Sixto
  Fixes #1955
  Closes #1956
Viktor Szakats (6 Oct 2017)
- lib/config-win32.h: let SMB/SMBS be enabled with OpenSSL/NSS
  The source code is now prepared to handle the case when both
  Win32 Crypto and OpenSSL/NSS crypto backends are enabled
  at the same time, making it now possible to enable `USE_WIN32_CRYPTO`
  whenever the targeted Windows version supports it. Since this
  matches the minimum Windows version supported by curl
  (Windows 2000), enable it unconditionally for the Win32 platform.
  This in turn enables SMB (and SMBS) protocol support whenever
  Win32 Crypto is available, regardless of what other crypto backends
  are enabled.
  Ref: https://github.com/curl/curl/pull/1840#issuecomment-325682052
  Closes https://github.com/curl/curl/pull/1943
Daniel Stenberg (5 Oct 2017)
- build: fix --disable-crypto-auth
  Reported-by: Wyatt O'Day
  Fixes #1945
  Closes #1947
Jay Satiro (5 Oct 2017)
- [Nick Zitzmann brought this change]
  darwinssl: add support for TLSv1.3
  Closes https://github.com/curl/curl/pull/1794
Daniel Stenberg (4 Oct 2017)
- [Felix Kaiser brought this change]
  docs: fix typo in curl_mime_data_cb man page
  Closes #1946
Viktor Szakats (4 Oct 2017)
- lib/Makefile.m32: allow customizing dll suffixes
  - New `CURL_DLL_SUFFIX` envvar will add a suffix to the generated
    libcurl dll name. Useful to add `-x64` to 64-bit builds so that
    it can live in the same directory as the 32-bit one. By default
    this is empty.
  - New `CURL_DLL_A_SUFFIX` envvar to customize the suffix of the
    generated import library (implib) for libcurl .dll. It defaults
    to `dll`, and it's useful to modify that to `.dll` to have the
    standard naming scheme for mingw-built .dlls, i.e. `libcurl.dll.a`.
  Closes https://github.com/curl/curl/pull/1942
Daniel Stenberg (4 Oct 2017)
- [Max Dymond brought this change]
  fuzzer: move to using external curl-fuzzer
  Use the external curl-fuzzer repository for fuzzing.
  Closes #1923
- failf: skip the sprintf() if there are no consumers
  Closes #1936
- ftp: UBsan fixup 'pointer index expression overflowed'
  Closes #1939
- RELEASE-PROCEDURE: update the release schedule
Version 7.56.0 (4 Oct 2017)
Daniel Stenberg (4 Oct 2017)
- RELEASE-NOTES: curl 7.56.0
- THANKS: added new 7.56.0 contributors
Jay Satiro (4 Oct 2017)
- build-openssl.bat: Warn OpenSSL 1.1.0 not yet supported
  Ref: https://github.com/curl/curl/issues/1002
Michael Kaufmann (3 Oct 2017)
- idn: fix source code comment
- vtls: compare and clone ssl configs properly
  Compare these settings in Curl_ssl_config_matches():
  - verifystatus (CURLOPT_SSL_VERIFYSTATUS)
  - random_file (CURLOPT_RANDOM_FILE)
  - egdsocket (CURLOPT_EGDSOCKET)
  Also copy the setting "verifystatus" in Curl_clone_primary_ssl_config(),
  and copy the setting "sessionid" unconditionally.
  This means that reusing connections that are secured with a client
  certificate is now possible, and the statement "TLS session resumption
  is disabled when a client certificate is used" in the old advisory at
  https://curl.haxx.se/docs/adv_20170419.html is obsolete.
  Reviewed-by: Daniel Stenberg
  Closes #1917
- proxy: read the "no_proxy" variable only if necessary
  Reviewed-by: Daniel Stenberg
  Closes #1919
Patrick Monnerat (3 Oct 2017)
- libcurl-tutorial: add casts in example to avoid compilation warnings.
Daniel Stenberg (3 Oct 2017)
- examples: bring back curl_formadd-using examples
  ... now with a -formadd suffix. While the new mime API is introduced in
  7.56.0 we must acknowledge that lots of users can't upgrade their curl
  versions immediately.
- test1153: verify quoted double-qoutes in PWD response
- FTP: zero terminate the entry path even on bad input
  ... a single double quote could leave the entry path buffer without a zero
  terminating byte. CVE-2017-1000254
  Test 1152 added to verify.
  Reported-by: Max Dymond
  Bug: https://curl.haxx.se/docs/adv_20171004.html
Jay Satiro (2 Oct 2017)
- [Sergei Nikulov brought this change]
  cmake: disable tests and man generation if perl/nroff not found
  Fixes https://github.com/curl/curl/issues/1500
  Reported-by: Jay Satiro
  Fixes https://github.com/curl/curl/pull/1662
  Assisted-by: Tom Seddon
  Assisted-by: dpull@users.noreply.github.com
  Assisted-by: elelel@users.noreply.github.com
  Closes https://github.com/curl/curl/pull/1924
Patrick Monnerat (2 Oct 2017)
- libcurl-tutorial: fix two typos.
- TODO: remove deprecated form API items.
- libcurl-tutorial: describe MIME API and deprecate form API.
  Include a guide to form/mime API conversion.
Daniel Stenberg (30 Sep 2017)
- cookie: fix memory leak if path was set twice in header
  ... this will let the second occurance override the first.
  Added test 1161 to verify.
  Reported-by: Max Dymond
  Fixes #1932
  Closes #1933
Dan Fandrich (30 Sep 2017)
- test650: Use variable replacement to set the host address and port
  Otherwise, the test fails when the -b test option is used to set a
  different test port range.
- Set and use more necessary options when some protocols are disabled
  When curl and libcurl are built with some protocols disabled, they stop
  setting and receiving some options that don't make sense with those
  protocols.  In particular, when HTTP is disabled many options aren't set
  that are used only by HTTP.  However, some options that appear to be
  HTTP-only are actually used by other protocols as well (some despite
  having HTTP in the name) and should be set, but weren't. This change now
  causes some of these options to be set and used for more (or for all)
  protocols. In particular, this fixes tests 646 through 649 in an
  HTTP-disabled build, which use the MIME API in the mail protocols.
Daniel Stenberg (29 Sep 2017)
- test1160: verifies cookie leak for large cookies
  The fix done in 20ea22ff735
- cookie: fix memory leak on oversized rejection
  Regression brought by 2bc230de63b
  Detected by OSS-fuzz: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=3513
  Assisted-by: Max Dymond
  Closes #1930
- [Anders Bakken brought this change]
  connect: fix race condition with happy eyeballs timeout
  The timer should be started after conn->connecttime is set. Otherwise
  the timer could expire without this condition being true:
      /* should we try another protocol family? */
      if(i == 0 && conn->tempaddr[1] == NULL &&
        curlx_tvdiff(now, conn->connecttime) >= HAPPY_EYEBALLS_TIMEOUT) {
  Ref: #1928
Michael Kaufmann (28 Sep 2017)
- docs: link CURLOPT_CONNECTTIMEOUT and CURLOPT_CONNECTTIMEOUT_MS
  Closes #1922
- docs: clarify the use of environment variables for proxy
  Closes #1921
- http: add custom empty headers to repeated requests
  Closes #1920
- reuse_conn: don't copy flags that are known to be equal
  A connection can only be reused if the flags "conn_to_host" and
  "conn_to_port" match. Therefore it is not necessary to copy these flags
  in reuse_conn().
  Closes #1918
Daniel Stenberg (27 Sep 2017)
- curl.h: include <sys/select.h> on cygwin too
  When building with -std=c++14 on cygwin, this header won't be
  automatically included as it otherwise is.
  The <sys/select.h> include decision should ideally be reversed and be
  avoided where that header file doesn't exist.
  Reported-by: Ian Fette
  Fixes #1925
- RELEASE-NOTES: synced with d8ab5dc50
Michael Kaufmann (24 Sep 2017)
- tests: adjust .gitignore for new tests
Jay Satiro (23 Sep 2017)
- ntlm: move NTLM_NEEDS_NSS_INIT define into core NTLM header
  .. and include the core NTLM header in all NTLM-related source files.
  Follow up to 6f86022. Since then http_ntlm checks NTLM_NEEDS_NSS_INIT
  but did not include vtls.h where it was defined.
  Closes https://github.com/curl/curl/pull/1911
Daniel Stenberg (23 Sep 2017)
- file_range: avoid integer overflow when figuring out byte range
  When trying to bump the value with one and the value is already at max,
  it causes an integer overflow.
  Closes #1908
  Detected by oss-fuzz:
  https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=3465
  Assisted-by: Max Dymond
Michael Kaufmann (23 Sep 2017)
- tests: fix a compiler warning in test 643
Jay Satiro (23 Sep 2017)
- symbols-in-versions: fix CURLSSLSET_NO_BACKENDS entry
  - Use spaces instead of tabs as the delimiter.
  Follow up to 7c52b12 which added the entry. The entry had used tabs but
  the symbol-scan parser doesn't recognize tabs and would fail the symbol.
Viktor Szakats (22 Sep 2017)
- metalink: fix NSS issue in MultiSSL builds
  In MultiSSL mode (i.e. when more than one SSL backend is compiled
  in), we cannot use the compile time flag `USE_NSS` as indicator that
  the NSS backend is in use. As far as Metalink is concerned, the SSL
  backend is only used for MD5, SHA-1 and SHA-256 calculations,
  therefore one of the available SSL backends is selected at compile
  time, in a strict order of preference.
  Let's introduce a new `HAVE_NSS_CONTEXT` constant that can be used
  to determine whether the SSL backend used for Metalink is the NSS
  backend, and use that to guard the code that wants to de-initialize
  the NSS-specific data structure.
  Ref: https://github.com/curl/curl/pull/1848
- ntlm: use strict order for SSL backend #if branches
  With the recently introduced MultiSSL support multiple SSL backends
  can be compiled into cURL That means that now the order of the SSL
  One option would be to use the same SSL backend as was configured
  via `curl_global_sslset()`, however, NTLMv2 support would appear
  to be available only with some SSL backends. For example, when
  eb88d778e (ntlm: Use Windows Crypt API, 2014-12-02) introduced
  support for NTLMv1 using Windows' Crypt API, it specifically did
  *not* introduce NTLMv2 support using Crypt API at the same time.
  So let's select one specific SSL backend for NTLM support when
  compiled with multiple SSL backends, using a priority order such
  that we support NTLMv2 even if only one compiled-in SSL backend can
  be used for that.
  Ref: https://github.com/curl/curl/pull/1848
Daniel Stenberg (22 Sep 2017)
- symbols-in-versions: add CURLSSLSET_NO_BACKENDS
  ...fixup from b8e0fe19ec
- imap: quote atoms properly when escaping characters
  Updates test 800 to verify
  Fixes #1902
  Closes #1903
- tests: make the imap server not verify user+password
  ... as the test cases themselves do that and it makes it easier to add
  crazy test cases.
  Test 800 updated to use user name + password that need quoting.
  Test 856 updated to trigger an auth fail differently.
  Ref: #1902
- vtls: provide curl_global_sslset() even in non-SSL builds
  ... it just returns error:
  Bug: https://github.com/curl/curl/commit/1328f69d53f2f2e937696ea954c480412b018451#commitcomment-24470367
  Reported-by: Marcel Raad
  Closes #1906
Patrick Monnerat (22 Sep 2017)
- form/mime: field names are not allowed to contain zero-valued bytes.
  Also suppress length argument of curl_mime_name() (names are always
  zero-terminated).
Daniel Stenberg (21 Sep 2017)
- [Dirk Feytons brought this change]
  openssl: only verify RSA private key if supported
  In some cases the RSA key does not support verifying it because it's
  located on a smart card, an engine wants to hide it, ...
  Check the flags on the key before trying to verify it.
  OpenSSL does the same thing internally; see ssl/ssl_rsa.c
  Closes #1904
Marcel Raad (21 Sep 2017)
- examples/post-callback: use long for CURLOPT_POSTFIELDSIZE
  Otherwise, typecheck-gcc.h warns on MinGW-w64.
Patrick Monnerat (20 Sep 2017)
- mime: rephrase the multipart output state machine (#1898) ...
  ... in hope coverity will like it much.
- mime: fix an explicit null dereference (#1899)
Daniel Stenberg (20 Sep 2017)
- curl: check fseek() return code and bail on error
  Detected by coverity. CID 1418137.
- smtp: fix memory leak in OOM
  Regression since ce0881edee
  Coverity CID 1418139 and CID 1418136 found it, but it was also seen in
  torture testing.
- RELEASE-NOTES: synced with 5fe85587c
- [Pavel Pavlov brought this change]
  cookies: use lock when using CURLINFO_COOKIELIST
  Closes #1896
- [Max Dymond brought this change]
  ossfuzz: changes before merging the generated corpora
  Before merging in the oss-fuzz corpora from Google, there are some changes
  to the fuzzer.
  - Add a read corpus script, to display corpus files nicely.
  - Change the behaviour of the fuzzer so that TLV parse failures all now
    go down the same execution paths, which should reduce the size of the
    corpora.
  - Make unknown TLVs a failure to parse, which should decrease the size
    of the corpora as well.
  Closes #1881
                                  _   _ ____  _
                              ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
 1. Philosophy
  1.1 What is cURL?
  1.2 What is libcurl?
  1.3 What is curl not?
  1.4 When will you make curl do XXXX ?
  1.5 Who makes curl?
  1.6 What do you get for making curl?
  1.7 What about CURL from curl.com?
  1.8 I have a problem who do I mail?
  1.9 Where do I buy commercial support for curl?
  1.10 How many are using curl?
  1.11 Why don't you update ca-bundle.crt
  1.12 I have a problem who can I chat with?
  1.13 curl's ECCN number?
  1.14 How do I submit my patch?
  1.15 How do I port libcurl to my OS?
 2. Install Related Problems
  2.1 configure doesn't find OpenSSL even when it is installed
   2.1.1 native linker doesn't find OpenSSL
   2.1.2 only the libssl lib is missing
  2.2 Does curl work/build with other SSL libraries?
  2.3 Where can I find a copy of LIBEAY32.DLL?
  2.4 Does curl support SOCKS (RFC 1928) ?
 3. Usage Problems
  3.1 curl: (1) SSL is disabled, https: not supported
  3.2 How do I tell curl to resume a transfer?
  3.3 Why doesn't my posting using -F work?
  3.4 How do I tell curl to run custom FTP commands?
  3.5 How can I disable the Accept: */* header?
  3.6 Does curl support ASP, XML, XHTML or HTML version Y?
  3.7 Can I use curl to delete/rename a file through FTP?
  3.8 How do I tell curl to follow HTTP redirects?
  3.9 How do I use curl in my favorite programming language?
  3.10 What about SOAP, WebDAV, XML-RPC or similar protocols over HTTP?
  3.11 How do I POST with a different Content-Type?
  3.12 Why do FTP specific features over HTTP proxy fail?
  3.13 Why does my single/double quotes fail?
  3.14 Does curl support Javascript or PAC (automated proxy config)?
  3.15 Can I do recursive fetches with curl?
  3.16 What certificates do I need when I use SSL?
  3.17 How do I list the root dir of an FTP server?
  3.18 Can I use curl to send a POST/PUT and not wait for a response?
  3.19 How do I get HTTP from a host using a specific IP address?
  3.20 How to SFTP from my user's home directory?
  3.21 Protocol xxx not supported or disabled in libcurl
  3.22 curl -X gives me HTTP problems
 4. Running Problems
  4.1 Problems connecting to SSL servers.
  4.2 Why do I get problems when I use & or % in the URL?
  4.3 How can I use {, }, [ or ] to specify multiple URLs?
  4.4 Why do I get downloaded data even though the web page doesn't exist?
  4.5 Why do I get return code XXX from a HTTP server?
   4.5.1 "400 Bad Request"
   4.5.2 "401 Unauthorized"
   4.5.3 "403 Forbidden"
   4.5.4 "404 Not Found"
   4.5.5 "405 Method Not Allowed"
   4.5.6 "301 Moved Permanently"
  4.6 Can you tell me what error code 142 means?
  4.7 How do I keep user names and passwords secret in Curl command lines?
  4.8 I found a bug!
  4.9 Curl can't authenticate to the server that requires NTLM?
  4.10 My HTTP request using HEAD, PUT or DELETE doesn't work!
  4.11 Why does my HTTP range requests return the full document?
  4.12 Why do I get "certificate verify failed" ?
  4.13 Why is curl -R on Windows one hour off?
  4.14 Redirects work in browser but not with curl!
  4.15 FTPS doesn't work
  4.16 My HTTP POST or PUT requests are slow!
  4.17 Non-functional connect timeouts on Windows
  4.18 file:// URLs containing drive letters (Windows, NetWare)
  4.19 Why doesn't curl return an error when the network cable is unplugged?
  4.20 curl doesn't return error for HTTP non-200 responses!
  4.21 Why is there a HTTP/1.1 in my HTTP/2 request?
 5. libcurl Issues
  5.1 Is libcurl thread-safe?
  5.2 How can I receive all data into a large memory chunk?
  5.3 How do I fetch multiple files with libcurl?
  5.4 Does libcurl do Winsock initing on win32 systems?
  5.5 Does CURLOPT_WRITEDATA and CURLOPT_READDATA work on win32 ?
  5.6 What about Keep-Alive or persistent connections?
  5.7 Link errors when building libcurl on Windows!
  5.8 libcurl.so.X: open failed: No such file or directory
  5.9 How does libcurl resolve host names?
  5.10 How do I prevent libcurl from writing the response to stdout?
  5.11 How do I make libcurl not receive the whole HTTP response?
  5.12 Can I make libcurl fake or hide my real IP address?
  5.13 How do I stop an ongoing transfer?
  5.14 Using C++ non-static functions for callbacks?
  5.15 How do I get an FTP directory listing?
  5.16 I want a different time-out!
  5.17 Can I write a server with libcurl?
  5.18 Does libcurl use threads?
 6. License Issues
  6.1 I have a GPL program, can I use the libcurl library?
  6.2 I have a closed-source program, can I use the libcurl library?
  6.3 I have a BSD licensed program, can I use the libcurl library?
  6.4 I have a program that uses LGPL libraries, can I use libcurl?
  6.5 Can I modify curl/libcurl for my program and keep the changes secret?
  6.6 Can you please change the curl/libcurl license to XXXX?
  6.7 What are my obligations when using libcurl in my commercial apps?
 7. PHP/CURL Issues
  7.1 What is PHP/CURL?
  7.2 Who wrote PHP/CURL?
  7.3 Can I perform multiple requests using the same handle?
  7.4 Does PHP/CURL have dependencies?
==============================================================================
1. Philosophy
  1.1 What is cURL?
  cURL is the name of the project. The name is a play on 'Client for URLs',
  originally with URL spelled in uppercase to make it obvious it deals with
  URLs. The fact it can also be pronounced 'see URL' also helped, it works as
  an abbreviation for "Client URL Request Library" or why not the recursive
  version: "Curl URL Request Library".
  The cURL project produces two products:
  libcurl
    A free and easy-to-use client-side URL transfer library, supporting DICT,
    FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3,
    POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET and TFTP.
    libcurl supports HTTPS certificates, HTTP POST, HTTP PUT, FTP uploading,
    Kerberos, SPNEGO, HTTP form based upload, proxies, cookies, user+password
    authentication, file transfer resume, http proxy tunneling and more!
    libcurl is highly portable, it builds and works identically on numerous
    platforms, including Solaris, NetBSD, FreeBSD, OpenBSD, Darwin, HP-UX,
    IRIX, AIX, Tru64, Linux, UnixWare, HURD, Windows, Amiga, OS/2, BeOS, Mac
    OS X, Ultrix, QNX, OpenVMS, RISC OS, Novell NetWare, DOS, Symbian, OSF,
    Android, Minix, IBM TPF and more...
    libcurl is free, thread-safe, IPv6 compatible, feature rich, well
    supported and fast.
  curl
    A command line tool for getting or sending files using URL syntax.
    Since curl uses libcurl, curl supports the same wide range of common
    Internet protocols that libcurl does.
  We pronounce curl with an initial k sound. It rhymes with words like girl
  and earl. This is a short WAV file to help you:
     https://media.merriam-webster.com/soundc11/c/curl0001.wav
  There are numerous sub-projects and related projects that also use the word
  curl in the project names in various combinations, but you should take
  notice that this FAQ is directed at the command-line tool named curl (and
  libcurl the library), and may therefore not be valid for other curl-related
  projects. (There is however a small section for the PHP/CURL in this FAQ.)
  1.2 What is libcurl?
  libcurl is a reliable and portable library which provides you with an easy
  interface to a range of common Internet protocols.
  You can use libcurl for free in your application, be it open source,
  commercial or closed-source.
  libcurl is most probably the most portable, most powerful and most often
  used C-based multi-platform file transfer library on this planet - be it
  open source or commercial.
  1.3 What is curl not?
  Curl is not a wget clone. That is a common misconception.  Never, during
  curl's development, have we intended curl to replace wget or compete on its
  market. Curl is targeted at single-shot file transfers.
  Curl is not a web site mirroring program. If you want to use curl to mirror
  something: fine, go ahead and write a script that wraps around curl to make
  it reality (like curlmirror.pl does).
  Curl is not an FTP site mirroring program. Sure, get and send FTP with curl
  but if you want systematic and sequential behavior you should write a
  script (or write a new program that interfaces libcurl) and do it.
  Curl is not a PHP tool, even though it works perfectly well when used from
  or with PHP (when using the PHP/CURL module).
  Curl is not a program for a single operating system. Curl exists, compiles,
  builds and runs under a wide range of operating systems, including all
  modern Unixes (and a bunch of older ones too), Windows, Amiga, BeOS, OS/2,
  OS X, QNX etc.
  1.4 When will you make curl do XXXX ?
  We love suggestions of what to change in order to make curl and libcurl
  better. We do however believe in a few rules when it comes to the future of
  curl:
  Curl -- the command line tool -- is to remain a non-graphical command line
  tool. If you want GUIs or fancy scripting capabilities, you should look for
  another tool that uses libcurl.
  We do not add things to curl that other small and available tools already do
  very well at the side. Curl's output can be piped into another program or
  redirected to another file for the next program to interpret.
  We focus on protocol related issues and improvements. If you want to do more
  magic with the supported protocols than curl currently does, chances are good
  we will agree. If you want to add more protocols, we may very well agree.
  If you want someone else to do all the work while you wait for us to
  implement it for you, that is not a very friendly attitude. We spend a
  considerable time already on maintaining and developing curl. In order to
  get more out of us, you should consider trading in some of your time and
  effort in return. Simply go to the GitHub repo which resides at
  https://github.com/curl/curl, fork the project, and create pull requests
  with your proposed changes.
  If you write the code, chances are better that it will get into curl faster.
  1.5 Who makes curl?
  curl and libcurl are not made by any single individual. Daniel Stenberg is
  project leader and main developer, but other persons' submissions are
  important and crucial. Anyone can contribute and post their changes and
  improvements and have them inserted in the main sources (of course on the
  condition that developers agree that the fixes are good).
  The full list of all contributors is found in the docs/THANKS file.
  curl is developed by a community, with Daniel at the wheel.
  1.6 What do you get for making curl?
  Project cURL is entirely free and open. No person gets paid for developing
  curl full time. We do this voluntarily, mostly in our spare time.
  Occasionally companies pay individual developers to work on curl, but that's
  up to each company and developer. This is not controlled by nor supervised in
  any way by the project.
  We still get help from companies. Haxx provides web site, bandwidth, mailing
  lists etc, sourceforge.net hosts project services we take advantage from,
  like the bug tracker, and GitHub hosts the primary git repository at
  https://github.com/curl/curl. Also again, some companies have sponsored
  certain parts of the development in the past and I hope some will continue to
  do so in the future.
  If you want to support our project, consider a donation or a banner-program
  or even better: by helping us with coding, documenting or testing etc.
  1.7 What about CURL from curl.com?
  During the summer of 2001, curl.com was busy advertising their client-side
  programming language for the web, named CURL.
  We are in no way associated with curl.com or their CURL programming
  language.
  Our project name curl has been in effective use since 1998. We were not the
  first computer related project to use the name "curl" and do not claim any
  rights to the name.
  We recognize that we will be living in parallel with curl.com and wish them
  every success.
  1.8 I have a problem whom do I mail?
  Please do not mail any single individual unless you really need to. Keep
  curl-related questions on a suitable mailing list. All available mailing
  lists are listed in the MANUAL document and online at
  https://curl.haxx.se/mail/
  Keeping curl-related questions and discussions on mailing lists allows
  others to join in and help, to share their ideas, to contribute their
  suggestions and to spread their wisdom. Keeping discussions on public mailing
  lists also allows for others to learn from this (both current and future
  users thanks to the web based archives of the mailing lists), thus saving us
  from having to repeat ourselves even more. Thanks for respecting this.
  If you have found or simply suspect a security problem in curl or libcurl,
  mail curl-security at haxx.se (closed list of receivers, mails are not
  disclosed) and tell. Then we can produce a fix in a timely manner before the
  flaw is announced to the world, thus lessen the impact the problem will have
  on existing users.
  1.9 Where do I buy commercial support for curl?
  curl is fully open source. It means you can hire any skilled engineer to fix
  your curl-related problems.
  We list available alternatives on the curl web site:
  https://curl.haxx.se/support.html
  1.10 How many are using curl?
  It is impossible to tell.
  We don't know how many users that knowingly have installed and use curl.
  We don't know how many users that use curl without knowing that they are in
  fact using it.
  We don't know how many users that downloaded or installed curl and then
  never use it.
  In May 2012 Daniel did a counting game and came up with a number that may
  be completely wrong or somewhat accurate. Over 500 million!
  See https://daniel.haxx.se/blog/2012/05/16/300m-users/
  1.11 Why don't you update ca-bundle.crt
  The ca cert bundle that used to be shipped with curl was very outdated and
  must be replaced with an up-to-date version by anyone who wants to verify
  peers. It is no longer provided by curl. The last curl release that ever
  shipped a ca cert bundle was curl 7.18.0.
  In the cURL project we've decided not to attempt to keep this file updated
  (or even present anymore) since deciding what to add to a ca cert bundle is
  an undertaking we've not been ready to accept, and the one we can get from
  Mozilla is perfectly fine so there's no need to duplicate that work.
  Today, with many services performed over HTTPS, every operating system
  should come with a default ca cert bundle that can be deemed somewhat
  trustworthy and that collection (if reasonably updated) should be deemed to
  be a lot better than a private curl version.
  If you want the most recent collection of ca certs that Mozilla Firefox
  uses, we recommend that you extract the collection yourself from Mozilla
  Firefox (by running 'make ca-bundle), or by using our online service setup
  for this purpose: https://curl.haxx.se/docs/caextract.html
  1.12 I have a problem who can I chat with?
  There's a bunch of friendly people hanging out in the #curl channel on the
  IRC network irc.freenode.net. If you're polite and nice, chances are good
  that you can get -- or provide -- help instantly.
  1.13 curl's ECCN number?
  The US government restricts exports of software that contains or uses
  cryptography. When doing so, the Export Control Classification Number (ECCN)
  is used to identify the level of export control etc.
  Apache Software Foundation gives a good explanation of ECCNs at
  https://www.apache.org/dev/crypto.html
  We believe curl's number might be ECCN 5D002, another possibility is
  5D992. It seems necessary to write them (the authority that administers ECCN
  numbers), asking to confirm.
  Comprehensible explanations of the meaning of such numbers and how to obtain
  them (resp.) are here
  https://www.bis.doc.gov/licensing/exportingbasics.htm
  https://www.bis.doc.gov/licensing/do_i_needaneccn.html
  An incomprehensible description of the two numbers above is here
  http://www.access.gpo.gov/bis/ear/pdf/ccl5-pt2.pdf
  1.14 How do I submit my patch?
  When you have made a patch or a change of whatever sort, and want to submit
  that to the project, there are a few different ways we prefer:
  o send a patch to the curl-library mailing list. We're many subscribers
    there and there are lots of people who can review patches, comment on them
    and "receive" them properly.
  o if your patch changes or fixes a bug, you can also opt to submit a bug
    report in the bug tracker and attach your patch there. There are less
    people involved there.
  Lots of more details are found in the CONTRIBUTE and INTERNALS docs.
  1.15 How do I port libcurl to my OS?
  Here's a rough step-by-step:
  1. copy a suitable lib/config-*.h file as a start to lib/config-[youros].h
  2. edit lib/config-[youros].h to match your OS and setup
  3. edit lib/curl_setup.h to include config-[youros].h when your OS is
     detected by the preprocessor, in the style others already exist
  4. compile lib/*.c and make them into a library
2. Install Related Problems
  2.1 configure doesn't find OpenSSL even when it is installed
  This may be because of several reasons.
    2.1.1 native linker doesn't find openssl
    Affected platforms:
      Solaris (native cc compiler)
      HPUX (native cc compiler)
      SGI IRIX (native cc compiler)
      SCO UNIX (native cc compiler)
    When configuring curl, I specify --with-ssl. OpenSSL is installed in
    /usr/local/ssl Configure reports SSL in /usr/local/ssl, but fails to find
    CRYPTO_lock in -lcrypto
    Cause: The cc for this test places the -L/usr/local/ssl/lib AFTER
    -lcrypto, so ld can't find the library. This is due to a bug in the GNU
    autoconf tool.
    Workaround: Specifying "LDFLAGS=-L/usr/local/ssl/lib" in front of
    ./configure places the -L/usr/local/ssl/lib early enough in the command
    line to make things work
    2.1.2 only the libssl lib is missing
    If all include files and the libcrypto lib is present, with only the
    libssl being missing according to configure, this is most likely because
    a few functions are left out from the libssl.
    If the function names missing include RSA or RSAREF you can be certain
    that this is because libssl requires the RSA and RSAREF libs to build.
    See the INSTALL file section that explains how to add those libs to
    configure. Make sure that you remove the config.cache file before you
    rerun configure with the new flags.
  2.2 Does curl work/build with other SSL libraries?
  Curl has been written to use a generic SSL function layer internally, and
  that SSL functionality can then be provided by one out of many different SSL
  backends.
  curl can be built to use one of the following SSL alternatives: OpenSSL,
  GnuTLS, yassl, NSS, PolarSSL, axTLS, Secure Transport (native iOS/OS X),
  WinSSL (native Windows) or GSKit (native IBM i). They all have their pros
  and cons, and we try to maintain a comparison of them here:
  https://curl.haxx.se/docs/ssl-compared.html
  2.3 Where can I find a copy of LIBEAY32.DLL?
  That is an OpenSSL binary built for Windows.
  Curl can be built with OpenSSL to do the SSL stuff. The LIBEAY32.DLL is then
  what curl needs on a windows machine to do https:// etc. Check out the curl
  web site to find accurate and up-to-date pointers to recent OpenSSL DLLs and
  other binary packages.
  2.4 Does curl support SOCKS (RFC 1928) ?
  Yes, SOCKS 4 and 5 are supported.
3. Usage problems
  3.1 curl: (1) SSL is disabled, https: not supported
  If you get this output when trying to get anything from a https:// server,
  it means that the instance of curl/libcurl that you're using was built
  without support for this protocol.
  This could've happened if the configure script that was run at build time
  couldn't find all libs and include files curl requires for SSL to work. If
  the configure script fails to find them, curl is simply built without SSL
  support.
  To get the https:// support into a curl that was previously built but that
  reports that https:// is not supported, you should dig through the document
  and logs and check out why the configure script doesn't find the SSL libs
  and/or include files.
  Also, check out the other paragraph in this FAQ labelled "configure doesn't
  find OpenSSL even when it is installed".
  3.2 How do I tell curl to resume a transfer?
  Curl supports resumed transfers both ways on both FTP and HTTP.
  Try the -C option.
  3.3 Why doesn't my posting using -F work?
  You can't arbitrarily use -F or -d, the choice between -F or -d depends on the
  HTTP operation you need curl to do and what the web server that will receive
  your post expects.
  If the form you're trying to submit uses the type 'multipart/form-data', then
  and only then you must use the -F type. In all the most common cases, you
  should use -d which then causes a posting with the type
  'application/x-www-form-urlencoded'.
  This is described in some detail in the MANUAL and TheArtOfHttpScripting
  documents, and if you don't understand it the first time, read it again
  before you post questions about this to the mailing list. Also, try reading
  through the mailing list archives for old postings and questions regarding
  this.
  3.4 How do I tell curl to run custom FTP commands?
  You can tell curl to perform optional commands both before and/or after a
  file transfer. Study the -Q/--quote option.
  Since curl is used for file transfers, you don't normally use curl to
  perform FTP commands without transferring anything. Therefore you must
  always specify a URL to transfer to/from even when doing custom FTP
  commands, or use -I which implies the "no body" option sent to libcurl.
  3.5 How can I disable the Accept: */* header?
  You can change all internally generated headers by adding a replacement with
  the -H/--header option. By adding a header with empty contents you safely
  disable that one. Use -H "Accept:" to disable that specific header.
  3.6 Does curl support ASP, XML, XHTML or HTML version Y?
  To curl, all contents are alike. It doesn't matter how the page was
  generated. It may be ASP, PHP, Perl, shell-script, SSI or plain HTML
  files. There's no difference to curl and it doesn't even know what kind of
  language that generated the page.
  See also item 3.14 regarding javascript.
  3.7 Can I use curl to delete/rename a file through FTP?
  Yes. You specify custom FTP commands with -Q/--quote.
  One example would be to delete a file after you have downloaded it:
     curl -O ftp://download.com/coolfile -Q '-DELE coolfile'
  or rename a file after upload:
     curl -T infile ftp://upload.com/dir/ -Q "-RNFR infile" -Q "-RNTO newname"
  3.8 How do I tell curl to follow HTTP redirects?
  Curl does not follow so-called redirects by default. The Location: header
  that informs the client about this is only interpreted if you're using the
  -L/--location option. As in:
     curl -L http://redirector.com
  Not all redirects are HTTP ones, see 4.14
  3.9 How do I use curl in my favorite programming language?
  There exist many language interfaces/bindings for curl that integrates it
  better with various languages. If you are fluid in a script language, you
  may very well opt to use such an interface instead of using the command line
  tool.
  Find out more about which languages that support curl directly, and how to
  install and use them, in the libcurl section of the curl web site:
  https://curl.haxx.se/libcurl/
  All the various bindings to libcurl are made by other projects and people,
  outside of the cURL project. The cURL project itself only produces libcurl
  with its plain C API. If you don't find anywhere else to ask you can ask
  about bindings on the curl-library list too, but be prepared that people on
  that list may not know anything about bindings.
  In October 2009, there were interfaces available for the following
  languages: Ada95, Basic, C, C++, Ch, Cocoa, D, Dylan, Eiffel, Euphoria,
  Ferite, Gambas, glib/GTK+, Haskell, ILE/RPG, Java, Lisp, Lua, Mono, .NET,
  Object-Pascal, OCaml, Pascal, Perl, PHP, PostgreSQL, Python, R, Rexx, Ruby,
  Scheme, S-Lang, Smalltalk, SP-Forth, SPL, Tcl, Visual Basic, Visual FoxPro,
  Q, wxwidgets and XBLite. By the time you read this, additional ones may have
  appeared!
  3.10 What about SOAP, WebDAV, XML-RPC or similar protocols over HTTP?
  Curl adheres to the HTTP spec, which basically means you can play with *any*
  protocol that is built on top of HTTP. Protocols such as SOAP, WEBDAV and
  XML-RPC are all such ones. You can use -X to set custom requests and -H to
  set custom headers (or replace internally generated ones).
  Using libcurl is of course just as good and you'd just use the proper
  library options to do the same.
  3.11 How do I POST with a different Content-Type?
  You can always replace the internally generated headers with -H/--header.
  To make a simple HTTP POST with text/xml as content-type, do something like:
        curl -d "datatopost" -H "Content-Type: text/xml" [URL]
  3.12 Why do FTP specific features over HTTP proxy fail?
  Because when you use a HTTP proxy, the protocol spoken on the network will
  be HTTP, even if you specify a FTP URL. This effectively means that you
  normally can't use FTP specific features such as FTP upload and FTP quote
  etc.
  There is one exception to this rule, and that is if you can "tunnel through"
  the given HTTP proxy. Proxy tunneling is enabled with a special option (-p)
  and is generally not available as proxy admins usually disable tunneling to
  ports other than 443 (which is used for HTTPS access through proxies).
  3.13 Why does my single/double quotes fail?
  To specify a command line option that includes spaces, you might need to
  put the entire option within quotes. Like in:
   curl -d " with spaces " url.com
  or perhaps
   curl -d ' with spaces ' url.com
  Exactly what kind of quotes and how to do this is entirely up to the shell
  or command line interpreter that you are using. For most unix shells, you
  can more or less pick either single (') or double (") quotes. For
  Windows/DOS prompts I believe you're forced to use double (") quotes.
  Please study the documentation for your particular environment. Examples in
  the curl docs will use a mix of both of these as shown above. You must
  adjust them to work in your environment.
  Remember that curl works and runs on more operating systems than most single
  individuals have ever tried.
  3.14 Does curl support Javascript or PAC (automated proxy config)?
  Many web pages do magic stuff using embedded Javascript. Curl and libcurl
  have no built-in support for that, so it will be treated just like any other
  contents.
  .pac files are a netscape invention and are sometimes used by organizations
  to allow them to differentiate which proxies to use. The .pac contents is
  just a Javascript program that gets invoked by the browser and that returns
  the name of the proxy to connect to. Since curl doesn't support Javascript,
  it can't support .pac proxy configuration either.
  Some workarounds usually suggested to overcome this Javascript dependency:
  Depending on the Javascript complexity, write up a script that translates it
  to another language and execute that.
  Read the Javascript code and rewrite the same logic in another language.
  Implement a Javascript interpreter, people have successfully used the
  Mozilla Javascript engine in the past.
  Ask your admins to stop this, for a static proxy setup or similar.
  3.15 Can I do recursive fetches with curl?
  No. curl itself has no code that performs recursive operations, such as
  those performed by wget and similar tools.
  There exists wrapper scripts with that functionality (for example the
  curlmirror perl script), and you can write programs based on libcurl to do
  it, but the command line tool curl itself cannot.
  3.16 What certificates do I need when I use SSL?
  There are three different kinds of "certificates" to keep track of when we
  talk about using SSL-based protocols (HTTPS or FTPS) using curl or libcurl.
  CLIENT CERTIFICATE
  The server you communicate with may require that you can provide this in
  order to prove that you actually are who you claim to be.  If the server
  doesn't require this, you don't need a client certificate.
  A client certificate is always used together with a private key, and the
  private key has a pass phrase that protects it.
  SERVER CERTIFICATE
  The server you communicate with has a server certificate. You can and should
  verify this certificate to make sure that you are truly talking to the real
  server and not a server impersonating it.
  CERTIFICATE AUTHORITY CERTIFICATE ("CA cert")
  You often have several CA certs in a CA cert bundle that can be used to
  verify a server certificate that was signed by one of the authorities in the
  bundle. curl does not come with a CA cert bundle but most curl installs
  provide one. You can also override the default.
  The server certificate verification process is made by using a Certificate
  Authority certificate ("CA cert") that was used to sign the server
  certificate. Server certificate verification is enabled by default in curl
  and libcurl and is often the reason for problems as explained in FAQ entry
  4.12 and the SSLCERTS document
  (https://curl.haxx.se/docs/sslcerts.html). Server certificates that are
  "self-signed" or otherwise signed by a CA that you do not have a CA cert
  for, cannot be verified. If the verification during a connect fails, you are
  refused access. You then need to explicitly disable the verification to
  connect to the server.
  3.17 How do I list the root dir of an FTP server?
  There are two ways. The way defined in the RFC is to use an encoded slash
  in the first path part. List the "/tmp" dir like this:
     curl ftp://ftp.sunet.se/%2ftmp/
  or the not-quite-kosher-but-more-readable way, by simply starting the path
  section of the URL with a slash:
     curl ftp://ftp.sunet.se//tmp/
  3.18 Can I use curl to send a POST/PUT and not wait for a response?
  No.
  But you could easily write your own program using libcurl to do such stunts.
  3.19 How do I get HTTP from a host using a specific IP address?
  For example, you may be trying out a web site installation that isn't yet in
  the DNS. Or you have a site using multiple IP addresses for a given host
  name and you want to address a specific one out of the set.
  Set a custom Host: header that identifies the server name you want to reach
  but use the target IP address in the URL:
    curl --header "Host: www.example.com" http://127.0.0.1/
  You can also opt to add faked host name entries to curl with the --resolve
  option. That has the added benefit that things like redirects will also work
  properly. The above operation would instead be done as:
    curl --resolve www.example.com:80:127.0.0.1 http://www.example.com/
  3.20 How to SFTP from my user's home directory?
  Contrary to how FTP works, SFTP and SCP URLs specify the exact directory to
  work with. It means that if you don't specify that you want the user's home
  directory, you get the actual root directory.
  To specify a file in your user's home directory, you need to use the correct
  URL syntax which for sftp might look similar to:
    curl -O -u user:password sftp://example.com/~/file.txt
  and for SCP it is just a different protocol prefix:
    curl -O -u user:password scp://example.com/~/file.txt
  3.21 Protocol xxx not supported or disabled in libcurl
  When passing on a URL to curl to use, it may respond that the particular
  protocol is not supported or disabled. The particular way this error message
  is phrased is because curl doesn't make a distinction internally of whether
  a particular protocol is not supported (i.e. never got any code added that
  knows how to speak that protocol) or if it was explicitly disabled. curl can
  be built to only support a given set of protocols, and the rest would then
  be disabled or not supported.
  Note that this error will also occur if you pass a wrongly spelled protocol
  part as in "htpt://example.com" or as in the less evident case if you prefix
  the protocol part with a space as in " http://example.com/".
  3.22 curl -X gives me HTTP problems
  In normal circumstances, -X should hardly ever be used.
  By default you use curl without explicitly saying which request method to
  use when the URL identifies a HTTP transfer. If you just pass in a URL like
  "curl http://example.com" it will use GET. If you use -d or -F curl will use
  POST, -I will cause a HEAD and -T will make it a PUT.
  If for whatever reason you're not happy with these default choices that curl
  does for you, you can override those request methods by specifying -X
  [WHATEVER]. This way you can for example send a DELETE by doing "curl -X
  DELETE [URL]".
  It is thus pointless to do "curl -XGET [URL]" as GET would be used
  anyway. In the same vein it is pointless to do "curl -X POST -d data
  [URL]"... But you can make a fun and somewhat rare request that sends a
  request-body in a GET request with something like "curl -X GET -d data
  [URL]"
  Note that -X doesn't actually change curl's behavior as it only modifies the
  actual string sent in the request, but that may of course trigger a
  different set of events.
  Accordingly, by using -XPOST on a command line that for example would follow
  a 303 redirect, you will effectively prevent curl from behaving
  correctly. Be aware.
4. Running Problems
  4.1 Problems connecting to SSL servers.
  It took a very long time before we could sort out why curl had problems to
  connect to certain SSL servers when using SSLeay or OpenSSL v0.9+.  The
  error sometimes showed up similar to:
  16570:error:1407D071:SSL routines:SSL2_READ:bad mac decode:s2_pkt.c:233:
  It turned out to be because many older SSL servers don't deal with SSLv3
  requests properly. To correct this problem, tell curl to select SSLv2 from
  the command line (-2/--sslv2).
  There have also been examples where the remote server didn't like the SSLv2
  request and instead you had to force curl to use SSLv3 with -3/--sslv3.
  4.2 Why do I get problems when I use & or % in the URL?
  In general unix shells, the & symbol is treated specially and when used, it
  runs the specified command in the background. To safely send the & as a part
  of a URL, you should quote the entire URL by using single (') or double (")
  quotes around it. Similar problems can also occur on some shells with other
  characters, including ?*!$~(){}<>\|;`.  When in doubt, quote the URL.
  An example that would invoke a remote CGI that uses &-symbols could be:
     curl 'http://www.altavista.com/cgi-bin/query?text=yes&q=curl'
  In Windows, the standard DOS shell treats the percent sign specially and you
  need to use TWO percent signs for each single one you want to use in the
  URL.
  If you want a literal percent sign to be part of the data you pass in a POST
  using -d/--data you must encode it as '%25' (which then also needs the
  percent sign doubled on Windows machines).
  4.3 How can I use {, }, [ or ] to specify multiple URLs?
  Because those letters have a special meaning to the shell, to be used in
  a URL specified to curl you must quote them.
  An example that downloads two URLs (sequentially) would be:
    curl '{curl,www}.haxx.se'
  To be able to use those characters as actual parts of the URL (without using
  them for the curl URL "globbing" system), use the -g/--globoff option:
    curl -g 'www.site.com/weirdname[].html'
  4.4 Why do I get downloaded data even though the web page doesn't exist?
  Curl asks remote servers for the page you specify. If the page doesn't exist
  at the server, the HTTP protocol defines how the server should respond and
  that means that headers and a "page" will be returned. That's simply how
  HTTP works.
  By using the --fail option you can tell curl explicitly to not get any data
  if the HTTP return code doesn't say success.
  4.5 Why do I get return code XXX from a HTTP server?
  RFC2616 clearly explains the return codes. This is a short transcript. Go
  read the RFC for exact details:
    4.5.1 "400 Bad Request"
    The request could not be understood by the server due to malformed
    syntax. The client SHOULD NOT repeat the request without modifications.
    4.5.2 "401 Unauthorized"
    The request requires user authentication.
    4.5.3 "403 Forbidden"
    The server understood the request, but is refusing to fulfil it.
    Authorization will not help and the request SHOULD NOT be repeated.
    4.5.4 "404 Not Found"
    The server has not found anything matching the Request-URI. No indication
    is given of whether the condition is temporary or permanent.
    4.5.5 "405 Method Not Allowed"
    The method specified in the Request-Line is not allowed for the resource
    identified by the Request-URI. The response MUST include an Allow header
    containing a list of valid methods for the requested resource.
    4.5.6 "301 Moved Permanently"
    If you get this return code and an HTML output similar to this:
       <H1>Moved Permanently</H1> The document has moved <A
       HREF="http://same_url_now_with_a_trailing_slash/">here</A>.
    it might be because you request a directory URL but without the trailing
    slash. Try the same operation again _with_ the trailing URL, or use the
    -L/--location option to follow the redirection.
  4.6 Can you tell me what error code 142 means?
  All curl error codes are described at the end of the man page, in the
  section called "EXIT CODES".
  Error codes that are larger than the highest documented error code means
  that curl has exited due to a crash. This is a serious error, and we
  appreciate a detailed bug report from you that describes how we could go
  ahead and repeat this!
  4.7 How do I keep user names and passwords secret in Curl command lines?
  This problem has two sides:
  The first part is to avoid having clear-text passwords in the command line
  so that they don't appear in 'ps' outputs and similar. That is easily
  avoided by using the "-K" option to tell curl to read parameters from a file
  or stdin to which you can pass the secret info. curl itself will also
  attempt to "hide" the given password by blanking out the option - this
  doesn't work on all platforms.
  To keep the passwords in your account secret from the rest of the world is
  not a task that curl addresses. You could of course encrypt them somehow to
  at least hide them from being read by human eyes, but that is not what
  anyone would call security.
  Also note that regular HTTP (using Basic authentication) and FTP passwords
  are sent in clear across the network. All it takes for anyone to fetch them
  is to listen on the network.  Eavesdropping is very easy. Use more secure
  authentication methods (like Digest, Negotiate or even NTLM) or consider the
  SSL-based alternatives HTTPS and FTPS.
  4.8 I found a bug!
  It is not a bug if the behavior is documented. Read the docs first.
  Especially check out the KNOWN_BUGS file, it may be a documented bug!
  If it is a problem with a binary you've downloaded or a package for your
  particular platform, try contacting the person who built the package/archive
  you have.
  If there is a bug, read the BUGS document first. Then report it as described
  in there.
  4.9 Curl can't authenticate to the server that requires NTLM?
  NTLM support requires OpenSSL, GnuTLS, mbedTLS, NSS, Secure Transport, or
  Microsoft Windows libraries at build-time to provide this functionality.
  NTLM is a Microsoft proprietary protocol. Proprietary formats are evil. You
  should not use such ones.
  4.10 My HTTP request using HEAD, PUT or DELETE doesn't work!
  Many web servers allow or demand that the administrator configures the
  server properly for these requests to work on the web server.
  Some servers seem to support HEAD only on certain kinds of URLs.
  To fully grasp this, try the documentation for the particular server
  software you're trying to interact with. This is not anything curl can do
  anything about.
  4.11 Why does my HTTP range requests return the full document?
  Because the range may not be supported by the server, or the server may
  choose to ignore it and return the full document anyway.
  4.12 Why do I get "certificate verify failed" ?
  You invoke curl 7.10 or later to communicate on a https:// URL and get an
  error back looking something similar to this:
      curl: (35) SSL: error:14090086:SSL routines:
      SSL3_GET_SERVER_CERTIFICATE:certificate verify failed
  Then it means that curl couldn't verify that the server's certificate was
  good. Curl verifies the certificate using the CA cert bundle that comes with
  the curl installation.
  To disable the verification (which makes it act like curl did before 7.10),
  use -k. This does however enable man-in-the-middle attacks.
  If you get this failure but are having a CA cert bundle installed and used,
  the server's certificate is not signed by one of the CA's in the bundle. It
  might for example be self-signed. You then correct this problem by obtaining
  a valid CA cert for the server. Or again, decrease the security by disabling
  this check.
  Details are also in the SSLCERTS file in the release archives, found online
  here: https://curl.haxx.se/docs/sslcerts.html
  4.13 Why is curl -R on Windows one hour off?
  Since curl 7.53.0 this issue should be fixed as long as curl was built with
  any modern compiler that allows for a 64-bit curl_off_t type. For older
  compilers or prior curl versions it may set a time that appears one hour off.
  This happens due to a flaw in how Windows stores and uses file modification
  times and it is not easily worked around. For more details read this:
  https://www.codeproject.com/Articles/1144/Beating-the-Daylight-Savings-Time-bug-and-getting
  4.14 Redirects work in browser but not with curl!
  curl supports HTTP redirects well (see item 3.8). Browsers generally support
  at least two other ways to perform redirects that curl does not:
  Meta tags. You can write a HTML tag that will cause the browser to redirect
  to another given URL after a certain time.
  Javascript. You can write a Javascript program embedded in a HTML page that
  redirects the browser to another given URL.
  There is no way to make curl follow these redirects. You must either
  manually figure out what the page is set to do, or you write a script that
  parses the results and fetches the new URL.
  4.15 FTPS doesn't work
  curl supports FTPS (sometimes known as FTP-SSL) both implicit and explicit
  mode.
  When a URL is used that starts with FTPS://, curl assumes implicit SSL on
  the control connection and will therefore immediately connect and try to
  speak SSL. FTPS:// connections default to port 990.
  To use explicit FTPS, you use a FTP:// URL and the --ftp-ssl option (or one
  of its related flavours). This is the most common method, and the one
  mandated by RFC4217. This kind of connection will then of course use the
  standard FTP port 21 by default.
  4.16 My HTTP POST or PUT requests are slow!
  libcurl makes all POST and PUT requests (except for POST requests with a
  very tiny request body) use the "Expect: 100-continue" header. This header
  allows the server to deny the operation early so that libcurl can bail out
  before having to send any data. This is useful in authentication
  cases and others.
  However, many servers don't implement the Expect: stuff properly and if the
  server doesn't respond (positively) within 1 second libcurl will continue
  and send off the data anyway.
  You can disable libcurl's use of the Expect: header the same way you disable
  any header, using -H / CURLOPT_HTTPHEADER, or by forcing it to use HTTP 1.0.
  4.17 Non-functional connect timeouts
  In most Windows setups having a timeout longer than 21 seconds make no
  difference, as it will only send 3 TCP SYN packets and no more. The second
  packet sent three seconds after the first and the third six seconds after
  the second.  No more than three packets are sent, no matter how long the
  timeout is set.
  See option TcpMaxConnectRetransmissions on this page:
  https://support.microsoft.com/en-us/kb/175523/en-us
  Also, even on non-Windows systems there may run a firewall or anti-virus
  software or similar that accepts the connection but does not actually do
  anything else. This will make (lib)curl to consider the connection connected
  and thus the connect timeout won't trigger.
  4.18 file:// URLs containing drive letters (Windows, NetWare)
  When using curl to try to download a local file, one might use a URL
  in this format:
  file://D:/blah.txt
  You'll find that even if D:\blah.txt does exist, curl returns a 'file
  not found' error.
  According to RFC 1738 (https://www.ietf.org/rfc/rfc1738.txt),
  file:// URLs must contain a host component, but it is ignored by
  most implementations. In the above example, 'D:' is treated as the
  host component, and is taken away. Thus, curl tries to open '/blah.txt'.
  If your system is installed to drive C:, that will resolve to 'C:\blah.txt',
  and if that doesn't exist you will get the not found error.
  To fix this problem, use file:// URLs with *three* leading slashes:
  file:///D:/blah.txt
  Alternatively, if it makes more sense, specify 'localhost' as the host
  component:
  file://localhost/D:/blah.txt
  In either case, curl should now be looking for the correct file.
  4.19 Why doesn't curl return an error when the network cable is unplugged?
  Unplugging a cable is not an error situation. The TCP/IP protocol stack
  was designed to be fault tolerant, so even though there may be a physical
  break somewhere the connection shouldn't be affected, just possibly
  delayed.  Eventually, the physical break will be fixed or the data will be
  re-routed around the physical problem through another path.
  In such cases, the TCP/IP stack is responsible for detecting when the
  network connection is irrevocably lost. Since with some protocols it is
  perfectly legal for the client to wait indefinitely for data, the stack may
  never report a problem, and even when it does, it can take up to 20 minutes
  for it to detect an issue.  The curl option --keepalive-time enables
  keep-alive support in the TCP/IP stack which makes it periodically probe the
  connection to make sure it is still available to send data. That should
  reliably detect any TCP/IP network failure.
  But even that won't detect the network going down before the TCP/IP
  connection is established (e.g. during a DNS lookup) or using protocols that
  don't use TCP.  To handle those situations, curl offers a number of timeouts
  on its own. --speed-limit/--speed-time will abort if the data transfer rate
  falls too low, and --connect-timeout and --max-time can be used to put an
  overall timeout on the connection phase or the entire transfer.
  A libcurl-using application running in a known physical environment (e.g.
  an embedded device with only a single network connection) may want to act
  immediately if its lone network connection goes down.  That can be achieved
  by having the application monitor the network connection on its own using an
  OS-specific mechanism, then signalling libcurl to abort (see also item 5.13).
  4.20 curl doesn't return error for HTTP non-200 responses!
  Correct. Unless you use -f (--fail).
  When doing HTTP transfers, curl will perform exactly what you're asking it
  to do and if successful it will not return an error. You can use curl to
  test your web server's "file not found" page (that gets 404 back), you can
  use it to check your authentication protected web pages (that gets a 401
  back) and so on.
  The specific HTTP response code does not constitute a problem or error for
  curl. It simply sends and delivers HTTP as you asked and if that worked,
  everything is fine and dandy. The response code is generally providing more
  higher level error information that curl doesn't care about. The error was
  not in the HTTP transfer.
  If you want your command line to treat error codes in the 400 and up range
  as errors and thus return a non-zero value and possibly show an error
  message, curl has a dedicated option for that: -f (CURLOPT_FAILONERROR in
  libcurl speak).
  You can also use the -w option and the variable %{response_code} to extract
  the exact response code that was returned in the response.
  4.21 Why is there a HTTP/1.1 in my HTTP/2 request?
  If you use verbose to see the HTTP request when you send off a HTTP/2
  request, it will still say 1.1.
  The reason for this is that we first generate the request to send using the
  old 1.1 style and show that request in the verbose output, and then we
  convert it over to the binary header-compressed HTTP/2 style. The actual
  "1.1" part from that request is then not actually used in the transfer.
  The binary HTTP/2 headers are not human readable.
5. libcurl Issues
  5.1 Is libcurl thread-safe?
  Yes.
  We have written the libcurl code specifically adjusted for multi-threaded
  programs. libcurl will use thread-safe functions instead of non-safe ones if
  your system has such.  Note that you must never share the same handle in
  multiple threads.
  There may be some exceptions to thread safety depending on how libcurl was
  built. Please review the guidelines for thread safety to learn more:
  https://curl.haxx.se/libcurl/c/threadsafe.html
  5.2 How can I receive all data into a large memory chunk?
  [ See also the examples/getinmemory.c source ]
  You are in full control of the callback function that gets called every time
  there is data received from the remote server. You can make that callback do
  whatever you want. You do not have to write the received data to a file.
  One solution to this problem could be to have a pointer to a struct that you
  pass to the callback function. You set the pointer using the
  CURLOPT_WRITEDATA option. Then that pointer will be passed to the callback
  instead of a FILE * to a file:
        /* imaginary struct */
        struct MemoryStruct {
          char *memory;
          size_t size;
        };
        /* imaginary callback function */
        size_t
        WriteMemoryCallback(void *ptr, size_t size, size_t nmemb, void *data)
        {
          size_t realsize = size * nmemb;
          struct MemoryStruct *mem = (struct MemoryStruct *)data;
          mem->memory = (char *)realloc(mem->memory, mem->size + realsize + 1);
          if (mem->memory) {
            memcpy(&(mem->memory[mem->size]), ptr, realsize);
            mem->size += realsize;
            mem->memory[mem->size] = 0;
          }
          return realsize;
        }
  5.3 How do I fetch multiple files with libcurl?
  libcurl has excellent support for transferring multiple files. You should
  just repeatedly set new URLs with curl_easy_setopt() and then transfer it
  with curl_easy_perform(). The handle you get from curl_easy_init() is not
  only reusable, but you're even encouraged to reuse it if you can, as that
  will enable libcurl to use persistent connections.
  5.4 Does libcurl do Winsock initialization on win32 systems?
  Yes, if told to in the curl_global_init() call.
  5.5 Does CURLOPT_WRITEDATA and CURLOPT_READDATA work on win32 ?
  Yes, but you cannot open a FILE * and pass the pointer to a DLL and have
  that DLL use the FILE * (as the DLL and the client application cannot access
  each others' variable memory areas). If you set CURLOPT_WRITEDATA you must
  also use CURLOPT_WRITEFUNCTION as well to set a function that writes the
  file, even if that simply writes the data to the specified FILE *.
  Similarly, if you use CURLOPT_READDATA you must also specify
  CURLOPT_READFUNCTION.
  5.6 What about Keep-Alive or persistent connections?
  curl and libcurl have excellent support for persistent connections when
  transferring several files from the same server.  Curl will attempt to reuse
  connections for all URLs specified on the same command line/config file, and
  libcurl will reuse connections for all transfers that are made using the
  same libcurl handle.
  When you use the easy interface the connection cache is kept within the easy
  handle. If you instead use the multi interface, the connection cache will be
  kept within the multi handle and will be shared among all the easy handles
  that are used within the same multi handle.
  5.7 Link errors when building libcurl on Windows!
  You need to make sure that your project, and all the libraries (both static
  and dynamic) that it links against, are compiled/linked against the same run
  time library.
  This is determined by the /MD, /ML, /MT (and their corresponding /M?d)
  options to the command line compiler. /MD (linking against MSVCRT dll) seems
  to be the most commonly used option.
  When building an application that uses the static libcurl library, you must
  add -DCURL_STATICLIB to your CFLAGS. Otherwise the linker will look for
  dynamic import symbols. If you're using Visual Studio, you need to instead
  add CURL_STATICLIB in the "Preprocessor Definitions" section.
  If you get linker error like "unknown symbol __imp__curl_easy_init ..." you
  have linked against the wrong (static) library.  If you want to use the
  libcurl.dll and import lib, you don't need any extra CFLAGS, but use one of
  the import libraries below. These are the libraries produced by the various
  lib/Makefile.* files:
       Target:          static lib.   import lib for libcurl*.dll.
       -----------------------------------------------------------
       MingW:           libcurl.a     libcurldll.a
       MSVC (release):  libcurl.lib   libcurl_imp.lib
       MSVC (debug):    libcurld.lib  libcurld_imp.lib
       Borland:         libcurl.lib   libcurl_imp.lib
  5.8 libcurl.so.X: open failed: No such file or directory
  This is an error message you might get when you try to run a program linked
  with a shared version of libcurl and your run-time linker (ld.so) couldn't
  find the shared library named libcurl.so.X. (Where X is the number of the
  current libcurl ABI, typically 3 or 4).
  You need to make sure that ld.so finds libcurl.so.X. You can do that
  multiple ways, and it differs somewhat between different operating systems,
  but they are usually:
  * Add an option to the linker command line that specify the hard-coded path
    the run-time linker should check for the lib (usually -R)
  * Set an environment variable (LD_LIBRARY_PATH for example) where ld.so
    should check for libs
  * Adjust the system's config to check for libs in the directory where you've
    put the dir (like Linux's /etc/ld.so.conf)
  'man ld.so' and 'man ld' will tell you more details
  5.9 How does libcurl resolve host names?
  libcurl supports a large a number of different name resolve functions. One
  of them is picked at build-time and will be used unconditionally. Thus, if
  you want to change name resolver function you must rebuild libcurl and tell
  it to use a different function.
  - The non-IPv6 resolver that can use one of four different host name resolve
  calls (depending on what your system supports):
      A - gethostbyname()
      B - gethostbyname_r() with 3 arguments
      C - gethostbyname_r() with 5 arguments
      D - gethostbyname_r() with 6 arguments
  - The IPv6-resolver that uses getaddrinfo()
  - The c-ares based name resolver that uses the c-ares library for resolves.
    Using this offers asynchronous name resolves.
  - The threaded resolver (default option on Windows). It uses:
      A - gethostbyname() on plain IPv4 hosts
      B - getaddrinfo() on IPv6 enabled hosts
  Also note that libcurl never resolves or reverse-lookups addresses given as
  pure numbers, such as 127.0.0.1 or ::1.
  5.10 How do I prevent libcurl from writing the response to stdout?
  libcurl provides a default built-in write function that writes received data
  to stdout. Set the CURLOPT_WRITEFUNCTION to receive the data, or possibly
  set CURLOPT_WRITEDATA to a different FILE * handle.
  5.11 How do I make libcurl not receive the whole HTTP response?
  You make the write callback (or progress callback) return an error and
  libcurl will then abort the transfer.
  5.12 Can I make libcurl fake or hide my real IP address?
  No. libcurl operates on a higher level. Besides, faking IP address would
  imply sending IP packets with a made-up source address, and then you normally
  get a problem with receiving the packet sent back as they would then not be
  routed to you!
  If you use a proxy to access remote sites, the sites will not see your local
  IP address but instead the address of the proxy.
  Also note that on many networks NATs or other IP-munging techniques are used
  that makes you see and use a different IP address locally than what the
  remote server will see you coming from. You may also consider using
  https://www.torproject.org/ .
  5.13 How do I stop an ongoing transfer?
  With the easy interface you make sure to return the correct error code from
  one of the callbacks, but none of them are instant. There is no function you
  can call from another thread or similar that will stop it immediately.
  Instead, you need to make sure that one of the callbacks you use returns an
  appropriate value that will stop the transfer.  Suitable callbacks that you
  can do this with include the progress callback, the read callback and the
  write callback.
  If you're using the multi interface, you can also stop a transfer by
  removing the particular easy handle from the multi stack at any moment you
  think the transfer is done or when you wish to abort the transfer.
  5.14 Using C++ non-static functions for callbacks?
  libcurl is a C library, it doesn't know anything about C++ member functions.
  You can overcome this "limitation" with relative ease using a static
  member function that is passed a pointer to the class:
     // f is the pointer to your object.
     static size_t YourClass::func(void *buffer, size_t sz, size_t n, void *f)
     {
       // Call non-static member function.
       static_cast<YourClass*>(f)->nonStaticFunction();
     }
     // This is how you pass pointer to the static function:
     curl_easy_setopt(hcurl, CURLOPT_WRITEFUNCTION, YourClass::func);
     curl_easy_setopt(hcurl, CURLOPT_WRITEDATA, this);
  5.15 How do I get an FTP directory listing?
  If you end the FTP URL you request with a slash, libcurl will provide you
  with a directory listing of that given directory. You can also set
  CURLOPT_CUSTOMREQUEST to alter what exact listing command libcurl would use
  to list the files.
  The follow-up question tends to be how is a program supposed to parse the
  directory listing. How does it know what's a file and what's a dir and what's
  a symlink etc. If the FTP server supports the MLSD command then it will
  return data in a machine-readable format that can be parsed for type. The
  types are specified by RFC3659 section 7.5.1. If MLSD is not supported then
  you have to work with what you're given. The LIST output format is entirely
  at the server's own liking and the NLST output doesn't reveal any types and
  in many cases doesn't even include all the directory entries. Also, both LIST
  and NLST tend to hide unix-style hidden files (those that start with a dot)
  by default so you need to do "LIST -a" or similar to see them.
  Example - List only directories.
  ftp.funet.fi supports MLSD and ftp.kernel.org does not:
     curl -s ftp.funet.fi/pub/ -X MLSD | \
       perl -lne 'print if s/(?:^|;)type=dir;[^ ]+ (.+)$/$1/'
     curl -s ftp.kernel.org/pub/linux/kernel/ | \
       perl -lne 'print if s/^d[-rwx]{9}(?: +[^ ]+){7} (.+)$/$1/'
  If you need to parse LIST output in libcurl one such existing
  list parser is available at https://cr.yp.to/ftpparse.html  Versions of
  libcurl since 7.21.0 also provide the ability to specify a wildcard to
  download multiple files from one FTP directory.
  5.16 I want a different time-out!
  Time and time again users realize that CURLOPT_TIMEOUT and
  CURLOPT_CONNECTIMEOUT are not sufficiently advanced or flexible to cover all
  the various use cases and scenarios applications end up with.
  libcurl offers many more ways to time-out operations. A common alternative
  is to use the CURLOPT_LOW_SPEED_LIMIT and CURLOPT_LOW_SPEED_TIME options to
  specify the lowest possible speed to accept before to consider the transfer
  timed out.
  The most flexible way is by writing your own time-out logic and using
  CURLOPT_XFERINFOFUNCTION (perhaps in combination with other callbacks) and
  use that to figure out exactly when the right condition is met when the
  transfer should get stopped.
  5.17 Can I write a server with libcurl?
  No. libcurl offers no functions or building blocks to build any kind of
  internet protocol server. libcurl is only a client-side library. For server
  libraries, you need to continue your search elsewhere but there exist many
  good open source ones out there for most protocols you could possibly want a
  server for. And there are really good stand-alone ones that have been tested
  and proven for many years. There's no need for you to reinvent them!
  5.18 Does libcurl use threads?
  Put simply: no, libcurl will execute in the same thread you call it in. All
  callbacks will be called in the same thread as the one you call libcurl in.
  If you want to avoid your thread to be blocked by the libcurl call, you make
  sure you use the non-blocking API which will do transfers asynchronously -
  but still in the same single thread.
  libcurl will potentially internally use threads for name resolving, if it
  was built to work like that, but in those cases it'll create the child
  threads by itself and they will only be used and then killed internally by
  libcurl and never exposed to the outside.
6. License Issues
  Curl and libcurl are released under a MIT/X derivate license. The license is
  very liberal and should not impose a problem for your project. This section
  is just a brief summary for the cases we get the most questions. (Parts of
  this section was much enhanced by Bjorn Reese.)
  We are not lawyers and this is not legal advice. You should probably consult
  one if you want true and accurate legal insights without our prejudice. Note
  especially that this section concerns the libcurl license only; compiling in
  features of libcurl that depend on other libraries (e.g. OpenSSL) may affect
  the licensing obligations of your application.
  6.1 I have a GPL program, can I use the libcurl library?
  Yes!
  Since libcurl may be distributed under the MIT/X derivate license, it can be
  used together with GPL in any software.
  6.2 I have a closed-source program, can I use the libcurl library?
  Yes!
  libcurl does not put any restrictions on the program that uses the library.
  6.3 I have a BSD licensed program, can I use the libcurl library?
  Yes!
  libcurl does not put any restrictions on the program that uses the library.
  6.4 I have a program that uses LGPL libraries, can I use libcurl?
  Yes!
  The LGPL license doesn't clash with other licenses.
  6.5 Can I modify curl/libcurl for my program and keep the changes secret?
  Yes!
  The MIT/X derivate license practically allows you to do almost anything with
  the sources, on the condition that the copyright texts in the sources are
  left intact.
  6.6 Can you please change the curl/libcurl license to XXXX?
  No.
  We have carefully picked this license after years of development and
  discussions and a large amount of people have contributed with source code
  knowing that this is the license we use. This license puts the restrictions
  we want on curl/libcurl and it does not spread to other programs or
  libraries that use it. It should be possible for everyone to use libcurl or
  curl in their projects, no matter what license they already have in use.
  6.7 What are my obligations when using libcurl in my commercial apps?
  Next to none. All you need to adhere to is the MIT-style license (stated in
  the COPYING file) which basically says you have to include the copyright
  notice in "all copies" and that you may not use the copyright holder's name
  when promoting your software.
  You do not have to release any of your source code.
  You do not have to reveal or make public any changes to the libcurl source
  code.
  You do not have to broadcast to the world that you are using libcurl within
  your app.
  All we ask is that you disclose "the copyright notice and this permission
  notice" somewhere. Most probably like in the documentation or in the section
  where other third party dependencies already are mentioned and acknowledged.
  As can be seen here: https://curl.haxx.se/docs/companies.html and elsewhere,
  more and more companies are discovering the power of libcurl and take
  advantage of it even in commercial environments.
7. PHP/CURL Issues
  7.1 What is PHP/CURL?
  The module for PHP that makes it possible for PHP programs to access curl-
  functions from within PHP.
  In the cURL project we call this module PHP/CURL to differentiate it from
  curl the command line tool and libcurl the library. The PHP team however
  does not refer to it like this (for unknown reasons). They call it plain
  CURL (often using all caps) or sometimes ext/curl, but both cause much
  confusion to users which in turn gives us a higher question load.
  7.2 Who wrote PHP/CURL?
  PHP/CURL was initially written by Sterling Hughes.
  7.3 Can I perform multiple requests using the same handle?
  Yes - at least in PHP version 4.3.8 and later (this has been known to not
  work in earlier versions, but the exact version when it started to work is
  unknown to me).
  After a transfer, you just set new options in the handle and make another
  transfer. This will make libcurl re-use the same connection if it can.
  7.4 Does PHP/CURL have dependencies?
  PHP/CURL is a module that comes with the regular PHP package. It depends on
  and uses libcurl, so you need to have libcurl installed properly before
  PHP/CURL can be used.
                                  _   _ ____  _
                              ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
FEATURES
curl tool
 - config file support
 - multiple URLs in a single command line
 - range "globbing" support: [0-13], {one,two,three}
 - multiple file upload on a single command line
 - custom maximum transfer rate
 - redirectable stderr
 - metalink support (*13)
libcurl
 - full URL syntax with no length limit
 - custom maximum download time
 - custom least download speed acceptable
 - custom output result after completion
 - guesses protocol from host name unless specified
 - uses .netrc
 - progress bar with time statistics while downloading
 - "standard" proxy environment variables support
 - compiles on win32 (reported builds on 40+ operating systems)
 - selectable network interface for outgoing traffic
 - IPv6 support on unix and Windows
 - persistent connections
 - socks 4 + 5 support, with or without local name resolving
 - supports user name and password in proxy environment variables
 - operations through proxy "tunnel" (using CONNECT)
 - support for large files (>2GB and >4GB) during upload and download
 - replaceable memory functions (malloc, free, realloc, etc)
 - asynchronous name resolving (*6)
 - both a push and a pull style interface
 - international domain names (*11)
HTTP
 - HTTP/1.1 compliant (optionally uses 1.0)
 - GET
 - PUT
 - HEAD
 - POST
 - Pipelining
 - multipart formpost (RFC1867-style)
 - authentication: Basic, Digest, NTLM (*9) and Negotiate (SPNEGO) (*3)
   to server and proxy
 - resume (both GET and PUT)
 - follow redirects
 - maximum amount of redirects to follow
 - custom HTTP request
 - cookie get/send fully parsed
 - reads/writes the netscape cookie file format
 - custom headers (replace/remove internally generated headers)
 - custom user-agent string
 - custom referrer string
 - range
 - proxy authentication
 - time conditions
 - via http-proxy
 - retrieve file modification date
 - Content-Encoding support for deflate and gzip
 - "Transfer-Encoding: chunked" support in uploads
 - data compression (*12)
 - HTTP/2 (*5)
HTTPS (*1)
 - (all the HTTP features)
 - using client certificates
 - verify server certificate
 - via http-proxy
 - select desired encryption
 - force usage of a specific SSL version (SSLv2 (*7), SSLv3 (*10) or TLSv1)
 - download
 - authentication
 - Kerberos 5 (*14)
 - active/passive using PORT, EPRT, PASV or EPSV
 - single file size information (compare to HTTP HEAD)
 - 'type=' URL support
 - dir listing
 - dir listing names-only
 - upload
 - upload append
 - upload via http-proxy as HTTP PUT
 - download resume
 - upload resume
 - custom ftp commands (before and/or after the transfer)
 - simple "range" support
 - via http-proxy
 - all operations can be tunneled through a http-proxy
 - customizable to retrieve file modification date
 - no dir depth limit
FTPS (*1)
 - implicit ftps:// support that use SSL on both connections
 - explicit "AUTH TLS" and "AUTH SSL" usage to "upgrade" plain ftp://
   connection to use SSL for both or one of the connections
SCP (*8)
 - both password and public key auth
SFTP (*8)
 - both password and public key auth
 - with custom commands sent before/after the transfer
TFTP
 - download
 - upload
TELNET
 - connection negotiation
 - custom telnet options
 - stdin/stdout I/O
LDAP (*2)
 - full LDAP URL support
DICT
 - extended DICT URL support
FILE
 - URL support
 - upload
 - resume
 - SMBv1 over TCP and SSL
 - download
 - upload
 - authentication with NTLMv1
SMTP
 - authentication: Plain, Login, CRAM-MD5, Digest-MD5, NTLM (*9), Kerberos 5
   (*4) and External.
 - send e-mails
 - mail from support
 - mail size support
 - mail auth support for trusted server-to-server relaying
 - multiple recipients
 - via http-proxy
SMTPS (*1)
 - implicit smtps:// support
 - explicit "STARTTLS" usage to "upgrade" plain smtp:// connections to use SSL
 - via http-proxy
POP3
 - authentication: Clear Text, APOP and SASL
 - SASL based authentication: Plain, Login, CRAM-MD5, Digest-MD5, NTLM (*9),
   Kerberos 5 (*4) and External.
 - list e-mails
 - retrieve e-mails
 - enhanced command support for: CAPA, DELE, TOP, STAT, UIDL and NOOP via
   custom requests
 - via http-proxy
POP3S (*1)
 - implicit pop3s:// support
 - explicit "STLS" usage to "upgrade" plain pop3:// connections to use SSL
 - via http-proxy
IMAP
 - authentication: Clear Text and SASL
 - SASL based authentication: Plain, Login, CRAM-MD5, Digest-MD5, NTLM (*9),
   Kerberos 5 (*4) and External.
 - list the folders of a mailbox
 - select a mailbox with support for verifying the UIDVALIDITY
 - fetch e-mails with support for specifying the UID and SECTION
 - upload e-mails via the append command
 - enhanced command support for: EXAMINE, CREATE, DELETE, RENAME, STATUS,
   STORE, COPY and UID via custom requests
 - via http-proxy
IMAPS (*1)
 - implicit imaps:// support
 - explicit "STARTTLS" usage to "upgrade" plain imap:// connections to use SSL
 - via http-proxy
FOOTNOTES
=========
  *1 = requires OpenSSL, GnuTLS, NSS, yassl, axTLS, PolarSSL, WinSSL (native
       Windows), Secure Transport (native iOS/OS X) or GSKit (native IBM i)
  *2 = requires OpenLDAP or WinLDAP
  *3 = requires a GSS-API implementation (such as Heimdal or MIT Kerberos) or
       SSPI (native Windows)
  *4 = requires a GSS-API implementation, however, only Windows SSPI is
       currently supported
  *5 = requires nghttp2 and possibly a recent TLS library
  *6 = requires c-ares
  *7 = requires OpenSSL, NSS, GSKit, WinSSL or Secure Transport; GnuTLS, for
       example, only supports SSLv3 and TLSv1
  *8 = requires libssh2
  *9 = requires OpenSSL, GnuTLS, mbedTLS, NSS, yassl, Secure Transport or SSPI
       (native Windows)
  *10 = requires any of the SSL libraries in (*1) above other than axTLS, which
        does not support SSLv3
  *11 = requires libidn or Windows
  *12 = requires libz
  *13 = requires libmetalink, and either an Apple or Microsoft operating
        system, or OpenSSL, or GnuTLS, or NSS
  *14 = requires a GSS-API implementation (such as Heimdal or MIT Kerberos)
LATEST VERSION
  You always find news about what's going on as well as the latest versions
  from the curl web pages, located at:
        https://curl.haxx.se
SIMPLE USAGE
  Get the main page from Netscape's web-server:
        curl http://www.netscape.com/
  Get the README file the user's home directory at funet's ftp-server:
        curl ftp://ftp.funet.fi/README
  Get a web page from a server using port 8000:
        curl http://www.weirdserver.com:8000/
  Get a directory listing of an FTP site:
        curl ftp://cool.haxx.se/
  Get the definition of curl from a dictionary:
        curl dict://dict.org/m:curl
  Fetch two documents at once:
        curl ftp://cool.haxx.se/ http://www.weirdserver.com:8000/
  Get a file off an FTPS server:
        curl ftps://files.are.secure.com/secrets.txt
  or use the more appropriate FTPS way to get the same file:
        curl --ftp-ssl ftp://files.are.secure.com/secrets.txt
  Get a file from an SSH server using SFTP:
        curl -u username sftp://example.com/etc/issue
  Get a file from an SSH server using SCP using a private key
  (not password-protected) to authenticate:
        curl -u username: --key ~/.ssh/id_rsa \
             scp://example.com/~/file.txt
  Get a file from an SSH server using SCP using a private key
  (password-protected) to authenticate:
        curl -u username: --key ~/.ssh/id_rsa --pass private_key_password \
             scp://example.com/~/file.txt
  Get the main page from an IPv6 web server:
        curl "http://[2001:1890:1112:1::20]/"
  Get a file from an SMB server:
        curl -u "domain\username:passwd" smb://server.example.com/share/file.txt
DOWNLOAD TO A FILE
  Get a web page and store in a local file with a specific name:
        curl -o thatpage.html http://www.netscape.com/
  Get a web page and store in a local file, make the local file get the name
  of the remote document (if no file name part is specified in the URL, this
  will fail):
        curl -O http://www.netscape.com/index.html
  Fetch two files and store them with their remote names:
        curl -O www.haxx.se/index.html -O curl.haxx.se/download.html
USING PASSWORDS
 FTP
   To ftp files using name+passwd, include them in the URL like:
        curl ftp://name:passwd@machine.domain:port/full/path/to/file
   or specify them with the -u flag like
        curl -u name:passwd ftp://machine.domain:port/full/path/to/file
 FTPS
   It is just like for FTP, but you may also want to specify and use
   SSL-specific options for certificates etc.
   Note that using FTPS:// as prefix is the "implicit" way as described in the
   standards while the recommended "explicit" way is done by using FTP:// and
   the --ftp-ssl option.
 SFTP / SCP
   This is similar to FTP, but you can use the --key option to specify a
   private key to use instead of a password. Note that the private key may
   itself be protected by a password that is unrelated to the login password
   of the remote system; this password is specified using the --pass option.
   Typically, curl will automatically extract the public key from the private
   key file, but in cases where curl does not have the proper library support,
   a matching public key file must be specified using the --pubkey option.
 HTTP
   Curl also supports user and password in HTTP URLs, thus you can pick a file
   like:
        curl http://name:passwd@machine.domain/full/path/to/file
   or specify user and password separately like in
        curl -u name:passwd http://machine.domain/full/path/to/file
   HTTP offers many different methods of authentication and curl supports
   several: Basic, Digest, NTLM and Negotiate (SPNEGO). Without telling which
   method to use, curl defaults to Basic. You can also ask curl to pick the
   most secure ones out of the ones that the server accepts for the given URL,
   by using --anyauth.
   NOTE! According to the URL specification, HTTP URLs can not contain a user
   and password, so that style will not work when using curl via a proxy, even
   though curl allows it at other times. When using a proxy, you _must_ use
   the -u style for user and password.
 HTTPS
   Probably most commonly used with private certificates, as explained below.
PROXY
 curl supports both HTTP and SOCKS proxy servers, with optional authentication.
 It does not have special support for FTP proxy servers since there are no
 standards for those, but it can still be made to work with many of them. You
 can also use both HTTP and SOCKS proxies to transfer files to and from FTP
 servers.
 Get an ftp file using an HTTP proxy named my-proxy that uses port 888:
        curl -x my-proxy:888 ftp://ftp.leachsite.com/README
 Get a file from an HTTP server that requires user and password, using the
 same proxy as above:
        curl -u user:passwd -x my-proxy:888 http://www.get.this/
 Some proxies require special authentication. Specify by using -U as above:
        curl -U user:passwd -x my-proxy:888 http://www.get.this/
 A comma-separated list of hosts and domains which do not use the proxy can
 be specified as:
        curl --noproxy localhost,get.this -x my-proxy:888 http://www.get.this/
 If the proxy is specified with --proxy1.0 instead of --proxy or -x, then
 curl will use HTTP/1.0 instead of HTTP/1.1 for any CONNECT attempts.
 curl also supports SOCKS4 and SOCKS5 proxies with --socks4 and --socks5.
 See also the environment variables Curl supports that offer further proxy
 control.
 Most FTP proxy servers are set up to appear as a normal FTP server from the
 client's perspective, with special commands to select the remote FTP server.
 curl supports the -u, -Q and --ftp-account options that can be used to
 set up transfers through many FTP proxies. For example, a file can be
 uploaded to a remote FTP server using a Blue Coat FTP proxy with the
 options:
   curl -u "Remote-FTP-Username@remote.ftp.server Proxy-Username:Remote-Pass" \
    --ftp-account Proxy-Password --upload-file local-file \
    ftp://my-ftp.proxy.server:21/remote/upload/path/
 See the manual for your FTP proxy to determine the form it expects to set up
 transfers, and curl's -v option to see exactly what curl is sending.
RANGES
  HTTP 1.1 introduced byte-ranges. Using this, a client can request
  to get only one or more subparts of a specified document. Curl supports
  this with the -r flag.
  Get the first 100 bytes of a document:
        curl -r 0-99 http://www.get.this/
  Get the last 500 bytes of a document:
        curl -r -500 http://www.get.this/
  Curl also supports simple ranges for FTP files as well. Then you can only
  specify start and stop position.
  Get the first 100 bytes of a document using FTP:
        curl -r 0-99 ftp://www.get.this/README
UPLOADING
 FTP / FTPS / SFTP / SCP
  Upload all data on stdin to a specified server:
        curl -T - ftp://ftp.upload.com/myfile
  Upload data from a specified file, login with user and password:
        curl -T uploadfile -u user:passwd ftp://ftp.upload.com/myfile
  Upload a local file to the remote site, and use the local file name at the remote
  site too:
        curl -T uploadfile -u user:passwd ftp://ftp.upload.com/
  Upload a local file to get appended to the remote file:
        curl -T localfile -a ftp://ftp.upload.com/remotefile
  Curl also supports ftp upload through a proxy, but only if the proxy is
  configured to allow that kind of tunneling. If it does, you can run curl in
  a fashion similar to:
        curl --proxytunnel -x proxy:port -T localfile ftp.upload.com
SMB / SMBS
        curl -T file.txt -u "domain\username:passwd" 
         smb://server.example.com/share/
 HTTP
  Upload all data on stdin to a specified HTTP site:
        curl -T - http://www.upload.com/myfile
  Note that the HTTP server must have been configured to accept PUT before
  this can be done successfully.
  For other ways to do HTTP data upload, see the POST section below.
VERBOSE / DEBUG
  If curl fails where it isn't supposed to, if the servers don't let you in,
  if you can't understand the responses: use the -v flag to get verbose
  fetching. Curl will output lots of info and what it sends and receives in
  order to let the user see all client-server interaction (but it won't show
  you the actual data).
        curl -v ftp://ftp.upload.com/
  To get even more details and information on what curl does, try using the
  --trace or --trace-ascii options with a given file name to log to, like
  this:
        curl --trace trace.txt www.haxx.se
DETAILED INFORMATION
  Different protocols provide different ways of getting detailed information
  about specific files/documents. To get curl to show detailed information
  about a single file, you should use -I/--head option. It displays all
  available info on a single file for HTTP and FTP. The HTTP information is a
  lot more extensive.
  For HTTP, you can get the header information (the same as -I would show)
  shown before the data by using -i/--include. Curl understands the
  -D/--dump-header option when getting files from both FTP and HTTP, and it
  will then store the headers in the specified file.
  Store the HTTP headers in a separate file (headers.txt in the example):
        curl --dump-header headers.txt curl.haxx.se
  Note that headers stored in a separate file can be very useful at a later
  time if you want curl to use cookies sent by the server. More about that in
  the cookies section.
POST (HTTP)
  It's easy to post data using curl. This is done using the -d <data>
  option.  The post data must be urlencoded.
  Post a simple "name" and "phone" guestbook.
        curl -d "name=Rafael%20Sagula&phone=3320780" \
                http://www.where.com/guest.cgi
  How to post a form with curl, lesson #1:
  Dig out all the <input> tags in the form that you want to fill in.
  If there's a "normal" post, you use -d to post. -d takes a full "post
  string", which is in the format
        <variable1>=<data1>&<variable2>=<data2>&...
  The 'variable' names are the names set with "name=" in the <input> tags, and
  the data is the contents you want to fill in for the inputs. The data *must*
  be properly URL encoded. That means you replace space with + and that you
  replace weird letters with %XX where XX is the hexadecimal representation of
  the letter's ASCII code.
  Example:
  (page located at http://www.formpost.com/getthis/
        <form action="post.cgi" method="post">
        <input name=user size=10>
        <input name=pass type=password size=10>
        <input name=id type=hidden value="blablabla">
        <input name=ding value="submit">
        </form>
  We want to enter user 'foobar' with password '12345'.
  To post to this, you enter a curl command line like:
        curl -d "user=foobar&pass=12345&id=blablabla&ding=submit"  (continues)
          http://www.formpost.com/getthis/post.cgi
  While -d uses the application/x-www-form-urlencoded mime-type, generally
  understood by CGI's and similar, curl also supports the more capable
  multipart/form-data type. This latter type supports things like file upload.
  -F accepts parameters like -F "name=contents". If you want the contents to
  be read from a file, use <@filename> as contents. When specifying a file,
  you can also specify the file content type by appending ';type=<mime type>'
  to the file name. You can also post the contents of several files in one
  field.  For example, the field name 'coolfiles' is used to send three files,
  with different content types using the following syntax:
        curl -F "coolfiles=@fil1.gif;type=image/gif,fil2.txt,fil3.html" \
        http://www.post.com/postit.cgi
  If the content-type is not specified, curl will try to guess from the file
  extension (it only knows a few), or use the previously specified type (from
  an earlier file if several files are specified in a list) or else it will
  use the default type 'application/octet-stream'.
  Emulate a fill-in form with -F. Let's say you fill in three fields in a
  form. One field is a file name which to post, one field is your name and one
  field is a file description. We want to post the file we have written named
  "cooltext.txt". To let curl do the posting of this data instead of your
  favourite browser, you have to read the HTML source of the form page and
  find the names of the input fields. In our example, the input field names
  are 'file', 'yourname' and 'filedescription'.
        curl -F "file=@cooltext.txt" -F "yourname=Daniel" \
             -F "filedescription=Cool text file with cool text inside" \
             http://www.post.com/postit.cgi
  To send two files in one post you can do it in two ways:
  1. Send multiple files in a single "field" with a single field name:
        curl -F "pictures=@dog.gif,cat.gif"
  2. Send two fields with two field names:
        curl -F "docpicture=@dog.gif" -F "catpicture=@cat.gif"
  To send a field value literally without interpreting a leading '@'
  or '<', or an embedded ';type=', use --form-string instead of
  -F. This is recommended when the value is obtained from a user or
  some other unpredictable source. Under these circumstances, using
  -F instead of --form-string would allow a user to trick curl into
  uploading a file.
REFERRER
  An HTTP request has the option to include information about which address
  referred it to the actual page.  Curl allows you to specify the
  referrer to be used on the command line. It is especially useful to
  fool or trick stupid servers or CGI scripts that rely on that information
  being available or contain certain data.
        curl -e www.coolsite.com http://www.showme.com/
  NOTE: The Referer: [sic] field is defined in the HTTP spec to be a full URL.
USER AGENT
  An HTTP request has the option to include information about the browser
  that generated the request. Curl allows it to be specified on the command
  line. It is especially useful to fool or trick stupid servers or CGI
  scripts that only accept certain browsers.
  Example:
  curl -A 'Mozilla/3.0 (Win95; I)' http://www.nationsbank.com/
  Other common strings:
    'Mozilla/3.0 (Win95; I)'     Netscape Version 3 for Windows 95
    'Mozilla/3.04 (Win95; U)'    Netscape Version 3 for Windows 95
    'Mozilla/2.02 (OS/2; U)'     Netscape Version 2 for OS/2
    'Mozilla/4.04 [en] (X11; U; AIX 4.2; Nav)'           NS for AIX
    'Mozilla/4.05 [en] (X11; U; Linux 2.0.32 i586)'      NS for Linux
  Note that Internet Explorer tries hard to be compatible in every way:
    'Mozilla/4.0 (compatible; MSIE 4.01; Windows 95)'    MSIE for W95
  Mozilla is not the only possible User-Agent name:
    'Konqueror/1.0'             KDE File Manager desktop client
    'Lynx/2.7.1 libwww-FM/2.14' Lynx command line browser
COOKIES
  Cookies are generally used by web servers to keep state information at the
  client's side. The server sets cookies by sending a response line in the
  headers that looks like 'Set-Cookie: <data>' where the data part then
  typically contains a set of NAME=VALUE pairs (separated by semicolons ';'
  like "NAME1=VALUE1; NAME2=VALUE2;"). The server can also specify for what
  path the "cookie" should be used for (by specifying "path=value"), when the
  cookie should expire ("expire=DATE"), for what domain to use it
  ("domain=NAME") and if it should be used on secure connections only
  ("secure").
  If you've received a page from a server that contains a header like:
        Set-Cookie: sessionid=boo123; path="/foo";
  it means the server wants that first pair passed on when we get anything in
  a path beginning with "/foo".
  Example, get a page that wants my name passed in a cookie:
        curl -b "name=Daniel" www.sillypage.com
  Curl also has the ability to use previously received cookies in following
  sessions. If you get cookies from a server and store them in a file in a
  manner similar to:
        curl --dump-header headers www.example.com
  ... you can then in a second connect to that (or another) site, use the
  cookies from the 'headers' file like:
        curl -b headers www.example.com
  While saving headers to a file is a working way to store cookies, it is
  however error-prone and not the preferred way to do this. Instead, make curl
  save the incoming cookies using the well-known netscape cookie format like
  this:
        curl -c cookies.txt www.example.com
  Note that by specifying -b you enable the "cookie awareness" and with -L
  you can make curl follow a location: (which often is used in combination
  with cookies). So that if a site sends cookies and a location, you can
  use a non-existing file to trigger the cookie awareness like:
        curl -L -b empty.txt www.example.com
  The file to read cookies from must be formatted using plain HTTP headers OR
  as netscape's cookie file. Curl will determine what kind it is based on the
  file contents.  In the above command, curl will parse the header and store
  the cookies received from www.example.com.  curl will send to the server the
  stored cookies which match the request as it follows the location.  The
  file "empty.txt" may be a nonexistent file.
  To read and write cookies from a netscape cookie file, you can set both -b
  and -c to use the same file:
        curl -b cookies.txt -c cookies.txt www.example.com
PROGRESS METER
  The progress meter exists to show a user that something actually is
  happening. The different fields in the output have the following meaning:
  % Total    % Received % Xferd  Average Speed          Time             Curr.
                                 Dload  Upload Total    Current  Left    Speed
  0  151M    0 38608    0     0   9406      0  4:41:43  0:00:04  4:41:39  9287
  From left-to-right:
   %             - percentage completed of the whole transfer
   Total         - total size of the whole expected transfer
   %             - percentage completed of the download
   Received      - currently downloaded amount of bytes
   %             - percentage completed of the upload
   Xferd         - currently uploaded amount of bytes
   Average Speed
   Dload         - the average transfer speed of the download
   Average Speed
   Upload        - the average transfer speed of the upload
   Time Total    - expected time to complete the operation
   Time Current  - time passed since the invoke
   Time Left     - expected time left to completion
   Curr.Speed    - the average transfer speed the last 5 seconds (the first
                   5 seconds of a transfer is based on less time of course.)
  The -# option will display a totally different progress bar that doesn't
  need much explanation!
SPEED LIMIT
  Curl allows the user to set the transfer speed conditions that must be met
  to let the transfer keep going. By using the switch -y and -Y you
  can make curl abort transfers if the transfer speed is below the specified
  lowest limit for a specified time.
  To have curl abort the download if the speed is slower than 3000 bytes per
  second for 1 minute, run:
        curl -Y 3000 -y 60 www.far-away-site.com
  This can very well be used in combination with the overall time limit, so
  that the above operation must be completed in whole within 30 minutes:
        curl -m 1800 -Y 3000 -y 60 www.far-away-site.com
  Forcing curl not to transfer data faster than a given rate is also possible,
  which might be useful if you're using a limited bandwidth connection and you
  don't want your transfer to use all of it (sometimes referred to as
  "bandwidth throttle").
  Make curl transfer data no faster than 10 kilobytes per second:
        curl --limit-rate 10K www.far-away-site.com
    or
        curl --limit-rate 10240 www.far-away-site.com
  Or prevent curl from uploading data faster than 1 megabyte per second:
        curl -T upload --limit-rate 1M ftp://uploadshereplease.com
  When using the --limit-rate option, the transfer rate is regulated on a
  per-second basis, which will cause the total transfer speed to become lower
  than the given number. Sometimes of course substantially lower, if your
  transfer stalls during periods.
CONFIG FILE
  Curl automatically tries to read the .curlrc file (or _curlrc file on win32
  systems) from the user's home dir on startup.
  The config file could be made up with normal command line switches, but you
  can also specify the long options without the dashes to make it more
  readable. You can separate the options and the parameter with spaces, or
  with = or :. Comments can be used within the file. If the first letter on a
  line is a '#'-symbol the rest of the line is treated as a comment.
  If you want the parameter to contain spaces, you must enclose the entire
  parameter within double quotes ("). Within those quotes, you specify a
  quote as \".
  NOTE: You must specify options and their arguments on the same line.
  Example, set default time out and proxy in a config file:
        # We want a 30 minute timeout:
        -m 1800
        # ... and we use a proxy for all accesses:
        proxy = proxy.our.domain.com:8080
  White spaces ARE significant at the end of lines, but all white spaces
  leading up to the first characters of each line are ignored.
  Prevent curl from reading the default file by using -q as the first command
  line parameter, like:
        curl -q www.thatsite.com
  Force curl to get and display a local help page in case it is invoked
  without URL by making a config file similar to:
        # default url to get
        url = "http://help.with.curl.com/curlhelp.html"
  You can specify another config file to be read by using the -K/--config
  flag. If you set config file name to "-" it'll read the config from stdin,
  which can be handy if you want to hide options from being visible in process
  tables etc:
        echo "user = user:passwd" | curl -K - http://that.secret.site.com
EXTRA HEADERS
  When using curl in your own very special programs, you may end up needing
  to pass on your own custom headers when getting a web page. You can do
  this by using the -H flag.
  Example, send the header "X-you-and-me: yes" to the server when getting a
  page:
        curl -H "X-you-and-me: yes" www.love.com
  This can also be useful in case you want curl to send a different text in a
  header than it normally does. The -H header you specify then replaces the
  header curl would normally send. If you replace an internal header with an
  empty one, you prevent that header from being sent. To prevent the Host:
  header from being used:
        curl -H "Host:" www.server.com
FTP and PATH NAMES
  Do note that when getting files with the ftp:// URL, the given path is
  relative the directory you enter. To get the file 'README' from your home
  directory at your ftp site, do:
        curl ftp://user:passwd@my.site.com/README
  But if you want the README file from the root directory of that very same
  site, you need to specify the absolute file name:
        curl ftp://user:passwd@my.site.com//README
  (I.e with an extra slash in front of the file name.)
SFTP and SCP and PATH NAMES
  With sftp: and scp: URLs, the path name given is the absolute name on the
  server. To access a file relative to the remote user's home directory,
  prefix the file with /~/ , such as:
        curl -u $USER sftp://home.example.com/~/.bashrc
FTP and firewalls
  The FTP protocol requires one of the involved parties to open a second
  connection as soon as data is about to get transferred. There are two ways to
  do this.
  The default way for curl is to issue the PASV command which causes the
  server to open another port and await another connection performed by the
  client. This is good if the client is behind a firewall that doesn't allow
  incoming connections.
        curl ftp.download.com
  If the server, for example, is behind a firewall that doesn't allow connections
  on ports other than 21 (or if it just doesn't support the PASV command), the
  other way to do it is to use the PORT command and instruct the server to
  connect to the client on the given IP number and port (as parameters to the
  PORT command).
  The -P flag to curl supports a few different options. Your machine may have
  several IP-addresses and/or network interfaces and curl allows you to select
  which of them to use. Default address can also be used:
        curl -P - ftp.download.com
  Download with PORT but use the IP address of our 'le0' interface (this does
  not work on windows):
        curl -P le0 ftp.download.com
  Download with PORT but use 192.168.0.10 as our IP address to use:
        curl -P 192.168.0.10 ftp.download.com
NETWORK INTERFACE
  Get a web page from a server using a specified port for the interface:
        curl --interface eth0:1 http://www.netscape.com/
  or
        curl --interface 192.168.1.10 http://www.netscape.com/
HTTPS
  Secure HTTP requires SSL libraries to be installed and used when curl is
  built. If that is done, curl is capable of retrieving and posting documents
  using the HTTPS protocol.
  Example:
        curl https://www.secure-site.com
  Curl is also capable of using your personal certificates to get/post files
  from sites that require valid certificates. The only drawback is that the
  certificate needs to be in PEM-format. PEM is a standard and open format to
  store certificates with, but it is not used by the most commonly used
  browsers (Netscape and MSIE both use the so called PKCS#12 format). If you
  want curl to use the certificates you use with your (favourite) browser, you
  may need to download/compile a converter that can convert your browser's
  formatted certificates to PEM formatted ones. This kind of converter is
  included in recent versions of OpenSSL, and for older versions Dr Stephen
  N. Henson has written a patch for SSLeay that adds this functionality. You
  can get his patch (that requires an SSLeay installation) from his site at:
  http://www.drh-consultancy.demon.co.uk/
  Example on how to automatically retrieve a document using a certificate with
  a personal password:
        curl -E /path/to/cert.pem:password https://secure.site.com/
  If you neglect to specify the password on the command line, you will be
  prompted for the correct password before any data can be received.
  Many older SSL-servers have problems with SSLv3 or TLS, which newer versions
  of OpenSSL etc use, therefore it is sometimes useful to specify what
  SSL-version curl should use. Use -3, -2 or -1 to specify that exact SSL
  version to use (for SSLv3, SSLv2 or TLSv1 respectively):
        curl -2 https://secure.site.com/
  Otherwise, curl will first attempt to use v3 and then v2.
  To use OpenSSL to convert your favourite browser's certificate into a PEM
  formatted one that curl can use, do something like this:
    In Netscape, you start with hitting the 'Security' menu button.
    Select 'certificates->yours' and then pick a certificate in the list
    Press the 'Export' button
    enter your PIN code for the certs
    select a proper place to save it
    Run the 'openssl' application to convert the certificate. If you cd to the
    openssl installation, you can do it like:
     # ./apps/openssl pkcs12 -in [file you saved] -clcerts -out [PEMfile]
    In Firefox, select Options, then Advanced, then the Encryption tab,
    View Certificates. This opens the Certificate Manager, where you can
    Export. Be sure to select PEM for the Save as type.
    In Internet Explorer, select Internet Options, then the Content tab, then
    Certificates. Then you can Export, and depending on the format you may
    need to convert to PEM.
    In Chrome, select Settings, then Show Advanced Settings. Under HTTPS/SSL
    select Manage Certificates.
RESUMING FILE TRANSFERS
 To continue a file transfer where it was previously aborted, curl supports
 resume on HTTP(S) downloads as well as FTP uploads and downloads.
 Continue downloading a document:
        curl -C - -o file ftp://ftp.server.com/path/file
 Continue uploading a document(*1):
        curl -C - -T file ftp://ftp.server.com/path/file
 Continue downloading a document from a web server(*2):
        curl -C - -o file http://www.server.com/
 (*1) = This requires that the FTP server supports the non-standard command
        SIZE. If it doesn't, curl will say so.
 (*2) = This requires that the web server supports at least HTTP/1.1. If it
        doesn't, curl will say so.
TIME CONDITIONS
 HTTP allows a client to specify a time condition for the document it
 requests. It is If-Modified-Since or If-Unmodified-Since. Curl allows you to
 specify them with the -z/--time-cond flag.
 For example, you can easily make a download that only gets performed if the
 remote file is newer than a local copy. It would be made like:
        curl -z local.html http://remote.server.com/remote.html
 Or you can download a file only if the local file is newer than the remote
 one. Do this by prepending the date string with a '-', as in:
        curl -z -local.html http://remote.server.com/remote.html
 You can specify a "free text" date as condition. Tell curl to only download
 the file if it was updated since January 12, 2012:
        curl -z "Jan 12 2012" http://remote.server.com/remote.html
 Curl will then accept a wide range of date formats. You always make the date
 check the other way around by prepending it with a dash '-'.
DICT
  For fun try
        curl dict://dict.org/m:curl
        curl dict://dict.org/d:heisenbug:jargon
        curl dict://dict.org/d:daniel:web1913
  Aliases for 'm' are 'match' and 'find', and aliases for 'd' are 'define'
  and 'lookup'. For example,
        curl dict://dict.org/find:curl
  Commands that break the URL description of the RFC (but not the DICT
  protocol) are
        curl dict://dict.org/show:db
        curl dict://dict.org/show:strat
  Authentication is still missing (but this is not required by the RFC)
LDAP
  If you have installed the OpenLDAP library, curl can take advantage of it
  and offer ldap:// support.
  On Windows, curl will use WinLDAP from Platform SDK by default.
  Default protocol version used by curl is LDAPv3. LDAPv2 will be used as
  fallback mechanism in case if LDAPv3 will fail to connect.
  LDAP is a complex thing and writing an LDAP query is not an easy task. I do
  advise you to dig up the syntax description for that elsewhere. One such
  place might be:
  RFC 2255, "The LDAP URL Format" https://curl.haxx.se/rfc/rfc2255.txt
  To show you an example, this is how I can get all people from my local LDAP
  server that has a certain sub-domain in their email address:
        curl -B "ldap://ldap.frontec.se/o=frontec??sub?mail=*sth.frontec.se"
  If I want the same info in HTML format, I can get it by not using the -B
  (enforce ASCII) flag.
  You also can use authentication when accessing LDAP catalog:
      curl -u user:passwd "ldap://ldap.frontec.se/o=frontec??sub?mail=*"
      curl "ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*"
  By default, if user and password provided, OpenLDAP/WinLDAP will use basic
  authentication. On Windows you can control this behavior by providing 
  one of --basic, --ntlm or --digest option in curl command line
      curl --ntlm "ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*"
  On Windows, if no user/password specified, auto-negotiation mechanism will
  be used with current logon credentials (SSPI/SPNEGO).
ENVIRONMENT VARIABLES
  Curl reads and understands the following environment variables:
        http_proxy, HTTPS_PROXY, FTP_PROXY
  They should be set for protocol-specific proxies. General proxy should be
  set with
        ALL_PROXY
  A comma-separated list of host names that shouldn't go through any proxy is
  set in (only an asterisk, '*' matches all hosts)
        NO_PROXY
  If the host name matches one of these strings, or the host is within the
  domain of one of these strings, transactions with that node will not be
  proxied. When a domain is used, it needs to start with a period. A user can
  specify that both www.example.com and foo.example.com should not uses a
  proxy by setting NO_PROXY to ".example.com". By including the full name you
  can exclude specific host names, so to make www.example.com not use a proxy
  but still have foo.example.com do it, set NO_PROXY to "www.example.com"
  The usage of the -x/--proxy flag overrides the environment variables.
NETRC
  Unix introduced the .netrc concept a long time ago. It is a way for a user
  to specify name and password for commonly visited FTP sites in a file so
  that you don't have to type them in each time you visit those sites. You
  realize this is a big security risk if someone else gets hold of your
  passwords, so therefore most unix programs won't read this file unless it is
  only readable by yourself (curl doesn't care though).
  Curl supports .netrc files if told to (using the -n/--netrc and
  --netrc-optional options). This is not restricted to just FTP,
  so curl can use it for all protocols where authentication is used.
  A very simple .netrc file could look something like:
        machine curl.haxx.se login iamdaniel password mysecret
CUSTOM OUTPUT
  To better allow script programmers to get to know about the progress of
  curl, the -w/--write-out option was introduced. Using this, you can specify
  what information from the previous transfer you want to extract.
  To display the amount of bytes downloaded together with some text and an
  ending newline:
        curl -w 'We downloaded %{size_download} bytes\n' www.download.com
KERBEROS FTP TRANSFER
  Curl supports kerberos4 and kerberos5/GSSAPI for FTP transfers. You need
  the kerberos package installed and used at curl build time for it to be
  available.
  First, get the krb-ticket the normal way, like with the kinit/kauth tool.
  Then use curl in way similar to:
        curl --krb private ftp://krb4site.com -u username:fakepwd
  There's no use for a password on the -u switch, but a blank one will make
  curl ask for one and you already entered the real password to kinit/kauth.
TELNET
  The curl telnet support is basic and very easy to use. Curl passes all data
  passed to it on stdin to the remote server. Connect to a remote telnet
  server using a command line similar to:
        curl telnet://remote.server.com
  And enter the data to pass to the server on stdin. The result will be sent
  to stdout or to the file you specify with -o.
  You might want the -N/--no-buffer option to switch off the buffered output
  for slow connections or similar.
  Pass options to the telnet protocol negotiation, by using the -t option. To
  tell the server we use a vt100 terminal, try something like:
        curl -tTTYPE=vt100 telnet://remote.server.com
  Other interesting options for it -t include:
   - XDISPLOC=<X display> Sets the X display location.
   - NEW_ENV=<var,val> Sets an environment variable.
  NOTE: The telnet protocol does not specify any way to login with a specified
  user and password so curl can't do that automatically. To do that, you need
  to track when the login prompt is received and send the username and
  password accordingly.
PERSISTENT CONNECTIONS
  Specifying multiple files on a single command line will make curl transfer
  all of them, one after the other in the specified order.
  libcurl will attempt to use persistent connections for the transfers so that
  the second transfer to the same host can use the same connection that was
  already initiated and was left open in the previous transfer. This greatly
  decreases connection time for all but the first transfer and it makes a far
  better use of the network.
  Note that curl cannot use persistent connections for transfers that are used
  in subsequence curl invokes. Try to stuff as many URLs as possible on the
  same command line if they are using the same host, as that'll make the
  transfers faster. If you use an HTTP proxy for file transfers, practically
  all transfers will be persistent.
MULTIPLE TRANSFERS WITH A SINGLE COMMAND LINE
  As is mentioned above, you can download multiple files with one command line
  by simply adding more URLs. If you want those to get saved to a local file
  instead of just printed to stdout, you need to add one save option for each
  URL you specify. Note that this also goes for the -O option (but not
  --remote-name-all).
  For example: get two files and use -O for the first and a custom file
  name for the second:
    curl -O http://url.com/file.txt ftp://ftp.com/moo.exe -o moo.jpg
  You can also upload multiple files in a similar fashion:
    curl -T local1 ftp://ftp.com/moo.exe -T local2 ftp://ftp.com/moo2.txt
IPv6
  curl will connect to a server with IPv6 when a host lookup returns an IPv6
  address and fall back to IPv4 if the connection fails. The --ipv4 and --ipv6
  options can specify which address to use when both are available. IPv6
  addresses can also be specified directly in URLs using the syntax:
    http://[2001:1890:1112:1::20]/overview.html
  When this style is used, the -g option must be given to stop curl from
  interpreting the square brackets as special globbing characters.  Link local
  and site local addresses including a scope identifier, such as fe80::1234%1,
  may also be used, but the scope portion must be numeric or match an existing
  network interface on Linux and the percent character must be URL escaped. The
  previous example in an SFTP URL might look like:
    sftp://[fe80::1234%251]/
  IPv6 addresses provided other than in URLs (e.g. to the --proxy, --interface
  or --ftp-port options) should not be URL encoded.
METALINK
  Curl supports Metalink (both version 3 and 4 (RFC 5854) are supported), a way
  to list multiple URIs and hashes for a file. Curl will make use of the mirrors
  listed within for failover if there are errors (such as the file or server not
  being available). It will also verify the hash of the file after the download
  completes. The Metalink file itself is downloaded and processed in memory and
  not stored in the local file system.
  Example to use a remote Metalink file:
    curl --metalink http://www.example.com/example.metalink
  To use a Metalink file in the local file system, use FILE protocol (file://):
    curl --metalink file://example.metalink
  Please note that if FILE protocol is disabled, there is no way to use a local
  Metalink file at the time of this writing. Also note that if --metalink and
  --include are used together, --include will be ignored. This is because including
  headers in the response will break Metalink parser and if the headers are included
  in the file described in Metalink file, hash check will fail.
MAILING LISTS
  For your convenience, we have several open mailing lists to discuss curl,
  its development and things relevant to this. Get all info at
  https://curl.haxx.se/mail/. Some of the lists available are:
  curl-users
    Users of the command line tool. How to use it, what doesn't work, new
    features, related tools, questions, news, installations, compilations,
    running, porting etc.
  curl-library
    Developers using or developing libcurl. Bugs, extensions, improvements.
  curl-announce
    Low-traffic. Only receives announcements of new public versions. At worst,
    that makes something like one or two mails per month, but usually only one
    mail every second month.
  curl-and-php
    Using the curl functions in PHP. Everything curl with a PHP angle. Or PHP
    with a curl angle.
  curl-and-python
    Python hackers using curl with or without the python binding pycurl.
  Please direct curl questions, feature requests and trouble reports to one of
  these mailing lists instead of mailing any individual.
                                  _   _ ____  _
                              ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
README
  Curl is a command line tool for transferring data specified with URL
  syntax. Find out how to use curl by reading the curl.1 man page or the
  MANUAL document. Find out how to install Curl by reading the INSTALL
  document.
  libcurl is the library curl is using to do its job. It is readily
  available to be used by your software. Read the libcurl.3 man page to
  learn how!
  You find answers to the most frequent questions we get in the FAQ document.
  Study the COPYING file for distribution terms and similar. If you distribute
  curl binaries or other binaries that involve libcurl, you might enjoy the
  LICENSE-MIXING document.
CONTACT
  If you have problems, questions, ideas or suggestions, please contact us
  by posting to a suitable mailing list. See https://curl.haxx.se/mail/
  All contributors to the project are listed in the THANKS document.
WEB SITE
  Visit the curl web site for the latest news and downloads:
        https://curl.haxx.se/
  To download the very latest source off the GIT server do this:
    git clone https://github.com/curl/curl.git
  (you'll get a directory named curl created, filled with the source code)
NOTICE
  Curl contains pieces of source code that is Copyright (c) 1998, 1999
  Kungliga Tekniska H
gskolan. This notice is included here to comply with the
  distribution terms.
                                  _   _ ____  _
  Project                     ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
This document lists documents and standards used by curl.
  RFC 959  - FTP Protocol
  RFC 1635 - How to Use Anonymous FTP
  RFC 1738 - Uniform Resource Locators
  RFC 1777 - Lightweight Directory Access Protocol (LDAP)
  RFC 1808 - Relative Uniform Resource Locators
  RFC 1867 - Form-based File Upload in HTML
  RFC 1950 - ZLIB Compressed Data Format Specification
  RFC 1951 - DEFLATE Compressed Data Format Specification
  RFC 1952 - GZIP File Format Specification
  RFC 1959 - LDAP URL Syntax
  RFC 2045-2049 - Everything you need to know about MIME! (needed for form
                  based upload)
  RFC 2068 - HTTP 1.1 (obsoleted by RFC 2616)
  RFC 2104 - Keyed-Hashing for Message Authentication
  RFC 2109 - HTTP State Management Mechanism (cookie stuff)
           - Also, read Netscape's specification at
             https://curl.haxx.se/rfc/cookie_spec.html
  RFC 2183 - The Content-Disposition Header Field
  RFC 2195 - CRAM-MD5 Authentication
  RFC 2229 - A Dictionary Server Protocol
  RFC 2255 - Newer LDAP URL Format
  RFC 2231 - MIME Parameter Value and Encoded Word Extensions:
             Character Sets, Languages, and Continuations
  RFC 2388 - "Returning Values from Forms: multipart/form-data"
             Use this as an addition to the RFC1867
  RFC 2396 - "Uniform Resource Identifiers: Generic Syntax and Semantics" This
             one obsoletes RFC 1738, but since RFC 1738 is often mentioned
             I've left it in this list.
  RFC 2428 - FTP Extensions for IPv6 and NATs
  RFC 2577 - FTP Security Considerations
  RFC 2616 - HTTP 1.1, the latest
  RFC 2617 - HTTP Authentication
  RFC 2718 - Guidelines for new URL Schemes
  RFC 2732 - Format for Literal IPv6 Addresses in URL's
  RFC 2818 - HTTP Over TLS (TLS is the successor to SSL)
  RFC 2821 - Simple Mail Transfer Protocol (SMTP)
  RFC 2964 - Use of HTTP State Management
  RFC 2965 - HTTP State Management Mechanism. Cookies. Obsoletes RFC2109
  RFC 3207 - SMTP Over TLS
  RFC 4616 - PLAIN Authentication
  RFC 4954 - SMTP Authentication
  RFC 7932 - Brotli Compressed Data Format
                                  _   _ ____  _
                              ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
The Art Of Scripting HTTP Requests Using Curl
 1. HTTP Scripting
 1.1 Background
 1.2 The HTTP Protocol
 1.3 See the Protocol
 1.4 See the Timing
 1.5 See the Response
 2. URL
 2.1 Spec
 2.2 Host
 2.3 Port number
 2.4 User name and password
 2.5 Path part
 3. Fetch a page
 3.1 GET
 3.2 HEAD
 3.3 Multiple URLs in a single command line
 3.4 Multiple HTTP methods in a single command line
 4. HTML forms
 4.1 Forms explained
 4.2 GET
 4.3 POST
 4.4 File Upload POST
 4.5 Hidden Fields
 4.6 Figure Out What A POST Looks Like
 5. HTTP upload
 5.1 PUT
 6. HTTP Authentication
 6.1 Basic Authentication
 6.2 Other Authentication
 6.3 Proxy Authentication
 6.4 Hiding credentials
 7. More HTTP Headers
 7.1 Referer
 7.2 User Agent
 8. Redirects
 8.1 Location header
 8.2 Other redirects
 9. Cookies
 9.1 Cookie Basics
 9.2 Cookie options
 10. HTTPS
 10.1 HTTPS is HTTP secure
 10.2 Certificates
 11. Custom Request Elements
 11.1 Modify method and headers
 11.2 More on changed methods
 12. Web Login
 12.1 Some login tricks
 13. Debug
 13.1 Some debug tricks
 14. References
 14.1 Standards
 14.2 Sites
==============================================================================
1. HTTP Scripting
 1.1 Background
 This document assumes that you're familiar with HTML and general networking.
 The increasing amount of applications moving to the web has made "HTTP
 Scripting" more frequently requested and wanted. To be able to automatically
 extract information from the web, to fake users, to post or upload data to
 web servers are all important tasks today.
 Curl is a command line tool for doing all sorts of URL manipulations and
 transfers, but this particular document will focus on how to use it when
 doing HTTP requests for fun and profit. I'll assume that you know how to
 invoke 'curl --help' or 'curl --manual' to get basic information about it.
 Curl is not written to do everything for you. It makes the requests, it gets
 the data, it sends data and it retrieves the information. You probably need
 to glue everything together using some kind of script language or repeated
 manual invokes.
 1.2 The HTTP Protocol
 HTTP is the protocol used to fetch data from web servers. It is a very simple
 protocol that is built upon TCP/IP. The protocol also allows information to
 get sent to the server from the client using a few different methods, as will
 be shown here.
 HTTP is plain ASCII text lines being sent by the client to a server to
 request a particular action, and then the server replies a few text lines
 before the actual requested content is sent to the client.
 The client, curl, sends a HTTP request. The request contains a method (like
 GET, POST, HEAD etc), a number of request headers and sometimes a request
 body. The HTTP server responds with a status line (indicating if things went
 well), response headers and most often also a response body. The "body" part
 is the plain data you requested, like the actual HTML or the image etc.
 1.3 See the Protocol
  Using curl's option --verbose (-v as a short option) will display what kind
  of commands curl sends to the server, as well as a few other informational
  texts.
  --verbose is the single most useful option when it comes to debug or even
  understand the curl<->server interaction.
  Sometimes even --verbose is not enough. Then --trace and --trace-ascii offer
  even more details as they show EVERYTHING curl sends and receives. Use it
  like this:
      curl --trace-ascii debugdump.txt http://www.example.com/
 1.4 See the Timing
  Many times you may wonder what exactly is taking all the time, or you just
  want to know the amount of milliseconds between two points in a
  transfer. For those, and other similar situations, the --trace-time option
  is what you need. It'll prepend the time to each trace output line:
      curl --trace-ascii d.txt --trace-time http://example.com/
 1.5 See the Response
  By default curl sends the response to stdout. You need to redirect it
  somewhere to avoid that, most often that is done with -o or -O.
2. URL
 2.1 Spec
 The Uniform Resource Locator format is how you specify the address of a
 particular resource on the Internet. You know these, you've seen URLs like
 https://curl.haxx.se or https://yourbank.com a million times. RFC 3986 is the
 canonical spec. And yeah, the formal name is not URL, it is URI.
 2.2 Host
 The host name is usually resolved using DNS or your /etc/hosts file to an IP
 address and that's what curl will communicate with. Alternatively you specify
 the IP address directly in the URL instead of a name.
 For development and other trying out situations, you can point to a different
 IP address for a host name than what would otherwise be used, by using curl's
 --resolve option:
      curl --resolve www.example.org:80:127.0.0.1 http://www.example.org/
 2.3 Port number
 Each protocol curl supports operates on a default port number, be it over TCP
 or in some cases UDP. Normally you don't have to take that into
 consideration, but at times you run test servers on other ports or
 similar. Then you can specify the port number in the URL with a colon and a
 number immediately following the host name. Like when doing HTTP to port
 1234:
      curl http://www.example.org:1234/
 The port number you specify in the URL is the number that the server uses to
 offer its services. Sometimes you may use a local proxy, and then you may
 need to specify that proxy's port number separately for what curl needs to
 connect to locally. Like when using a HTTP proxy on port 4321:
      curl --proxy http://proxy.example.org:4321 http://remote.example.org/
 2.4 User name and password
 Some services are setup to require HTTP authentication and then you need to
 provide name and password which is then transferred to the remote site in
 various ways depending on the exact authentication protocol used.
 You can opt to either insert the user and password in the URL or you can
 provide them separately:
      curl http://user:password@example.org/
      curl -u user:password http://example.org/
 You need to pay attention that this kind of HTTP authentication is not what
 is usually done and requested by user-oriented web sites these days. They
 tend to use forms and cookies instead.
 2.5 Path part
 The path part is just sent off to the server to request that it sends back
 the associated response. The path is what is to the right side of the slash
 that follows the host name and possibly port number.
3. Fetch a page
 3.1 GET
 The simplest and most common request/operation made using HTTP is to GET a
 URL. The URL could itself refer to a web page, an image or a file. The client
 issues a GET request to the server and receives the document it asked for.
 If you issue the command line
        curl https://curl.haxx.se
 you get a web page returned in your terminal window. The entire HTML document
 that that URL holds.
 All HTTP replies contain a set of response headers that are normally hidden,
 use curl's --include (-i) option to display them as well as the rest of the
 document.
 3.2 HEAD
 You can ask the remote server for ONLY the headers by using the --head (-I)
 option which will make curl issue a HEAD request. In some special cases
 servers deny the HEAD method while others still work, which is a particular
 kind of annoyance.
 The HEAD method is defined and made so that the server returns the headers
 exactly the way it would do for a GET, but without a body. It means that you
 may see a Content-Length: in the response headers, but there must not be an
 actual body in the HEAD response.
 3.3 Multiple URLs in a single command line
 A single curl command line may involve one or many URLs. The most common case
 is probably to just use one, but you can specify any amount of URLs. Yes
 any. No limits. You'll then get requests repeated over and over for all the
 given URLs.
 Example, send two GETs:
    curl http://url1.example.com http://url2.example.com
 If you use --data to POST to the URL, using multiple URLs means that you send
 that same POST to all the given URLs.
 Example, send two POSTs:
    curl --data name=curl http://url1.example.com http://url2.example.com
 3.4 Multiple HTTP methods in a single command line
 Sometimes you need to operate on several URLs in a single command line and do
 different HTTP methods on each. For this, you'll enjoy the --next option. It
 is basically a separator that separates a bunch of options from the next. All
 the URLs before --next will get the same method and will get all the POST
 data merged into one.
 When curl reaches the --next on the command line, it'll sort of reset the
 method and the POST data and allow a new set.
 Perhaps this is best shown with a few examples. To send first a HEAD and then
 a GET:
   curl -I http://example.com --next http://example.com
 To first send a POST and then a GET:
   curl -d score=10 http://example.com/post.cgi --next http://example.com/results.html
4. HTML forms
 4.1 Forms explained
 Forms are the general way a web site can present a HTML page with fields for
 the user to enter data in, and then press some kind of 'OK' or 'Submit'
 button to get that data sent to the server. The server then typically uses
 the posted data to decide how to act. Like using the entered words to search
 in a database, or to add the info in a bug tracking system, display the entered
 address on a map or using the info as a login-prompt verifying that the user
 is allowed to see what it is about to see.
 Of course there has to be some kind of program on the server end to receive
 the data you send. You cannot just invent something out of the air.
 4.2 GET
  A GET-form uses the method GET, as specified in HTML like:
        <form method="GET" action="junk.cgi">
          <input type=text name="birthyear">
          <input type=submit name=press value="OK">
        </form>
  In your favorite browser, this form will appear with a text box to fill in
  and a press-button labeled "OK". If you fill in '1905' and press the OK
  button, your browser will then create a new URL to get for you. The URL will
  get "junk.cgi?birthyear=1905&press=OK" appended to the path part of the
  previous URL.
  If the original form was seen on the page "www.hotmail.com/when/birth.html",
  the second page you'll get will become
  "www.hotmail.com/when/junk.cgi?birthyear=1905&press=OK".
  Most search engines work this way.
  To make curl do the GET form post for you, just enter the expected created
  URL:
        curl "http://www.hotmail.com/when/junk.cgi?birthyear=1905&press=OK"
 4.3 POST
  The GET method makes all input field names get displayed in the URL field of
  your browser. That's generally a good thing when you want to be able to
  bookmark that page with your given data, but it is an obvious disadvantage
  if you entered secret information in one of the fields or if there are a
  large amount of fields creating a very long and unreadable URL.
  The HTTP protocol then offers the POST method. This way the client sends the
  data separated from the URL and thus you won't see any of it in the URL
  address field.
  The form would look very similar to the previous one:
        <form method="POST" action="junk.cgi">
          <input type=text name="birthyear">
          <input type=submit name=press value=" OK ">
        </form>
  And to use curl to post this form with the same data filled in as before, we
  could do it like:
        curl --data "birthyear=1905&press=%20OK%20" \
        http://www.example.com/when.cgi
  This kind of POST will use the Content-Type
  application/x-www-form-urlencoded and is the most widely used POST kind.
  The data you send to the server MUST already be properly encoded, curl will
  not do that for you. For example, if you want the data to contain a space,
  you need to replace that space with %20 etc. Failing to comply with this
  will most likely cause your data to be received wrongly and messed up.
  Recent curl versions can in fact url-encode POST data for you, like this:
        curl --data-urlencode "name=I am Daniel" http://www.example.com
  If you repeat --data several times on the command line, curl will
  concatenate all the given data pieces - and put a '&' symbol between each
  data segment.
 4.4 File Upload POST
  Back in late 1995 they defined an additional way to post data over HTTP. It
  is documented in the RFC 1867, why this method sometimes is referred to as
  RFC1867-posting.
  This method is mainly designed to better support file uploads. A form that
  allows a user to upload a file could be written like this in HTML:
    <form method="POST" enctype='multipart/form-data' action="upload.cgi">
      <input type=file name=upload>
      <input type=submit name=press value="OK">
    </form>
  This clearly shows that the Content-Type about to be sent is
  multipart/form-data.
  To post to a form like this with curl, you enter a command line like:
        curl --form upload=@localfilename --form press=OK [URL]
 4.5 Hidden Fields
  A very common way for HTML based applications to pass state information
  between pages is to add hidden fields to the forms. Hidden fields are
  already filled in, they aren't displayed to the user and they get passed
  along just as all the other fields.
  A similar example form with one visible field, one hidden field and one
  submit button could look like:
    <form method="POST" action="foobar.cgi">
      <input type=text name="birthyear">
      <input type=hidden name="person" value="daniel">
      <input type=submit name="press" value="OK">
    </form>
  To POST this with curl, you won't have to think about if the fields are
  hidden or not. To curl they're all the same:
        curl --data "birthyear=1905&press=OK&person=daniel" [URL]
 4.6 Figure Out What A POST Looks Like
  When you're about fill in a form and send to a server by using curl instead
  of a browser, you're of course very interested in sending a POST exactly the
  way your browser does.
  An easy way to get to see this, is to save the HTML page with the form on
  your local disk, modify the 'method' to a GET, and press the submit button
  (you could also change the action URL if you want to).
  You will then clearly see the data get appended to the URL, separated with a
  '?'-letter as GET forms are supposed to.
5. HTTP upload
 5.1 PUT
 Perhaps the best way to upload data to a HTTP server is to use PUT. Then
 again, this of course requires that someone put a program or script on the
 server end that knows how to receive a HTTP PUT stream.
 Put a file to a HTTP server with curl:
        curl --upload-file uploadfile http://www.example.com/receive.cgi
6. HTTP Authentication
 6.1 Basic Authentication
 HTTP Authentication is the ability to tell the server your username and
 password so that it can verify that you're allowed to do the request you're
 doing. The Basic authentication used in HTTP (which is the type curl uses by
 default) is *plain* *text* based, which means it sends username and password
 only slightly obfuscated, but still fully readable by anyone that sniffs on
 the network between you and the remote server.
 To tell curl to use a user and password for authentication:
        curl --user name:password http://www.example.com
 6.2 Other Authentication
 The site might require a different authentication method (check the headers
 returned by the server), and then --ntlm, --digest, --negotiate or even
 --anyauth might be options that suit you.
 6.3 Proxy Authentication
 Sometimes your HTTP access is only available through the use of a HTTP
 proxy. This seems to be especially common at various companies. A HTTP proxy
 may require its own user and password to allow the client to get through to
 the Internet. To specify those with curl, run something like:
        curl --proxy-user proxyuser:proxypassword curl.haxx.se
 If your proxy requires the authentication to be done using the NTLM method,
 use --proxy-ntlm, if it requires Digest use --proxy-digest.
 If you use any one of these user+password options but leave out the password
 part, curl will prompt for the password interactively.
 6.4 Hiding credentials
 Do note that when a program is run, its parameters might be possible to see
 when listing the running processes of the system. Thus, other users may be
 able to watch your passwords if you pass them as plain command line
 options. There are ways to circumvent this.
 It is worth noting that while this is how HTTP Authentication works, very
 many web sites will not use this concept when they provide logins etc. See
 the Web Login chapter further below for more details on that.
7. More HTTP Headers
 7.1 Referer
 A HTTP request may include a 'referer' field (yes it is misspelled), which
 can be used to tell from which URL the client got to this particular
 resource. Some programs/scripts check the referer field of requests to verify
 that this wasn't arriving from an external site or an unknown page. While
 this is a stupid way to check something so easily forged, many scripts still
 do it. Using curl, you can put anything you want in the referer-field and
 thus more easily be able to fool the server into serving your request.
 Use curl to set the referer field with:
        curl --referer http://www.example.come http://www.example.com
 7.2 User Agent
 Very similar to the referer field, all HTTP requests may set the User-Agent
 field. It names what user agent (client) that is being used. Many
 applications use this information to decide how to display pages. Silly web
 programmers try to make different pages for users of different browsers to
 make them look the best possible for their particular browsers. They usually
 also do different kinds of javascript, vbscript etc.
 At times, you will see that getting a page with curl will not return the same
 page that you see when getting the page with your browser. Then you know it
 is time to set the User Agent field to fool the server into thinking you're
 one of those browsers.
 To make curl look like Internet Explorer 5 on a Windows 2000 box:
  curl --user-agent "Mozilla/4.0 (compatible; MSIE 5.01; Windows NT 5.0)" [URL]
 Or why not look like you're using Netscape 4.73 on an old Linux box:
  curl --user-agent "Mozilla/4.73 [en] (X11; U; Linux 2.2.15 i686)" [URL]
8. Redirects
 8.1 Location header
 When a resource is requested from a server, the reply from the server may
 include a hint about where the browser should go next to find this page, or a
 new page keeping newly generated output. The header that tells the browser
 to redirect is Location:.
 Curl does not follow Location: headers by default, but will simply display
 such pages in the same manner it displays all HTTP replies. It does however
 feature an option that will make it attempt to follow the Location: pointers.
 To tell curl to follow a Location:
        curl --location http://www.example.com
 If you use curl to POST to a site that immediately redirects you to another
 page, you can safely use --location (-L) and --data/--form together. Curl will
 only use POST in the first request, and then revert to GET in the following
 operations.
 8.2 Other redirects
 Browser typically support at least two other ways of redirects that curl
 doesn't: first the html may contain a meta refresh tag that asks the browser
 to load a specific URL after a set number of seconds, or it may use
 javascript to do it.
9. Cookies
 9.1 Cookie Basics
 The way the web browsers do "client side state control" is by using
 cookies. Cookies are just names with associated contents. The cookies are
 sent to the client by the server. The server tells the client for what path
 and host name it wants the cookie sent back, and it also sends an expiration
 date and a few more properties.
 When a client communicates with a server with a name and path as previously
 specified in a received cookie, the client sends back the cookies and their
 contents to the server, unless of course they are expired.
 Many applications and servers use this method to connect a series of requests
 into a single logical session. To be able to use curl in such occasions, we
 must be able to record and send back cookies the way the web application
 expects them. The same way browsers deal with them.
 9.2 Cookie options
 The simplest way to send a few cookies to the server when getting a page with
 curl is to add them on the command line like:
        curl --cookie "name=Daniel" http://www.example.com
 Cookies are sent as common HTTP headers. This is practical as it allows curl
 to record cookies simply by recording headers. Record cookies with curl by
 using the --dump-header (-D) option like:
        curl --dump-header headers_and_cookies http://www.example.com
 (Take note that the --cookie-jar option described below is a better way to
 store cookies.)
 Curl has a full blown cookie parsing engine built-in that comes in use if you
 want to reconnect to a server and use cookies that were stored from a
 previous connection (or hand-crafted manually to fool the server into
 believing you had a previous connection). To use previously stored cookies,
 you run curl like:
        curl --cookie stored_cookies_in_file http://www.example.com
 Curl's "cookie engine" gets enabled when you use the --cookie option. If you
 only want curl to understand received cookies, use --cookie with a file that
 doesn't exist. Example, if you want to let curl understand cookies from a
 page and follow a location (and thus possibly send back cookies it received),
 you can invoke it like:
        curl --cookie nada --location http://www.example.com
 Curl has the ability to read and write cookie files that use the same file
 format that Netscape and Mozilla once used. It is a convenient way to share
 cookies between scripts or invokes. The --cookie (-b) switch automatically
 detects if a given file is such a cookie file and parses it, and by using the
 --cookie-jar (-c) option you'll make curl write a new cookie file at the end
 of an operation:
        curl --cookie cookies.txt --cookie-jar newcookies.txt \
        http://www.example.com
10. HTTPS
 10.1 HTTPS is HTTP secure
 There are a few ways to do secure HTTP transfers. By far the most common
 protocol for doing this is what is generally known as HTTPS, HTTP over
 SSL. SSL encrypts all the data that is sent and received over the network and
 thus makes it harder for attackers to spy on sensitive information.
 SSL (or TLS as the latest version of the standard is called) offers a
 truckload of advanced features to allow all those encryptions and key
 infrastructure mechanisms encrypted HTTP requires.
 Curl supports encrypted fetches when built to use a TLS library and it can be
 built to use one out of a fairly large set of libraries - "curl -V" will show
 which one your curl was built to use (if any!). To get a page from a HTTPS
 server, simply run curl like:
        curl https://secure.example.com
 10.2 Certificates
  In the HTTPS world, you use certificates to validate that you are the one
  you claim to be, as an addition to normal passwords. Curl supports client-
  side certificates. All certificates are locked with a pass phrase, which you
  need to enter before the certificate can be used by curl. The pass phrase
  can be specified on the command line or if not, entered interactively when
  curl queries for it. Use a certificate with curl on a HTTPS server like:
        curl --cert mycert.pem https://secure.example.com
  curl also tries to verify that the server is who it claims to be, by
  verifying the server's certificate against a locally stored CA cert
  bundle. Failing the verification will cause curl to deny the connection. You
  must then use --insecure (-k) in case you want to tell curl to ignore that
  the server can't be verified.
  More about server certificate verification and ca cert bundles can be read
  in the SSLCERTS document, available online here:
        https://curl.haxx.se/docs/sslcerts.html
  At times you may end up with your own CA cert store and then you can tell
  curl to use that to verify the server's certificate:
        curl --cacert ca-bundle.pem https://example.com/
11. Custom Request Elements
11.1 Modify method and headers
 Doing fancy stuff, you may need to add or change elements of a single curl
 request.
 For example, you can change the POST request to a PROPFIND and send the data
 as "Content-Type: text/xml" (instead of the default Content-Type) like this:
         curl --data "<xml>" --header "Content-Type: text/xml" \
              --request PROPFIND url.com
 You can delete a default header by providing one without content. Like you
 can ruin the request by chopping off the Host: header:
        curl --header "Host:" http://www.example.com
 You can add headers the same way. Your server may want a "Destination:"
 header, and you can add it:
        curl --header "Destination: http://nowhere" http://example.com
 11.2 More on changed methods
 It should be noted that curl selects which methods to use on its own
 depending on what action to ask for. -d will do POST, -I will do HEAD and so
 on. If you use the --request / -X option you can change the method keyword
 curl selects, but you will not modify curl's behavior. This means that if you
 for example use -d "data" to do a POST, you can modify the method to a
 PROPFIND with -X and curl will still think it sends a POST. You can change
 the normal GET to a POST method by simply adding -X POST in a command line
 like:
        curl -X POST http://example.org/
 ... but curl will still think and act as if it sent a GET so it won't send any
 request body etc.
12. Web Login
 12.1 Some login tricks
 While not strictly just HTTP related, it still causes a lot of people problems
 so here's the executive run-down of how the vast majority of all login forms
 work and how to login to them using curl.
 It can also be noted that to do this properly in an automated fashion, you
 will most certainly need to script things and do multiple curl invokes etc.
 First, servers mostly use cookies to track the logged-in status of the
 client, so you will need to capture the cookies you receive in the
 responses. Then, many sites also set a special cookie on the login page (to
 make sure you got there through their login page) so you should make a habit
 of first getting the login-form page to capture the cookies set there.
 Some web-based login systems feature various amounts of javascript, and
 sometimes they use such code to set or modify cookie contents. Possibly they
 do that to prevent programmed logins, like this manual describes how to...
 Anyway, if reading the code isn't enough to let you repeat the behavior
 manually, capturing the HTTP requests done by your browsers and analyzing the
 sent cookies is usually a working method to work out how to shortcut the
 javascript need.
 In the actual <form> tag for the login, lots of sites fill-in random/session
 or otherwise secretly generated hidden tags and you may need to first capture
 the HTML code for the login form and extract all the hidden fields to be able
 to do a proper login POST. Remember that the contents need to be URL encoded
 when sent in a normal POST.
13. Debug
 13.1 Some debug tricks
 Many times when you run curl on a site, you'll notice that the site doesn't
 seem to respond the same way to your curl requests as it does to your
 browser's.
 Then you need to start making your curl requests more similar to your
 browser's requests:
 * Use the --trace-ascii option to store fully detailed logs of the requests
 for easier analyzing and better understanding
 * Make sure you check for and use cookies when needed (both reading with
 --cookie and writing with --cookie-jar)
 * Set user-agent to one like a recent popular browser does
 * Set referer like it is set by the browser
 * If you use POST, make sure you send all the fields and in the same order as
 the browser does it.
 A very good helper to make sure you do this right, is the LiveHTTPHeader tool
 that lets you view all headers you send and receive with Mozilla/Firefox
 (even when using HTTPS). Chrome features similar functionality out of the box
 among the developer's tools.
 A more raw approach is to capture the HTTP traffic on the network with tools
 such as ethereal or tcpdump and check what headers that were sent and
 received by the browser. (HTTPS makes this technique inefficient.)
14. References
 14.1 Standards
 RFC 7230 is a must to read if you want in-depth understanding of the HTTP
 protocol
 RFC 3986 explains the URL syntax
 RFC 1867 defines the HTTP post upload format
 RFC 6525 defines how HTTP cookies work
 14.2 Sites
 https://curl.haxx.se is the home of the curl project
                                  _   _ ____  _
                              ___| | | |  _ \| |
                             / __| | | | |_) | |
                            | (__| |_| |  _ <| |___
                             \___|\___/|_| \_\_____|
                Things that could be nice to do in the future
 Things to do in project curl. Please tell us what you think, contribute and
 send us patches that improve things!
 Be aware that these are things that we could do, or have once been considered
 things we could do. If you want to work on any of these areas, please
 consider bringing it up for discussions first on the mailing list so that we
 all agree it is still a good idea for the project!
 All bugs documented in the KNOWN_BUGS document are subject for fixing!
 1. libcurl
 1.2 More data sharing
 1.3 struct lifreq
 1.4 signal-based resolver timeouts
 1.5 get rid of PATH_MAX
 1.6 Modified buffer size approach
 1.7 Support HTTP/2 for HTTP(S) proxies
 1.8 CURLOPT_RESOLVE for any port number
 1.9 Cache negative name resolves
 1.10 auto-detect proxy
 1.11 minimize dependencies with dynamically loaded modules
 1.12 updated DNS server while running
 1.13 DNS-over-HTTPS
 1.14 Typesafe curl_easy_setopt()
 1.15 Monitor connections in the connection pool
 1.16 Try to URL encode given URL
 1.17 Add support for IRIs
 1.18 try next proxy if one doesn't work
 1.19 Timeout idle connections from the pool
 1.20 SRV and URI DNS records
 1.21 API for URL parsing/splitting
 1.22 CURLINFO_PAUSE_STATE
 1.23 Offer API to flush the connection pool
 1.24 TCP Fast Open for windows
 1.25 Expose tried IP addresses that failed
 1.26 CURL_REFUSE_CLEARTEXT
 1.27 hardcode the "localhost" addresses
 1.28 FD_CLOEXEC
 2. libcurl - multi interface
 2.1 More non-blocking
 2.2 Better support for same name resolves
 2.3 Non-blocking curl_multi_remove_handle()
 2.4 Split connect and authentication process
 2.5 Edge-triggered sockets should work
 3. Documentation
 3.2 Provide cmake config-file
 4. FTP
 4.1 HOST
 4.2 Alter passive/active on failure and retry
 4.3 Earlier bad letter detection
 4.4 REST for large files
 4.5 ASCII support
 4.6 GSSAPI via Windows SSPI
 4.7 STAT for LIST without data connection
 4.8 Option to ignore private IP addresses in PASV response
 5. HTTP
 5.1 Better persistency for HTTP 1.0
 5.2 support FF3 sqlite cookie files
 5.3 Rearrange request header order
 5.5 auth= in URLs
 5.6 Refuse "downgrade" redirects
 5.7 QUIC
 5.8 Leave secure cookies alone
 6. TELNET
 6.1 ditch stdin
 6.2 ditch telnet-specific select
 6.3 feature negotiation debug data
 7. SMTP
 7.1 Pipelining
 7.2 Enhanced capability support
 7.3 Add CURLOPT_MAIL_CLIENT option
 8. POP3
 8.1 Pipelining
 8.2 Enhanced capability support
 9. IMAP
 9.1 Enhanced capability support
 10. LDAP
 10.1 SASL based authentication mechanisms
 11. SMB
 11.1 File listing support
 11.2 Honor file timestamps
 11.3 Use NTLMv2
 11.4 Create remote directories
 12. New protocols
 12.1 RSYNC
 13. SSL
 13.1 Disable specific versions
 13.2 Provide mutex locking API
 13.3 Support in-memory certs/ca certs/keys
 13.4 Cache/share OpenSSL contexts
 13.5 Export session ids
 13.6 Provide callback for cert verification
 13.7 improve configure --with-ssl
 13.8 Support DANE
 13.9 Configurable loading of OpenSSL configuration file
 13.10 Support Authority Information Access certificate extension (AIA)
 13.11 Support intermediate & root pinning for PINNEDPUBLICKEY
 13.12 Support HSTS
 13.13 Support HPKP
 13.14 Support the clienthello extension
 14. GnuTLS
 14.1 SSL engine stuff
 14.2 check connection
 15. WinSSL/SChannel
 15.1 Add support for client certificate authentication
 15.3 Add support for the --ciphers option
 16. SASL
 16.1 Other authentication mechanisms
 16.2 Add QOP support to GSSAPI authentication
 16.3 Support binary messages (i.e.: non-base64)
 17. SSH protocols
 17.1 Multiplexing
 17.2 SFTP performance
 17.3 Support better than MD5 hostkey hash
 17.4 Support CURLOPT_PREQUOTE
 18. Command line tool
 18.1 sync
 18.2 glob posts
 18.3 prevent file overwriting
 18.4 simultaneous parallel transfers
 18.5 UTF-8 filenames in Content-Disposition
 18.6 warning when setting an option
 18.7 warning if curl version is not in sync with libcurl version
 18.8 offer color-coded HTTP header output
 18.9 Choose the name of file in braces for complex URLs
 18.10 improve how curl works in a windows console window
 18.11 -w output to stderr
 18.12 keep running, read instructions from pipe/socket
 18.13 support metalink in http headers
 18.14 --fail without --location should treat 3xx as a failure
 18.15 --retry should resume
 18.16 send only part of --data
 18.17 consider file name from the redirected URL with -O ?
 18.18 retry on network is unreachable
 18.19 expand ~/ in config files
 18.20 host name sections in config files
 19. Build
 19.1 roffit
 19.2 Enable PIE and RELRO by default
 20. Test suite
 20.1 SSL tunnel
 20.2 nicer lacking perl message
 20.3 more protocols supported
 20.4 more platforms supported
 20.5 Add support for concurrent connections
 20.6 Use the RFC6265 test suite
 21. Next SONAME bump
 21.1 http-style HEAD output for FTP
 21.2 combine error codes
 21.3 extend CURLOPT_SOCKOPTFUNCTION prototype
 22. Next major release
 22.1 cleanup return codes
 22.2 remove obsolete defines
 22.3 size_t
 22.4 remove several functions
 22.5 remove CURLOPT_FAILONERROR
 22.6 remove CURLOPT_DNS_USE_GLOBAL_CACHE
 22.7 remove progress meter from libcurl
 22.8 remove 'curl_httppost' from public
==============================================================================
1. libcurl
1.2 More data sharing
 curl_share_* functions already exist and work, and they can be extended to
 share more. For example, enable sharing of the ares channel.
1.3 struct lifreq
 Use 'struct lifreq' and SIOCGLIFADDR instead of 'struct ifreq' and
 SIOCGIFADDR on newer Solaris versions as they claim the latter is obsolete.
 To support IPv6 interface addresses for network interfaces properly.
1.4 signal-based resolver timeouts
 libcurl built without an asynchronous resolver library uses alarm() to time
 out DNS lookups. When a timeout occurs, this causes libcurl to jump from the
 signal handler back into the library with a sigsetjmp, which effectively
 causes libcurl to continue running within the signal handler. This is
 non-portable and could cause problems on some platforms. A discussion on the
 problem is available at https://curl.haxx.se/mail/lib-2008-09/0197.html
 Also, alarm() provides timeout resolution only to the nearest second. alarm
 ought to be replaced by setitimer on systems that support it.
1.5 get rid of PATH_MAX
 Having code use and rely on PATH_MAX is not nice:
 https://insanecoding.blogspot.com/2007/11/pathmax-simply-isnt.html
 Currently the SSH based code uses it a bit, but to remove PATH_MAX from there
 we need libssh2 to properly tell us when we pass in a too small buffer and
 its current API (as of libssh2 1.2.7) doesn't.
1.6 Modified buffer size approach
 Current libcurl allocates a fixed 16K size buffer for download and an
 additional 16K for upload. They are always unconditionally part of the easy
 handle. If CRLF translations are requested, an additional 32K "scratch
 buffer" is allocated. A total of 64K transfer buffers in the worst case.
 First, while the handles are not actually in use these buffers could be freed
 so that lingering handles just kept in queues or whatever waste less memory.
 Secondly, SFTP is a protocol that needs to handle many ~30K blocks at once
 since each need to be individually acked and therefore libssh2 must be
 allowed to send (or receive) many separate ones in parallel to achieve high
 transfer speeds. A current libcurl build with a 16K buffer makes that
 impossible, but one with a 512K buffer will reach MUCH faster transfers. But
 allocating 512K unconditionally for all buffers just in case they would like
 to do fast SFTP transfers at some point is not a good solution either.
 Dynamically allocate buffer size depending on protocol in use in combination
 with freeing it after each individual transfer? Other suggestions?
1.7 Support HTTP/2 for HTTP(S) proxies
 Support for doing HTTP/2 to HTTP and HTTPS proxies is still missing.
1.8 CURLOPT_RESOLVE for any port number
 This option allows applications to set a replacement IP address for a given
 host + port pair. Consider making support for providing a replacement address
 for the host name on all port numbers.
 See https://github.com/curl/curl/issues/1264
1.9 Cache negative name resolves
 A name resolve that has failed is likely to fail when made again within a
 short period of time. Currently we only cache positive responses.
1.10 auto-detect proxy
 libcurl could be made to detect the system proxy setup automatically and use
 that. On Windows, macOS and Linux desktops for example.
 The pull-request to use libproxy for this was deferred due to doubts on the
 reliability of the dependency and how to use it:
 https://github.com/curl/curl/pull/977
 libdetectproxy is a (C++) library for detecting the proxy on Windows
 https://github.com/paulharris/libdetectproxy
1.11 minimize dependencies with dynamically loaded modules
 We can create a system with loadable modules/plug-ins, where these modules
 would be the ones that link to 3rd party libs. That would allow us to avoid
 having to load ALL dependencies since only the necessary ones for this
 app/invoke/used protocols would be necessary to load.  See
 https://github.com/curl/curl/issues/349
1.12 updated DNS server while running
 If /etc/resolv.conf gets updated while a program using libcurl is running, it
 is may cause name resolves to fail unless res_init() is called. We should
 consider calling res_init() + retry once unconditionally on all name resolve
 failures to mitigate against this. Firefox works like that. Note that Windows
 doesn't have res_init() or an alternative.
 https://github.com/curl/curl/issues/2251
1.13 DNS-over-HTTPS
 By adding support for DNS-over-HTTPS curl could resolve host names using a
 totally separate name server than the standard system resolver, while at the
 same time doing so over a communication channel that enhances privacy and
 security.
 https://github.com/curl/curl/wiki/DNS-over-HTTPS
1.14 Typesafe curl_easy_setopt()
 One of the most common problems in libcurl using applications is the lack of
 type checks for curl_easy_setopt() which happens because it accepts varargs
 and thus can take any type.
 One possible solution to this is to introduce a few different versions of the
 setopt version for the different kinds of data you can set.
  curl_easy_set_num() - sets a long value
  curl_easy_set_large() - sets a curl_off_t value
  curl_easy_set_ptr() - sets a pointer
  curl_easy_set_cb() - sets a callback PLUS its callback data
1.15 Monitor connections in the connection pool
 libcurl's connection cache or pool holds a number of open connections for the
 purpose of possible subsequent connection reuse. It may contain a few up to a
 significant amount of connections. Currently, libcurl leaves all connections
 as they are and first when a connection is iterated over for matching or
 reuse purpose it is verified that it is still alive.
 Those connections may get closed by the server side for idleness or they may
 get a HTTP/2 ping from the peer to verify that they're still alive. By adding
 monitoring of the connections while in the pool, libcurl can detect dead
 connections (and close them) better and earlier, and it can handle HTTP/2
 pings to keep such ones alive even when not actively doing transfers on them.
1.16 Try to URL encode given URL
 Given a URL that for example contains spaces, libcurl could have an option
 that would try somewhat harder than it does now and convert spaces to %20 and
 perhaps URL encoded byte values over 128 etc (basically do what the redirect
 following code already does).
 https://github.com/curl/curl/issues/514
1.17 Add support for IRIs
 IRIs (RFC 3987) allow localized, non-ascii, names in the URL. To properly
 support this, curl/libcurl would need to translate/encode the given input
 from the input string encoding into percent encoded output "over the wire".
 To make that work smoothly for curl users even on Windows, curl would
 probably need to be able to convert from several input encodings.
1.18 try next proxy if one doesn't work
 Allow an application to specify a list of proxies to try, and failing to
 connect to the first go on and try the next instead until the list is
 exhausted. Browsers support this feature at least when they specify proxies
 using PACs.
 https://github.com/curl/curl/issues/896
1.19 Timeout idle connections from the pool
 libcurl currently keeps connections in its connection pool for an indefinite
 period of time, until it either gets reused, gets noticed that it has been
 closed by the server or gets pruned to make room for a new connection.
 To reduce overhead (especially for when we add monitoring of the connections
 in the pool), we should introduce a timeout so that connections that have
 been idle for N seconds get closed.
1.20 SRV and URI DNS records
 Offer support for resolving SRV and URI DNS records for libcurl to know which
 server to connect to for various protocols (including HTTP!).
1.21 API for URL parsing/splitting
 libcurl has always parsed URLs internally and never exposed any API or
 features to allow applications to do it. Still most or many applications
 using libcurl need that ability. In polls to users, we've learned that many
 libcurl users would like to see and use such an API.
1.22 CURLINFO_PAUSE_STATE
 Return information about the transfer's current pause state, in both
 directions. https://github.com/curl/curl/issues/2588
1.23 Offer API to flush the connection pool
 Sometimes applications want to flush all the existing connections kept alive.
 An API could allow a forced flush or just a forced loop that would properly
 close all connections that have been closed by the server already.
1.24 TCP Fast Open for windows
 libcurl supports the CURLOPT_TCP_FASTOPEN option since 7.49.0 for Linux and
 Mac OS. Windows supports TCP Fast Open starting with Windows 10, version 1607
 and we should add support for it.
1.25 Expose tried IP addresses that failed
 When libcurl fails to connect to a host, it should be able to offer the
 application the list of IP addresses that were used in the attempt.
 https://github.com/curl/curl/issues/2126
1.26 CURL_REFUSE_CLEARTEXT
 An environment variable that when set will make libcurl refuse to use any
 cleartext network protocol. That's all non-encrypted ones (FTP, HTTP, Gopher,
 etc). By adding the check to libcurl and not just curl, this environment
 variable can then help users to block all libcurl-using programs from
 accessing the network using unsafe protocols.
 The variable could be given some sort of syntax or different levels and be
 used to also allow for example users to refuse libcurl to do transfers with
 HTTPS certificate checks disabled.
 It could also offer to refuse usernames in URLs (see TODO 1.1)
1.27 hardcode the "localhost" addresses
 There's this new spec getting adopted that says "localhost" should always and
 unconditionally be a local address and not get resolved by a DNS server. A
 fine way for curl to fix this would be to simply hard-code the response to
 127.0.0.1 and/or ::1 (depending on what IP versions that are requested). This
 is what the browsers probably will do with this hostname.
 https://bugzilla.mozilla.org/show_bug.cgi?id=1220810
 https://tools.ietf.org/html/draft-ietf-dnsop-let-localhost-be-localhost-02
1.28 FD_CLOEXEC
 It sets the close-on-exec flag for the file descriptor, which causes the file
 descriptor to be automatically (and atomically) closed when any of the
 exec-family functions succeed. Should probably be set by default?
 https://github.com/curl/curl/issues/2252
2. libcurl - multi interface
2.1 More non-blocking
 Make sure we don't ever loop because of non-blocking sockets returning
 EWOULDBLOCK or similar. Blocking cases include:
 - Name resolves on non-windows unless c-ares or the threaded resolver is used
 - SOCKS proxy handshakes
 - file:// transfers
 - TELNET transfers
 - The "DONE" operation (post transfer protocol-specific actions) for the
   protocols SFTP, SMTP, FTP. Fixing Curl_done() for this is a worthy task.
2.2 Better support for same name resolves
 If a name resolve has been initiated for name NN and a second easy handle
 wants to resolve that name as well, make it wait for the first resolve to end
 up in the cache instead of doing a second separate resolve. This is
 especially needed when adding many simultaneous handles using the same host
 name when the DNS resolver can get flooded.
2.3 Non-blocking curl_multi_remove_handle()
 The multi interface has a few API calls that assume a blocking behavior, like
 add_handle() and remove_handle() which limits what we can do internally. The
 multi API need to be moved even more into a single function that "drives"
 everything in a non-blocking manner and signals when something is done. A
 remove or add would then only ask for the action to get started and then
 multi_perform() etc still be called until the add/remove is completed.
2.4 Split connect and authentication process
 The multi interface treats the authentication process as part of the connect
 phase. As such any failures during authentication won't trigger the relevant
 QUIT or LOGOFF for protocols such as IMAP, POP3 and SMTP.
2.5 Edge-triggered sockets should work
 The multi_socket API should work with edge-triggered socket events. One of
 the internal actions that need to be improved for this to work perfectly is
 the 'maxloops' handling in transfer.c:readwrite_data().
3. Documentation
3.2 Provide cmake config-file
 A config-file package is a set of files provided by us to allow applications
 to write cmake scripts to find and use libcurl easier. See
 https://github.com/curl/curl/issues/885
4. FTP
4.1 HOST
 HOST is a command for a client to tell which host name to use, to offer FTP
 servers named-based virtual hosting:
 https://tools.ietf.org/html/rfc7151
4.2 Alter passive/active on failure and retry
 When trying to connect passively to a server which only supports active
 connections, libcurl returns CURLE_FTP_WEIRD_PASV_REPLY and closes the
 connection. There could be a way to fallback to an active connection (and
 vice versa). https://curl.haxx.se/bug/feature.cgi?id=1754793
4.3 Earlier bad letter detection
 Make the detection of (bad) %0d and %0a codes in FTP URL parts earlier in the
 process to avoid doing a resolve and connect in vain.
4.4 REST for large files
 REST fix for servers not behaving well on >2GB requests. This should fail if
 the server doesn't set the pointer to the requested index. The tricky
 (impossible?) part is to figure out if the server did the right thing or not.
4.5 ASCII support
 FTP ASCII transfers do not follow RFC959. They don't convert the data
 accordingly.
4.6 GSSAPI via Windows SSPI
 In addition to currently supporting the SASL GSSAPI mechanism (Kerberos V5)
 via third-party GSS-API libraries, such as Heimdal or MIT Kerberos, also add
 support for GSSAPI authentication via Windows SSPI.
4.7 STAT for LIST without data connection
 Some FTP servers allow STAT for listing directories instead of using LIST,
 and the response is then sent over the control connection instead of as the
 otherwise usedw data connection: http://www.nsftools.com/tips/RawFTP.htm#STAT
 This is not detailed in any FTP specification.
4.8 Option to ignore private IP addresses in PASV response
 Some servers respond with and some other FTP client implementations can
 ignore private (RFC 1918 style) IP addresses when received in PASV responses.
 To consider for libcurl as well. See https://github.com/curl/curl/issues/1455
5. HTTP
5.1 Better persistency for HTTP 1.0
 "Better" support for persistent connections over HTTP 1.0
 https://curl.haxx.se/bug/feature.cgi?id=1089001
5.2 support FF3 sqlite cookie files
 Firefox 3 is changing from its former format to a a sqlite database instead.
 We should consider how (lib)curl can/should support this.
 https://curl.haxx.se/bug/feature.cgi?id=1871388
5.3 Rearrange request header order
 Server implementors often make an effort to detect browser and to reject
 clients it can detect to not match. One of the last details we cannot yet
 control in libcurl's HTTP requests, which also can be exploited to detect
 that libcurl is in fact used even when it tries to impersonate a browser, is
 the order of the request headers. I propose that we introduce a new option in
 which you give headers a value, and then when the HTTP request is built it
 sorts the headers based on that number. We could then have internally created
 headers use a default value so only headers that need to be moved have to be
 specified.
5.5 auth= in URLs
 Add the ability to specify the preferred authentication mechanism to use by
 using ;auth=<mech> in the login part of the URL.
 For example:
 http://test:pass;auth=NTLM@example.com would be equivalent to specifying --user
 test:pass;auth=NTLM or --user test:pass --ntlm from the command line.
 Additionally this should be implemented for proxy base URLs as well.
5.6 Refuse "downgrade" redirects
 See https://github.com/curl/curl/issues/226
 Consider a way to tell curl to refuse to "downgrade" protocol with a redirect
 and/or possibly a bit that refuses redirect to change protocol completely.
5.7 QUIC
 The standardization process of QUIC has been taken to the IETF and can be
 followed on the [IETF QUIC Mailing
 list](https://www.ietf.org/mailman/listinfo/quic). I'd like us to get on the
 bandwagon. Ideally, this would be done with a separate library/project to
 handle the binary/framing layer in a similar fashion to how HTTP/2 is
 implemented. This, to allow other projects to benefit from the work and to
 thus broaden the interest and chance of others to participate.
5.8 Leave secure cookies alone
 Non-secure origins (HTTP sites) should not be allowed to set or modify
 cookies with the 'secure' property:
 https://tools.ietf.org/html/draft-ietf-httpbis-cookie-alone-01
6. TELNET
6.1 ditch stdin
Reading input (to send to the remote server) on stdin is a crappy solution for
library purposes. We need to invent a good way for the application to be able
to provide the data to send.
6.2 ditch telnet-specific select
 Move the telnet support's network select() loop go away and merge the code
 into the main transfer loop. Until this is done, the multi interface won't
 work for telnet.
6.3 feature negotiation debug data
  Add telnet feature negotiation data to the debug callback as header data.
7. SMTP
7.1 Pipelining
 Add support for pipelining emails.
7.2 Enhanced capability support
 Add the ability, for an application that uses libcurl, to obtain the list of
 capabilities returned from the EHLO command.
7.3 Add CURLOPT_MAIL_CLIENT option
 Rather than use the URL to specify the mail client string to present in the
 HELO and EHLO commands, libcurl should support a new CURLOPT specifically for
 specifying this data as the URL is non-standard and to be honest a bit of a
 hack ;-)
 Please see the following thread for more information:
 https://curl.haxx.se/mail/lib-2012-05/0178.html
8. POP3
8.1 Pipelining
 Add support for pipelining commands.
8.2 Enhanced capability support
 Add the ability, for an application that uses libcurl, to obtain the list of
 capabilities returned from the CAPA command.
9. IMAP
9.1 Enhanced capability support
 Add the ability, for an application that uses libcurl, to obtain the list of
 capabilities returned from the CAPABILITY command.
10. LDAP
10.1 SASL based authentication mechanisms
 Currently the LDAP module only supports ldap_simple_bind_s() in order to bind
 to an LDAP server. However, this function sends username and password details
 using the simple authentication mechanism (as clear text). However, it should
 be possible to use ldap_bind_s() instead specifying the security context
 information ourselves.
11. SMB
11.1 File listing support
Add support for listing the contents of a SMB share. The output should probably
be the same as/similar to FTP.
11.2 Honor file timestamps
The timestamp of the transferred file should reflect that of the original file.
11.3 Use NTLMv2
Currently the SMB authentication uses NTLMv1.
11.4 Create remote directories
Support for creating remote directories when uploading a file to a directory
that doesn't exist on the server, just like --ftp-create-dirs.
12. New protocols
12.1 RSYNC
 There's no RFC for the protocol or an URI/URL format.  An implementation
 should most probably use an existing rsync library, such as librsync.
13. SSL
13.1 Disable specific versions
 Provide an option that allows for disabling specific SSL versions, such as
 SSLv2 https://curl.haxx.se/bug/feature.cgi?id=1767276
13.2 Provide mutex locking API
 Provide a libcurl API for setting mutex callbacks in the underlying SSL
 library, so that the same application code can use mutex-locking
 independently of OpenSSL or GnutTLS being used.
13.3 Support in-memory certs/ca certs/keys
 You can specify the private and public keys for SSH/SSL as file paths. Some
 programs want to avoid using files and instead just pass them as in-memory
 data blobs. There's probably a challenge to make this work across the
 plethory of different TLS and SSH backends that curl supports.
 https://github.com/curl/curl/issues/2310
13.4 Cache/share OpenSSL contexts
 "Look at SSL cafile - quick traces look to me like these are done on every
 request as well, when they should only be necessary once per SSL context (or
 once per handle)". The major improvement we can rather easily do is to make
 sure we don't create and kill a new SSL "context" for every request, but
 instead make one for every connection and re-use that SSL context in the same
 style connections are re-used. It will make us use slightly more memory but
 it will libcurl do less creations and deletions of SSL contexts.
 Technically, the "caching" is probably best implemented by getting added to
 the share interface so that easy handles who want to and can reuse the
 context specify that by sharing with the right properties set.
 https://github.com/curl/curl/issues/1110
13.5 Export session ids
 Add an interface to libcurl that enables "session IDs" to get
 exported/imported. Cris Bailiff said: "OpenSSL has functions which can
 serialise the current SSL state to a buffer of your choice, and recover/reset
 the state from such a buffer at a later date - this is used by mod_ssl for
 apache to implement and SSL session ID cache".
13.6 Provide callback for cert verification
 OpenSSL supports a callback for customised verification of the peer
 certificate, but this doesn't seem to be exposed in the libcurl APIs. Could
 it be? There's so much that could be done if it were!
13.7 improve configure --with-ssl
 make the configure --with-ssl option first check for OpenSSL, then GnuTLS,
 then NSS...
13.8 Support DANE
 DNS-Based Authentication of Named Entities (DANE) is a way to provide SSL
 keys and certs over DNS using DNSSEC as an alternative to the CA model.
 https://www.rfc-editor.org/rfc/rfc6698.txt
 An initial patch was posted by Suresh Krishnaswamy on March 7th 2013
 (https://curl.haxx.se/mail/lib-2013-03/0075.html) but it was a too simple
 approach. See Daniel's comments:
 https://curl.haxx.se/mail/lib-2013-03/0103.html . libunbound may be the
 correct library to base this development on.
rn Stenberg wrote a separate initial take on DANE that was never
 completed.
13.9 Configurable loading of OpenSSL configuration file
 libcurl calls the OpenSSL function CONF_modules_load_file() in openssl.c,
 Curl_ossl_init(). "We regard any changes in the OpenSSL configuration as a
 security risk or at least as unnecessary."
 Please add a configuration switch or something similar to disable the
 CONF_modules_load_file() call.
 See https://github.com/curl/curl/issues/2724
13.10 Support Authority Information Access certificate extension (AIA)
 AIA can provide various things like CRLs but more importantly information
 about intermediate CA certificates that can allow validation path to be
 fullfilled when the HTTPS server doesn't itself provide them.
 Since AIA is about downloading certs on demand to complete a TLS handshake,
 it is probably a bit tricky to get done right.
 See https://github.com/curl/curl/issues/2793
13.11 Support intermediate & root pinning for PINNEDPUBLICKEY
 CURLOPT_PINNEDPUBLICKEY does not consider the hashes of intermediate & root
 certificates when comparing the pinned keys. Therefore it is not compatible
 with "HTTP Public Key Pinning" as there also intermediate and root certificates
 can be pinned. This is very useful as it prevents webadmins from "locking
 themself out of their servers".
 Adding this feature would make curls pinning 100% compatible to HPKP and allow
 more flexible pinning.
13.12 Support HSTS
 "HTTP Strict Transport Security" is TOFU (trust on first use), time-based
 features indicated by a HTTP header send by the webserver. It is widely used
 in browsers and it's purpose is to prevent insecure HTTP connections after
 a previous HTTPS connection. It protects against SSLStripping attacks.
 Doc: https://developer.mozilla.org/en-US/docs/Web/Security/HTTP_strict_transport_security
 RFC 6797: https://tools.ietf.org/html/rfc6797
13.13 Support HPKP
 "HTTP Public Key Pinning" is TOFU (trust on first use), time-based
 features indicated by a HTTP header send by the webserver. It's purpose is
 to prevent Man-in-the-middle attacks by trusted CAs by allowing webadmins
 to specify which CAs/certificates/public keys to trust when connection to
 their websites.
 It can be build based on PINNEDPUBLICKEY.
 Wikipedia: https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning
 OWASP: https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning
 Doc: https://developer.mozilla.org/de/docs/Web/Security/Public_Key_Pinning
 RFC: https://tools.ietf.org/html/draft-ietf-websec-key-pinning-21
13.14 Support the clienthello extension
 Certain stupid networks and middle boxes have a problem with SSL handshake
 pakets that are within a certain size range because how that sets some bits
 that previously (in older TLS version) were not set. The clienthello
 extension adds padding to avoid that size range.
 https://tools.ietf.org/html/rfc7685
 https://github.com/curl/curl/issues/2299
14. GnuTLS
14.1 SSL engine stuff
 Is this even possible?
14.2 check connection
 Add a way to check if the connection seems to be alive, to correspond to the
 SSL_peak() way we use with OpenSSL.
15. WinSSL/SChannel
15.1 Add support for client certificate authentication
 WinSSL/SChannel currently makes use of the OS-level system and user
 certificate and private key stores. This does not allow the application
 or the user to supply a custom client certificate using curl or libcurl.
 Therefore support for the existing -E/--cert and --key options should be
 implemented by supplying a custom certificate to the SChannel APIs, see:
 - Getting a Certificate for Schannel
   https://msdn.microsoft.com/en-us/library/windows/desktop/aa375447.aspx
15.3 Add support for the --ciphers option
 The cipher suites used by WinSSL/SChannel are configured on an OS-level
 instead of an application-level. This does not allow the application or
 the user to customize the configured cipher suites using curl or libcurl.
 Therefore support for the existing --ciphers option should be implemented
 by mapping the OpenSSL/GnuTLS cipher suites to the SChannel APIs, see
 - Specifying Schannel Ciphers and Cipher Strengths
   https://msdn.microsoft.com/en-us/library/windows/desktop/aa380161.aspx
16. SASL
16.1 Other authentication mechanisms
 Add support for other authentication mechanisms such as OLP,
 GSS-SPNEGO and others.
16.2 Add QOP support to GSSAPI authentication
 Currently the GSSAPI authentication only supports the default QOP of auth
 (Authentication), whilst Kerberos V5 supports both auth-int (Authentication
 with integrity protection) and auth-conf (Authentication with integrity and
 privacy protection).
16.3 Support binary messages (i.e.: non-base64)
  Mandatory to support LDAP SASL authentication.
17. SSH protocols
17.1 Multiplexing
 SSH is a perfectly fine multiplexed protocols which would allow libcurl to do
 multiple parallel transfers from the same host using the same connection,
 much in the same spirit as HTTP/2 does. libcurl however does not take
 advantage of that ability but will instead always create a new connection for
 new transfers even if an existing connection already exists to the host.
 To fix this, libcurl would have to detect an existing connection and "attach"
 the new transfer to the existing one.
17.2 SFTP performance
 libcurl's SFTP transfer performance is sub par and can be improved, mostly by
 the approach mentioned in "1.6 Modified buffer size approach".
17.3 Support better than MD5 hostkey hash
 libcurl offers the CURLOPT_SSH_HOST_PUBLIC_KEY_MD5 option for verifying the
 server's key. MD5 is generally being deprecated so we should implement
 support for stronger hashing algorithms. libssh2 itself is what provides this
 underlying functionality and it supports at least SHA-1 as an alternative.
 SHA-1 is also being deprecated these days so we should consider workign with
 libssh2 to instead offer support for SHA-256 or similar.
17.4 Support CURLOPT_PREQUOTE
 The two other QUOTE options are supported for SFTP, but this was left out for
 unknown reasons!
18. Command line tool
18.1 sync
 "curl --sync http://example.com/feed[1-100].rss" or
 "curl --sync http://example.net/{index,calendar,history}.html"
 Downloads a range or set of URLs using the remote name, but only if the
 remote file is newer than the local file. A Last-Modified HTTP date header
 should also be used to set the mod date on the downloaded file.
18.2 glob posts
 Globbing support for -d and -F, as in 'curl -d "name=foo[0-9]" URL'.
 This is easily scripted though.
18.3 prevent file overwriting
 Add an option that prevents curl from overwriting existing local files. When
 used, and there already is an existing file with the target file name
 (either -O or -o), a number should be appended (and increased if already
 existing). So that index.html becomes first index.html.1 and then
 index.html.2 etc.
18.4 simultaneous parallel transfers
 The client could be told to use maximum N simultaneous parallel transfers and
 then just make sure that happens. It should of course not make more than one
 connection to the same remote host. This would require the client to use the
 multi interface. https://curl.haxx.se/bug/feature.cgi?id=1558595
 Using the multi interface would also allow properly using parallel transfers
 with HTTP/2 and supporting HTTP/2 server push from the command line.
18.5 UTF-8 filenames in Content-Disposition
 RFC 6266 documents how UTF-8 names can be passed to a client in the
 Content-Disposition header, and curl does not support this.
 https://github.com/curl/curl/issues/1888
18.6 warning when setting an option
 Display a warning when libcurl returns an error when setting an option.
 This can be useful to tell when support for a particular feature hasn't been
 compiled into the library.
18.7 warning if curl version is not in sync with libcurl version
 This is usually a sign of a funny, weird or unexpected install situations
 that aren't always quickly nor easily detected by users. curl and libcurl are
 always released in sync and should use the same version numbers unless very
 special situations.
18.8 offer color-coded HTTP header output
 By offering different color output on the header name and the header
 contents, they could be made more readable and thus help users working on
 HTTP services.
18.9 Choose the name of file in braces for complex URLs
 When using braces to download a list of URLs and you use complicated names
 in the list of alternatives, it could be handy to allow curl to use other
 names when saving.
 Consider a way to offer that. Possibly like
 {partURL1:name1,partURL2:name2,partURL3:name3} where the name following the
 colon is the output name.
 See https://github.com/curl/curl/issues/221
18.10 improve how curl works in a windows console window
 If you pull the scrollbar when transferring with curl in a Windows console
 window, the transfer is interrupted and can get disconnected. This can
 probably be improved. See https://github.com/curl/curl/issues/322
18.11 -w output to stderr
 -w is quite useful, but not to those of us who use curl without -o or -O
 (such as for scripting through a higher level language). It would be nice to
 have an option that is exactly like -w but sends it to stderr
 instead. Proposed name: --write-stderr. See
 https://github.com/curl/curl/issues/613
18.12 keep running, read instructions from pipe/socket
 Provide an option that makes curl not exit after the last URL (or even work
 without a given URL), and then make it read instructions passed on a pipe or
 over a socket to make further instructions so that a second subsequent curl
 invoke can talk to the still running instance and ask for transfers to get
 done, and thus maintain its connection pool, DNS cache and more.
18.13 support metalink in http headers
 Curl has support for downloading a metalink xml file, processing it, and then
 downloading the target of the metalink. This is done via the --metalink option.
 It would be nice if metalink also supported downloading via metalink
 information that is stored in HTTP headers (RFC 6249). Theoretically this could
 also be supported with the --metalink option.
 See https://tools.ietf.org/html/rfc6249
 See also https://lists.gnu.org/archive/html/bug-wget/2015-06/msg00034.html for
 an implematation of this in wget.
18.14 --fail without --location should treat 3xx as a failure
 To allow a command line like this to detect a redirect and consider it a
 failure:
    curl -v --fail -O https://example.com/curl-7.48.0.tar.gz
 ... --fail must treat 3xx responses as failures too. The least problematic
 way to implement this is probably to add that new logic in the command line
 tool only and not in the underlying CURLOPT_FAILONERROR logic.
18.15 --retry should resume
 When --retry is used and curl actually retries transfer, it should use the
 already transferred data and do a resumed transfer for the rest (when
 possible) so that it doesn't have to transfer the same data again that was
 already transferred before the retry.
 See https://github.com/curl/curl/issues/1084
18.16 send only part of --data
 When the user only wants to send a small piece of the data provided with
 --data or --data-binary, like when that data is a huge file, consider a way
 to specify that curl should only send a piece of that. One suggested syntax
 would be: "--data-binary @largefile.zip!1073741823-2147483647".
 See https://github.com/curl/curl/issues/1200
18.17 consider file name from the redirected URL with -O ?
 When a user gives a URL and uses -O, and curl follows a redirect to a new
 URL, the file name is not extracted and used from the newly redirected-to URL
 even if the new URL may have a much more sensible file name.
 This is clearly documented and helps for security since there's no surprise
 to users which file name that might get overwritten. But maybe a new option
 could allow for this or maybe -J should imply such a treatment as well as -J
 already allows for the server to decide what file name to use so it already
 provides the "may overwrite any file" risk.
 This is extra tricky if the original URL has no file name part at all since
 then the current code path will error out with an error message, and we can't
 *know* already at that point if curl will be redirected to a URL that has a
 file name...
 See https://github.com/curl/curl/issues/1241
18.18 retry on network is unreachable
 The --retry option retries transfers on "transient failures". We later added
 --retry-connrefused to also retry for "connection refused" errors.
 Suggestions have been brought to also allow retry on "network is unreachable"
 errors and while totally reasonable, maybe we should consider a way to make
 this more configurable than to add a new option for every new error people
 want to retry for?
 https://github.com/curl/curl/issues/1603
18.19 expand ~/ in config files
 For example .curlrc could benefit from being able to do this.
 See https://github.com/curl/curl/issues/2317
18.20 host name sections in config files
 config files would be more powerful if they could set different
 configurations depending on used URLs, host name or possibly origin. Then a
 default .curlrc could a specific user-agent only when doing requests against
 a certain site.
19. Build
19.1 roffit
 Consider extending 'roffit' to produce decent ASCII output, and use that
 instead of (g)nroff when building src/tool_hugehelp.c
19.2 Enable PIE and RELRO by default
 Especially when having programs that execute curl via the command line, PIE
 renders the exploitation of memory corruption vulnerabilities a lot more
 difficult. This can be attributed to the additional information leaks being
 required to conduct a successful attack. RELRO, on the other hand, masks
 different binary sections like the GOT as read-only and thus kills a handful
 of techniques that come in handy when attackers are able to arbitrarily
 overwrite memory. A few tests showed that enabling these features had close
 to no impact, neither on the performance nor on the general functionality of
 curl.
20. Test suite
20.1 SSL tunnel
 Make our own version of stunnel for simple port forwarding to enable HTTPS
 and FTP-SSL tests without the stunnel dependency, and it could allow us to
 provide test tools built with either OpenSSL or GnuTLS
20.2 nicer lacking perl message
 If perl wasn't found by the configure script, don't attempt to run the tests
 but explain something nice why it doesn't.
20.3 more protocols supported
 Extend the test suite to include more protocols. The telnet could just do FTP
 or http operations (for which we have test servers).
20.4 more platforms supported
 Make the test suite work on more platforms. OpenBSD and Mac OS. Remove
 fork()s and it should become even more portable.
20.5 Add support for concurrent connections
 Tests 836, 882 and 938 were designed to verify that separate connections aren't
 used when using different login credentials in protocols that shouldn't re-use
 a connection under such circumstances.
 Unfortunately, ftpserver.pl doesn't appear to support multiple concurrent
 connections. The read while() loop seems to loop until it receives a disconnect
 from the client, where it then enters the waiting for connections loop. When
 the client opens a second connection to the server, the first connection hasn't
 been dropped (unless it has been forced - which we shouldn't do in these tests)
 and thus the wait for connections loop is never entered to receive the second
 connection.
20.6 Use the RFC6265 test suite
 A test suite made for HTTP cookies (RFC 6265) by Adam Barth is available at
 https://github.com/abarth/http-state/tree/master/tests
 It'd be really awesome if someone would write a script/setup that would run
 curl with that test suite and detect deviances. Ideally, that would even be
 incorporated into our regular test suite.
21. Next SONAME bump
21.1 http-style HEAD output for FTP
 #undef CURL_FTP_HTTPSTYLE_HEAD in lib/ftp.c to remove the HTTP-style headers
 from being output in NOBODY requests over FTP
21.2 combine error codes
 Combine some of the error codes to remove duplicates.  The original
 numbering should not be changed, and the old identifiers would be
 macroed to the new ones in an CURL_NO_OLDIES section to help with
 backward compatibility.
 Candidates for removal and their replacements:
    CURLE_FILE_COULDNT_READ_FILE => CURLE_REMOTE_FILE_NOT_FOUND
    CURLE_FTP_COULDNT_RETR_FILE => CURLE_REMOTE_FILE_NOT_FOUND
    CURLE_FTP_COULDNT_USE_REST => CURLE_RANGE_ERROR
    CURLE_FUNCTION_NOT_FOUND => CURLE_FAILED_INIT
    CURLE_LDAP_INVALID_URL => CURLE_URL_MALFORMAT
    CURLE_TFTP_NOSUCHUSER => CURLE_TFTP_ILLEGAL
    CURLE_TFTP_NOTFOUND => CURLE_REMOTE_FILE_NOT_FOUND
    CURLE_TFTP_PERM => CURLE_REMOTE_ACCESS_DENIED
21.3 extend CURLOPT_SOCKOPTFUNCTION prototype
 The current prototype only provides 'purpose' that tells what the
 connection/socket is for, but not any protocol or similar. It makes it hard
 for applications to differentiate on TCP vs UDP and even HTTP vs FTP and
 similar.
22. Next major release
22.1 cleanup return codes
 curl_easy_cleanup() returns void, but curl_multi_cleanup() returns a
 CURLMcode. These should be changed to be the same.
22.2 remove obsolete defines
 remove obsolete defines from curl/curl.h
22.3 size_t
 make several functions use size_t instead of int in their APIs
22.4 remove several functions
 remove the following functions from the public API:
 curl_getenv
 curl_mprintf (and variations)
 curl_strequal
 curl_strnequal
 They will instead become curlx_ - alternatives. That makes the curl app
 still capable of using them, by building with them from source.
 These functions have no purpose anymore:
 curl_multi_socket
 curl_multi_socket_all
22.5 remove CURLOPT_FAILONERROR
 Remove support for CURLOPT_FAILONERROR, it has gotten too kludgy and weird
 internally. Let the app judge success or not for itself.
22.6 remove CURLOPT_DNS_USE_GLOBAL_CACHE
 Remove support for a global DNS cache. Anything global is silly, and we
 already offer the share interface for the same functionality but done
 "right".
22.7 remove progress meter from libcurl
 The internally provided progress meter output doesn't belong in the library.
 Basically no application wants it (apart from curl) but instead applications
 can and should do their own progress meters using the progress callback.
 The progress callback should then be bumped as well to get proper 64bit
 variable types passed to it instead of doubles so that big files work
 correctly.
22.8 remove 'curl_httppost' from public
 curl_formadd() was made to fill in a public struct, but the fact that the
 struct is public is never really used by application for their own advantage
 but instead often restricts how the form functions can or can't be modified.
 Changing them to return a private handle will benefit the implementation and
 allow us much greater freedoms while still maintaining a solid API and ABI.
X6jsoK
qimg
cLoTc
RKUa
TY`Uj
P}<<
LajM
%moS
VUYC 	
w>To
7iO*
:]"B
ZB'v'
x#8IK
$?6B
#~7s{;
)F-}["
&>HZ
NSS5nm
 @3	
Gz3p
y?DR
YcN-
+@/%^Y
_eLZ"
!x(i
HI6U
J8:m[fN
0H6	
+hGI
~4,<'
}Lj`
8Gpq!0#
T0CR"q
f8#RZ;
 d$!<
id]Q
(?oY
hdI1L
ey%')a>'
9>gZ
>zOx
)D]B/k
8@>M
Tm#f@
4Q@)
tBcB
M)c3
SbQ\V
cS0=
c.sE
_3!:
UOlz
J$T+1\#Z;
Y%<3
eI7Pf
hd:t/
W)W	9
r%$~
Bt}x4
W2x#
)`}4
)}8;
Qydi
\\W<
 l>m
 +!9
@I13
d	hT
Pm'P
>/G%`
$c z7
!9@Y
'Q2U
{	qJ
4u|s_S
N%@M}
q]clM-QI
ssM|j
<5}L
J/G3?/
H9~	
+`#5E
_]iF
q;q7
{7ka
%u7j
"qGJ
tN&(C
_9n@
]w3p
$Sr3
L#(9	
7if$
Jrb#
f+ij
Tn5l+
brI)K
tSD>
SVUu
8)3=c
_d{7
)T1U
bp	L
lt9/^
+M||%
 ?/>
('7r
0h2Cd4
7	D4qH$}L
,$Okn
}7hs2Q	
qFvqSD
Q6?-
D6?EC#
5/K2#
7H	M
oF#p
boTl
CLFZ
3`B#R
;ILkd
mb8f
"2fz
I*3Bm
NeZE
6K"Jm
@"tb
A]PX
$fd1
p,uE
>GYZ
Nw<{
2{A4
%#m9N
	KDN
|_k*
&u\'
EdhsccQ
i>B7
9?igR
p&~=B
RpI 
pH-3
$`|2
!9 Y#
gD%i
FCoI
|(0\
^.`%
;3!T
\~]Hi
wHX{P
~i~7
}&+'
b\A~
gvIy`\
4gL+
Z4.e
*L"<
4x-	
4_+* "
;/3y
qOp1
0/ '#
ykBL
}< zW
U}7"A
3m&N
R7|-
6Jil
T_Cjg
+b2Q
#!$M
T*	o
N|%9
|[(vP
dZgZ
\|/e
Y<p:
U5.-
hpaj
#BKG
%G,y-t
tr\xe{
d39/
bYIJ
f$Y^#W
-	1A
eog^
c~,Q
V;zQ
i!iqqR]
B {QX
t5HL
AG3H3	
Y^I>6g
N4es.
4.)K
2oP%P
:>ao
.ir{
LB6S
5RClG|?
h&/d
FdUg
Z*eRO]Zc
8?:<}
TmmP
&TCp
t  r+
P.;d.Wqx
 8W.
GCC9m.
T<S2^
Q~e/
2""	
0R`I
U* J
'x*lE
}~_7
/WM:
1C)}
~XeP
{[s>`
JEM~
ZYS17
JYKY
kdI.
D"m.s
$xAJV
&Yt-y
6SJJ%
)<)Tq!
Ed&j
QeWr
ca<)
:_ig
tFB,
FB[0v]
!"me=
HTF6
Y@>F4
ZJnw
r#?f3J
?(uB{F
^n,@,
scv$
gPT V
N\!$
4nRt
/y6b
Iq&/
+hNh
w"72
/-&TtK
oKj[`>
6oww)Y
K`n]
Jla@
oyw#i
z2/i
lo5Sp
ep$v
;XcX
m]!z
WY5	
rM I^
X__[
H-Z9
CX@x0$
X*!n
|t/Fv
JrM=
3cpm
>yC\
pho!
9'fL
Jk2Z
gTyH
LYf$
v7XS
D2J'
N8W'
2%7$
?Da>q|
(L3$
$V;9+W
ZB$|pr
!=yQ
K[4ppV
:r&	R
X.Mc]
NK/3
(x=/	^?
 xMr
E fA
73T]u
H(Cj
v|l-
#R%1q
J>6$^
j%Ui
'C\<
IUWW
|-9j
&AD[T
0uTY`
gU*Lr
U@Q 
o3@M&^
,h$^
xg+2
\n4XN)
&;o6
CO|0r
d%?~
?yFT
8hiG/
,0~J
h*srqK
ygMvR
,iv=
RQSM
%oy}j/
x4se
v+~&
A:%*Fp
5Z7e7O
OusF"
!]\i$
Hc\J
DqDo
<3-Le:s\
N]G>
o2t4
fw[*.
i<XLU'E
a3m~
%VG3
+JA9
q1L'[
z*yW
>#WW
HG@Kf5
0za"
PA}N
Ctbd
dx[ 
F+-O,
AD;R
tD(P
Y7~/
_N'\
<=?Jq
4MhgMC
9%&bW
(52j
?;0$
A*SSM
s`d9|
.R]L
V~ 4
[RdA
\G|5
6ua7
|5)P
Pw?J
]Rf~
Rz$TkV0
bNO'
&?md
Q)@#NF
[x/8
~No4
S l8J
5*o|
#<X!
?DMs
OkAJG7[=
L_\nOg	
Guk"
	B_q
F*xB
S65rF58k8
KpF1
'j(T
wM/TrS
h-V^
#&:@
#]9d
1P:DXj
UW",
.Isv
Pm`a
PdA^
J/6'
 ~ta
a'*y
D>{B	
/s0s$
tdN)
tS6X
9ZEY
,^$6
Xm]	
8>Mv
Zter
cNgC*
f/82*
viz0y
	+d:@R
tjyx
iThE
.oM'
)W!uq
_cu6!
~G4b
x-F	
x~{t@
thH8\
E^\c
{xDTS;
P;XY[
s)d@H
t`nQ
Mc`Y
0bzh
KEZ#
tYT2
i5$/`r
QN2m
d0X&
P	Y;(
Vuz9
KyYz
n(g<#
ywsk--
UpIJ
*b$+J
mflk
lwcw
O}/h
qmyvcp
nKM)m6
{pR`
T3dF+=
y3p92j
Q1%=
uusc
9n;:h
t T&
36Q^2!S
)Lt1
>o!A
BWG)
vFLB?
e>WK
3IJ>
"gFJ4U
P)U]
vfd&
#)H$
vB;W
&O{1B
q:o~;
N({Q
Wg'Go
&|2U*
{@J  
mO}5
uF-?84
-^S 
eWl	
'-sq
N\>X
Bi9\+
0Q&+=
1wVp"
mYa|$
X{hr2
Ir6~
_d$I
eY%'
yk)g
HW3F
ZTHA
@c.J
NZV*
,k1)
UNe%
44.2
UE_]
;M`2
L:*n
'RE:.
OFRp
O)y-
XssaCG]
Dg8&-
E9'"
d4(bu
@/0&e
TQ|I
	zIr
Q/	n
/%.5
i",oBR
vVF&Q(
QYc/
"N<<2w
";<}
qMtAZ
$1>k&
^r%^
2}xM
qP9+R
$1Th
i7{U
'd-j
_*qV uB
cCUhA
8f2k
H`JU
D;LNqJ
+c(}
r4+p
(=>9
AM#Ri
P	?@|
\*nl
A9t$VX
81gR
?H#[.
n5w3*
'g{w
qh^\
A@*6
/D0?!/
O7Te
~/|p
Fc1j
736T
h!#`R
Yp< 
g&c{
'-Gd
#compdef curl
# curl zsh completion
local curcontext="$curcontext" state state_descr line
typeset -A opt_args
local rc=1
_arguments -C -S \
  --happy-eyeballs-timeout-ms'[How long to wait in milliseconds for IPv6 before trying IPv4]':'<milliseconds>' \
  {-c,--cookie-jar}'[Write cookies to <filename> after operation]':'<filename>':_files \
  {-D,--dump-header}'[Write the received headers to <filename>]':'<filename>':_files \
  {-y,--speed-time}'[Trigger '\''speed-limit'\'' abort after this time]':'<seconds>' \
  --proxy-cacert'[CA certificate to verify peer against for proxy]':'<file>':_files \
  --tls13-ciphers'[of TLS 1.3 ciphersuites> TLS 1.3 cipher suites to use]':'<list' \
  {-E,--cert}'[Client certificate file and password]':'<certificate[:password]>' \
  --libcurl'[Dump libcurl equivalent code of this command line]':'<file>':_files \
  --proxy-capath'[CA directory to verify peer against for proxy]':'<dir>':_files \
  --proxy-negotiate'[HTTP Negotiate (SPNEGO) authentication on the proxy]':'Use' \
  --proxy-pinnedpubkey'[FILE/HASHES public key to verify proxy with]':'<hashes>' \
  --crlfile'[Get a CRL list in PEM format from the given file]':'<file>':_files \
  --proxy-insecure'[HTTPS proxy connections without verifying the proxy]':'Do' \
  --proxy-ssl-allow-beast'[security flaw for interop for HTTPS proxy]':'Allow' \
  --abstract-unix-socket'[Connect via abstract Unix domain socket]':'<path>' \
  --pinnedpubkey'[FILE/HASHES Public key to verify peer against]':'<hashes>' \
  --proxy-pass'[Pass phrase for the private key for HTTPS proxy]':'<phrase>' \
  {-p,--proxytunnel}'[Operate through an HTTP proxy tunnel (using CONNECT)]' \
  --socks5-hostname'[SOCKS5 proxy, pass host name to proxy]':'<host[:port]>' \
  --proto-default'[Use PROTOCOL for any URL missing a scheme]':'<protocol>' \
  --proxy-tls13-ciphers'[list> TLS 1.3 proxy cipher suites]':'<ciphersuite' \
  --socks5-gssapi-service'[SOCKS5 proxy service name for GSS-API]':'<name>' \
  --ftp-alternative-to-user'[String to replace USER \[name\]]':'<command>' \
  --ftp-ssl-control'[SSL/TLS for FTP login, clear for transfer]':'Require' \
  {-T,--upload-file}'[Transfer local FILE to destination]':'<file>':_files \
  --local-port'[Force use of RANGE for local port numbers]':'<num/range>' \
  --proxy-tlsauthtype'[TLS authentication type for HTTPS proxy]':'<type>' \
  {-R,--remote-time}'[Set the remote file'\''s time on the local output]' \
  --retry-connrefused'[on connection refused (use with --retry)]':'Retry' \
  --suppress-connect-headers'[proxy CONNECT response headers]':'Suppress' \
  {-j,--junk-session-cookies}'[session cookies read from file]':'Ignore' \
  --location-trusted'[--location, and send auth to other hosts]':'Like' \
  --proxy-cert-type'[Client certificate type for HTTPS proxy]':'<type>' \
  {-O,--remote-name}'[Write output to a file named as the remote file]' \
  --trace-ascii'[Like --trace, but without hex output]':'<file>':_files \
  --connect-timeout'[Maximum time allowed for connection]':'<seconds>' \
  --expect100-timeout'[How long to wait for 100-continue]':'<seconds>' \
  {-g,--globoff}'[Disable URL sequences and ranges using {} and \[\]]' \
  {-m,--max-time}'[Maximum time allowed for the transfer]':'<seconds>' \
  --dns-ipv4-addr'[IPv4 address to use for DNS requests]':'<address>' \
  --dns-ipv6-addr'[IPv6 address to use for DNS requests]':'<address>' \
  --ignore-content-length'[the size of the remote resource]':'Ignore' \
  {-k,--insecure}'[Allow insecure server connections when using SSL]' \
  --mail-auth'[Originator address of the original email]':'<address>' \
  --noproxy'[List of hosts which do not use proxy]':'<no-proxy-list>' \
  --proto-redir'[Enable/disable PROTOCOLS on redirect]':'<protocols>' \
  --dns-interface'[Interface to use for DNS requests]':'<interface>' \
  --hostpubmd5'[Acceptable MD5 hash of the host public key]':'<md5>' \
  --keepalive-time'[Interval time for keepalive probes]':'<seconds>' \
  --proxy-cert'[Set client certificate for proxy]':'<cert[:passwd]>' \
  --random-file'[File for reading random data from]':'<file>':_files \
  --socks5-basic'[Enable username/password auth for SOCKS5 proxies]' \
  --cacert'[CA certificate to verify peer against]':'<file>':_files \
  {-H,--header}'[Pass custom header(s) to server]':'<header/@file>' \
  {-i,--include}'[Include protocol response headers in the output]' \
  --proxy-header'[Pass custom header(s) to proxy]':'<header/@file>' \
  --unix-socket'[Connect through this Unix domain socket]':'<path>' \
  {-w,--write-out}'[Use output FORMAT after completion]':'<format>' \
  --http2-prior-knowledge'[HTTP 2 without HTTP/1.1 Upgrade]':'Use' \
  {-o,--output}'[Write to file instead of stdout]':'<file>':_files \
  {-J,--remote-header-name}'[the header-provided filename]':'Use' \
  --socks4a'[SOCKS4a proxy on given host + port]':'<host[:port]>' \
  {-Y,--speed-limit}'[Stop transfers slower than this]':'<speed>' \
  {-z,--time-cond}'[Transfer based on a time condition]':'<time>' \
  --capath'[CA directory to verify peer against]':'<dir>':_files \
  {-f,--fail}'[Fail silently (no output at all) on HTTP errors]' \
  --proxy-tlspassword'[TLS password for HTTPS proxy]':'<string>' \
  {-U,--proxy-user}'[Proxy user and password]':'<user:password>' \
  --proxy1.0'[Use HTTP/1.0 proxy on given port]':'<host[:port]>' \
  {-r,--range}'[Retrieve only the bytes within RANGE]':'<range>' \
  {-A,--user-agent}'[Send User-Agent <name> to server]':'<name>' \
  --egd-file'[EGD socket path for random data]':'<file>':_files \
  --fail-early'[Fail on first transfer error, do not continue]' \
  --haproxy-protocol'[HAProxy PROXY protocol v1 header]':'Send' \
  --preproxy'[Use this proxy first]':'[protocol://]host[:port]' \
  --retry-max-time'[Retry only within this period]':'<seconds>' \
  --socks4'[SOCKS4 proxy on given host + port]':'<host[:port]>' \
  --socks5'[SOCKS5 proxy on given host + port]':'<host[:port]>' \
  --socks5-gssapi-nec'[with NEC SOCKS5 server]':'Compatibility' \
  --ssl-allow-beast'[security flaw to improve interop]':'Allow' \
  --cert-status'[Verify the status of the server certificate]' \
  --ftp-create-dirs'[the remote dirs if not present]':'Create' \
  {-:,--next}'[Make next URL use its separate set of options]' \
  --proxy-key-type'[Private key file type for proxy]':'<type>' \
  --remote-name-all'[the remote file name for all URLs]':'Use' \
  {-X,--request}'[Specify request command to use]':'<command>' \
  --retry'[Retry request if transient problems occur]':'<num>' \
  --ssl-no-revoke'[cert revocation checks (WinSSL)]':'Disable' \
  --cert-type'[Certificate file type (DER/PEM/ENG)]':'<type>' \
  --connect-to'[Connect to host]':'<HOST1:PORT1:HOST2:PORT2>' \
  --create-dirs'[Create necessary local directory hierarchy]' \
  --max-redirs'[Maximum number of redirects allowed]':'<num>' \
  {-n,--netrc}'[Must read .netrc for user name and password]' \
  --proxy-crlfile'[Set a CRL list for proxy]':'<file>':_files \
  --sasl-ir'[Enable initial response in SASL authentication]' \
  --socks5-gssapi'[GSS-API auth for SOCKS5 proxies]':'Enable' \
  --interface'[Use network INTERFACE (or address)]':'<name>' \
  --key-type'[Private key file type (DER/PEM/ENG)]':'<type>' \
  --netrc-file'[Specify FILE for netrc]':'<filename>':_files \
  {-N,--no-buffer}'[Disable buffering of the output stream]' \
  --proxy-service-name'[SPNEGO proxy service name]':'<name>' \
  --styled-output'[styled output for HTTP headers]':'Enable' \
  --max-filesize'[Maximum file size to download]':'<bytes>' \
  --negotiate'[Use HTTP Negotiate (SPNEGO) authentication]' \
  --no-keepalive'[Disable TCP keepalive on the connection]' \
  {-#,--progress-bar}'[Display transfer progress as a bar]' \
  {-x,--proxy}'[Use this proxy]':'[protocol://]host[:port]' \
  --proxy-anyauth'[any proxy authentication method]':'Pick' \
  {-Q,--quote}'[Send command(s) to server before transfer]' \
  --request-target'[the target for this request]':'Specify' \
  {-u,--user}'[Server user and password]':'<user:password>' \
  {-K,--config}'[Read config from a file]':'<file>':_files \
  {-C,--continue-at}'[Resumed transfer offset]':'<offset>' \
  --data-raw'[HTTP POST data, '\''@'\'' allowed]':'<data>' \
  --disallow-username-in-url'[username in url]':'Disallow' \
  --krb'[Enable Kerberos with security <level>]':'<level>' \
  --proxy-ciphers'[SSL ciphers to use for proxy]':'<list>' \
  --proxy-digest'[Use Digest authentication on the proxy]' \
  --proxy-tlsuser'[TLS username for HTTPS proxy]':'<name>' \
  {-b,--cookie}'[Send cookies from string/file]':'<data>' \
  --data-urlencode'[HTTP POST data url encoded]':'<data>' \
  --delegation'[GSS-API delegation permission]':'<LEVEL>' \
  {-P,--ftp-port}'[Use PORT instead of PASV]':'<address>' \
  --post301'[Do not switch to GET after following a 301]' \
  --post302'[Do not switch to GET after following a 302]' \
  --post303'[Do not switch to GET after following a 303]' \
  --trace-time'[Add time stamps to trace/verbose output]' \
  --dns-servers'[DNS server addrs to use]':'<addresses>' \
  {-G,--get}'[Put the post data in the URL and use GET]' \
  --limit-rate'[Limit transfer speed to RATE]':'<speed>' \
  --ntlm-wb'[Use HTTP NTLM authentication with winbind]' \
  --path-as-is'[Do not squash .. sequences in URL path]' \
  --proxy-basic'[Use Basic authentication on the proxy]' \
  --retry-delay'[Wait time between retries]':'<seconds>' \
  --trace'[Write a debug trace to FILE]':'<file>':_files \
  {-a,--append}'[Append to target file when uploading]' \
  --ftp-ssl-ccc-mode'[Set CCC mode]':'<active/passive>' \
  --metalink'[Process given URLs as metalink XML file]' \
  --tr-encoding'[Request compressed transfer encoding]' \
  --xattr'[Store metadata in extended file attributes]' \
  --ftp-skip-pasv-ip'[the IP address for PASV]':'Skip' \
  --pass'[Pass phrase for the private key]':'<phrase>' \
  --proxy-ntlm'[Use NTLM authentication on the proxy]' \
  {-S,--show-error}'[Show error even when -s is used]' \
  --ciphers'[of ciphers> SSL ciphers to use]':'<list' \
  --form-string'[Specify multipart MIME data]':'<name=string>' \
  --login-options'[Server login options]':'<options>' \
  --tftp-blksize'[Set TFTP BLKSIZE option]':'<value>' \
  --tftp-no-options'[not send any TFTP options]':'Do' \
  {-v,--verbose}'[Make the operation more talkative]' \
  --proxy-key'[Private key for HTTPS proxy]':'<key>' \
  {-F,--form}'[Specify multipart MIME data]':'<name=content>' \
  --mail-from'[Mail from this address]':'<address>' \
  --oauth2-bearer'[OAuth 2 Bearer Token]':'<token>' \
  --proto'[Enable/disable PROTOCOLS]':'<protocols>' \
  --tlsauthtype'[TLS authentication type]':'<type>' \
  --no-sessionid'[Disable SSL session-ID reusing]' \
  --data-binary'[HTTP POST binary data]':'<data>' \
  --mail-rcpt'[Mail to this address]':'<address>' \
  {-t,--telnet-option}'[Set telnet option]':'<opt=val>' \
  --tls-max'[Use TLSv1.0 or greater]':'<VERSION>' \
  --ftp-ssl-ccc'[Send CCC after authenticating]' \
  {-4,--ipv4}'[Resolve names to IPv4 addresses]' \
  {-6,--ipv6}'[Resolve names to IPv6 addresses]' \
  --netrc-optional'[either .netrc or URL]':'Use' \
  --service-name'[SPNEGO service name]':'<name>' \
  {-V,--version}'[Show version number and quit]' \
  --data-ascii'[HTTP POST ASCII data]':'<data>' \
  --ftp-account'[Account data string]':'<data>' \
  --compressed-ssh'[SSH compression]':'Enable' \
  --disable-eprt'[Inhibit using EPRT or LPRT]' \
  --ftp-method'[Control CWD usage]':'<method>' \
  --pubkey'[SSH Public key file name]':'<key>' \
  --raw'[Do HTTP "raw"; no transfer decoding]' \
  --anyauth'[Pick any authentication method]' \
  --compressed'[Request compressed response]' \
  --ftp-pasv'[Use PASV/EPSV instead of PORT]' \
  --no-alpn'[Disable the ALPN TLS extension]' \
  --tcp-nodelay'[Use the TCP_NODELAY option]' \
  {-B,--use-ascii}'[Use ASCII/text transfer]' \
  --digest'[Use HTTP Digest Authentication]' \
  --proxy-tlsv1'[Use TLSv1 for HTTPS proxy]' \
  --engine'[Crypto engine to use]':'<name>' \
  --no-npn'[Disable the NPN TLS extension]' \
  --basic'[Use HTTP Basic Authentication]' \
  {-M,--manual}'[Display the full manual]' \
  --false-start'[Enable TLS False Start]' \
  --crlf'[Convert LF to CRLF in upload]' \
  {-d,--data}'[HTTP POST data]':'<data>' \
  {-I,--head}'[Show document info only]' \
  --key'[Private key file name]':'<key>' \
  --ntlm'[Use HTTP NTLM authentication]' \
  {-e,--referer}'[Referrer URL]':'<URL>' \
  {-1,--tlsv1}'[Use TLSv1.0 or greater]' \
  --disable-epsv'[Inhibit using EPSV]' \
  --stderr'[Where to redirect stderr]' \
  --ftp-pret'[Send PRET before PASV]' \
  {-L,--location}'[Follow redirects]' \
  --tcp-fastopen'[Use TCP Fast Open]' \
  --tlsuser'[TLS user name]':'<name>' \
  {-l,--list-only}'[List only mode]' \
  {-q,--disable}'[Disable .curlrc]' \
  --url'[URL to work with]':'<url>' \
  {-0,--http1.0}'[Use HTTP 1.0]' \
  {-h,--help}'[This help text]' \
  --ssl-reqd'[Require SSL/TLS]' \
  --tlspassword'[TLS password]' \
  {-s,--silent}'[Silent mode]' \
  --http1.1'[Use HTTP 1.1]' \
  {-2,--sslv2}'[Use SSLv2]' \
  {-3,--sslv3}'[Use SSLv3]' \
  --tlsv1.0'[Use TLSv1.0]' \
  --tlsv1.1'[Use TLSv1.1]' \
  --tlsv1.2'[Use TLSv1.2]' \
  --tlsv1.3'[Use TLSv1.3]' \
  --http2'[Use HTTP 2]' \
  --ssl'[Try SSL/TLS]' \
  '*:URL:_urls' && rc=0
return rc
